{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 4\n",
    "\n",
    "- has **`location_raw`**: True\n",
    "- vars one-hot encoded: False\n",
    "- var label-encoded: True\n",
    "- oversampled: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T21:45:21.114557Z",
     "start_time": "2018-05-19T21:45:19.922338Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "import humanize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T21:45:22.616191Z",
     "start_time": "2018-05-19T21:45:21.115374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row counts:\n",
      "\ttrain: 628906\n",
      "\ttest: 55547\n"
     ]
    }
   ],
   "source": [
    "X_train = pickle.load(open('./data/stage4-train.pkl', 'rb'))\n",
    "y_train = X_train.pop('stop_outcome')\n",
    "X_test = pickle.load(open('./data/stage4-test.pkl', 'rb'))\n",
    "y_test = X_test.pop('stop_outcome')\n",
    "\n",
    "print('Row counts:\\n\\ttrain: {}\\n\\ttest: {}'.format(X_train.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T13:16:42.027484Z",
     "start_time": "2018-05-19T13:16:42.025830Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# features = pickle.load(open('./data/stage4-l_encoded-oversampled.pkl', 'rb'))\n",
    "# labels = features.pop('stop_outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T13:16:42.031963Z",
     "start_time": "2018-05-19T13:16:42.028300Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take out 5% of data for final final testing; shuffle first\n",
    "# final_test_features = pickle.load(open('./data/final_test_set.pkl', 'rb'))\n",
    "# final_test_outcomes = final_test_features.pop('stop_outcome')\n",
    "# print('Final test set row count: {}'.format(final_test_features.shape[0]))\n",
    "\n",
    "# X_train = features\n",
    "# y_train = labels\n",
    "# X_test = final_test_features\n",
    "# y_test = final_test_outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T13:16:44.796546Z",
     "start_time": "2018-05-19T13:16:42.032917Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pato/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.68118890309107605"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "clf_sgd = linear_model.SGDClassifier()\n",
    "clf_sgd.fit(X_train, y_train)\n",
    "clf_sgd.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T13:21:19.378704Z",
     "start_time": "2018-05-19T13:16:44.797512Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 10building tree 2 of 10building tree 3 of 10building tree 4 of 10building tree 5 of 10building tree 6 of 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    1.8s remaining:    4.3s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    2.0s remaining:    0.8s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    2.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1      966737.1600            4.37m\n",
      "         2      938521.2147            4.36m\n",
      "         3      915793.7583            4.31m\n",
      "         4      897012.8253            4.26m\n",
      "         5      881475.0663            4.22m\n",
      "         6      868541.5927            4.18m\n",
      "         7      857503.3246            4.14m\n",
      "         8      848309.0173            4.11m\n",
      "         9      840114.7978            4.06m\n",
      "        10      833249.3731            4.02m\n",
      "        11      827302.9631            3.98m\n",
      "        12      821642.0822            3.94m\n",
      "        13      817122.6466            3.88m\n",
      "        14      812900.7590            3.84m\n",
      "        15      809349.9902            3.79m\n",
      "        16      806250.7984            3.74m\n",
      "        17      803465.3690            3.69m\n",
      "        18      800763.7098            3.65m\n",
      "        19      797216.7401            3.62m\n",
      "        20      794977.1946            3.57m\n",
      "        21      793149.3354            3.53m\n",
      "        22      790756.5706            3.49m\n",
      "        23      788548.9955            3.45m\n",
      "        24      786993.8752            3.40m\n",
      "        25      785386.3363            3.36m\n",
      "        26      784088.9905            3.31m\n",
      "        27      782196.4232            3.28m\n",
      "        28      780765.4461            3.23m\n",
      "        29      779520.1132            3.19m\n",
      "        30      778402.6028            3.15m\n",
      "        31      777143.2389            3.10m\n",
      "        32      776187.4763            3.05m\n",
      "        33      774750.9247            3.00m\n",
      "        34      773769.1661            2.96m\n",
      "        35      772999.7357            2.91m\n",
      "        36      772076.6671            2.87m\n",
      "        37      771185.6040            2.82m\n",
      "        38      770107.7730            2.78m\n",
      "        39      769218.3965            2.74m\n",
      "        40      768355.0182            2.70m\n",
      "        41      767698.3233            2.65m\n",
      "        42      767062.8882            2.60m\n",
      "        43      766433.2354            2.56m\n",
      "        44      765409.2055            2.51m\n",
      "        45      764603.1061            2.47m\n",
      "        46      763842.9549            2.43m\n",
      "        47      763212.8409            2.38m\n",
      "        48      762747.9275            2.33m\n",
      "        49      762088.3886            2.29m\n",
      "        50      761545.4923            2.24m\n",
      "        51      760973.9603            2.20m\n",
      "        52      760254.9757            2.15m\n",
      "        53      759667.2549            2.11m\n",
      "        54      758553.2941            2.06m\n",
      "        55      758101.3550            2.02m\n",
      "        56      757677.9800            1.97m\n",
      "        57      757105.1925            1.93m\n",
      "        58      756316.3313            1.88m\n",
      "        59      755853.0899            1.84m\n",
      "        60      755221.9626            1.79m\n",
      "        61      754679.2145            1.75m\n",
      "        62      754358.5977            1.70m\n",
      "        63      753805.8601            1.66m\n",
      "        64      753327.0256            1.61m\n",
      "        65      752776.0568            1.57m\n",
      "        66      752318.2994            1.52m\n",
      "        67      751951.6773            1.48m\n",
      "        68      751658.0437            1.43m\n",
      "        69      751117.6335            1.39m\n",
      "        70      750580.0997            1.34m\n",
      "        71      750185.7552            1.30m\n",
      "        72      749667.9306            1.25m\n",
      "        73      749279.6479            1.21m\n",
      "        74      749018.5338            1.16m\n",
      "        75      748644.9669            1.12m\n",
      "        76      748307.2896            1.07m\n",
      "        77      748051.6532            1.03m\n",
      "        78      747709.4537           58.99s\n",
      "        79      747442.7110           56.28s\n",
      "        80      747018.3701           53.60s\n",
      "        81      746748.6271           50.89s\n",
      "        82      746457.6741           48.16s\n",
      "        83      746123.0094           45.48s\n",
      "        84      745712.1373           42.82s\n",
      "        85      745413.0249           40.14s\n",
      "        86      745171.4604           37.46s\n",
      "        87      744727.8056           34.79s\n",
      "        88      744353.9890           32.08s\n",
      "        89      744006.7520           29.43s\n",
      "        90      743715.5938           26.75s\n",
      "        91      743430.7029           24.05s\n",
      "        92      743256.6123           21.36s\n",
      "        93      743024.6985           18.69s\n",
      "        94      742815.5262           16.01s\n",
      "        95      742502.1022           13.35s\n",
      "        96      742264.8875           10.68s\n",
      "        97      741900.0587            8.01s\n",
      "        98      741573.7139            5.33s\n",
      "        99      741161.1802            2.67s\n",
      "       100      740870.9388            0.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eclf score: 0.6084577024861829\n"
     ]
    }
   ],
   "source": [
    "clf1 = RandomForestClassifier(n_jobs=8, verbose=3, random_state=0)\n",
    "clf2 = GaussianNB()\n",
    "clf3 = DecisionTreeClassifier(random_state=0)\n",
    "clf4 = GradientBoostingClassifier(verbose=3, random_state=0)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('rf', clf1), ('gnb', clf2), ('dt', clf3), ('gb', clf4)],\n",
    "                        voting='soft')\n",
    "eclf = eclf.fit(X_train, y_train)\n",
    "print('eclf score: {}'.format(eclf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T13:21:19.382766Z",
     "start_time": "2018-05-19T13:21:19.379571Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=8,\n",
       "             oob_score=False, random_state=0, verbose=3, warm_start=False),\n",
       " GaussianNB(priors=None),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "             splitter='best'),\n",
       " GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "               learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "               max_features=None, max_leaf_nodes=None,\n",
       "               min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "               min_samples_leaf=1, min_samples_split=2,\n",
       "               min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "               presort='auto', random_state=0, subsample=1.0, verbose=3,\n",
       "               warm_start=False)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf.estimators_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T13:21:20.952741Z",
     "start_time": "2018-05-19T13:21:19.383691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6537166723675446\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "print('{}'.format(gnb.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T13:21:24.575045Z",
     "start_time": "2018-05-19T13:21:20.953573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5296595675734063\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(random_state=0)\n",
    "dtc.fit(X_train, y_train)\n",
    "print('{}'.format(dtc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T13:21:33.045834Z",
     "start_time": "2018-05-19T13:21:24.575804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5750985651790376\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(random_state=0)\n",
    "rfc.fit(X_train, y_train)\n",
    "print('{}'.format(rfc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T13:26:02.016818Z",
     "start_time": "2018-05-19T13:21:33.046654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5244927718868706\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(random_state=0)\n",
    "gbc.fit(X_train, y_train)\n",
    "print('{}'.format(gbc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingClassifier (Tuned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T22:07:18.782067Z",
     "start_time": "2018-05-19T21:45:28.486252Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1      793889.6061       11425.9968          796.86m\n",
      "         2      713850.9406        8394.0481          959.58m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7a5a53aac01f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mgbc_tuned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgbc_tuned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[0;32m-> 1034\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1035\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1088\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m                 tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m--> 788\u001b[0;31m                          check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gbc_tuned = GradientBoostingClassifier(\n",
    "    learning_rate=0.0983,\n",
    "    max_depth=6,\n",
    "    max_features=len(list(X_train.columns.values)),\n",
    "    subsample=0.9,\n",
    "    verbose=3,\n",
    "    random_state=0,\n",
    ")\n",
    "gbc_tuned.fit(X_train, y_train)\n",
    "print('{}'.format(gbc_tuned.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
