{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-05-24T19:10:05.264Z"
    }
   },
   "source": [
    "# RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T20:37:52.486573Z",
     "start_time": "2018-05-25T20:37:51.717204Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import humanize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.externals.joblib import parallel_backend\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T20:37:53.778206Z",
     "start_time": "2018-05-25T20:37:52.487316Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row counts:\n",
      "\ttrain: 250120\n",
      "\ttest: 62530\n"
     ]
    }
   ],
   "source": [
    "X_train = pickle.load(open('./data/stage6-train.pkl', 'rb'))\n",
    "y_train = X_train.pop('stop_outcome')\n",
    "X_test = pickle.load(open('./data/stage6-test.pkl', 'rb'))\n",
    "y_test = X_test.pop('stop_outcome')\n",
    "\n",
    "print('Row counts:\\n\\ttrain: {}\\n\\ttest: {}'.format(X_train.shape[0], X_test.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T23:14:34.866242Z",
     "start_time": "2018-05-24T22:36:18.603874Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] subsample=0.85, max_features=219, max_depth=5, learning_rate=0.1, criterion=mse \n",
      "[CV] subsample=0.85, max_features=219, max_depth=5, learning_rate=0.1, criterion=mse [CV] subsample=0.85, max_features=219, max_depth=5, learning_rate=0.1, criterion=mse [CV] subsample=0.85, max_features=219, max_depth=5, learning_rate=0.1, criterion=mse [CV] subsample=0.85, max_features=219, max_depth=5, learning_rate=0.1, criterion=mse \n",
      "\n",
      "\n",
      "\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1      207878.1076        2937.3215           21.88m\n",
      "         1      207869.0921        2979.9750           22.47m\n",
      "         1      207806.5613        2988.8004           24.44m\n",
      "         1      207669.5961        2991.6726           27.44m\n",
      "         1      208005.0543        2947.6120           30.22m\n",
      "         2      194943.0443        2291.8740           21.59m\n",
      "         2      194585.1921        2300.6604           23.01m\n",
      "         2      194495.1362        2307.9416           25.10m\n",
      "         2      194761.3395        2294.1609           26.30m\n",
      "         2      194862.3953        2274.8205           29.61m\n",
      "         3      184799.3813        1838.3343           21.33m\n",
      "         3      184441.4675        1844.4008           22.04m\n",
      "         3      184109.2882        1835.2106           24.20m\n",
      "         3      184528.2842        1828.7752           26.31m\n",
      "         4      176134.1391        1452.0029           21.32m\n",
      "         3      184666.4102        1814.9227           29.05m\n",
      "         4      175849.2322        1471.4479           22.51m\n",
      "         4      175475.4365        1473.8114           23.80m\n",
      "         4      175982.0733        1469.0354           25.71m\n",
      "         5      169458.5919        1191.0408           21.31m\n",
      "         4      176321.5211        1454.9488           28.45m\n",
      "         5      168634.3441        1204.9972           23.22m\n",
      "         5      168956.8800        1191.3005           23.72m\n",
      "         5      169125.7932        1205.5195           24.75m\n",
      "         6      163969.1478         980.0969           21.13m\n",
      "         6      162930.3154         993.5060           22.97m\n",
      "         5      169548.2446        1192.8050           28.42m\n",
      "         6      163379.2185         975.4422           24.37m\n",
      "         6      163523.3337         985.0302           24.28m\n",
      "         7      159084.8575         809.5022           20.86m\n",
      "         7      158287.1434         815.6698           22.97m\n",
      "         6      163929.5790         988.2953           27.84m\n",
      "         7      158928.1763         813.4376           23.97m\n",
      "         8      155294.2082         680.3674           21.41m\n",
      "         7      158764.5537         811.5911           24.81m\n",
      "         8      154221.6844         703.3695           23.09m\n",
      "         7      159224.0342         814.0592           26.66m\n",
      "         8      154816.0558         682.3094           23.55m\n",
      "         8      154803.4398         687.4691           24.04m\n",
      "         9      151955.9927         574.2085           21.88m\n",
      "         8      155216.2288         667.7543           25.60m\n",
      "         9      151566.7287         573.1659           22.91m\n",
      "         9      151266.4852         568.5641           23.28m\n",
      "         9      150945.1527         587.2578           23.34m\n",
      "        10      149204.1922         485.2359           21.97m\n",
      "         9      152063.6740         579.8172           24.73m\n",
      "        10      148548.7273         485.8801           22.28m\n",
      "        10      148599.0504         478.1072           22.57m\n",
      "        10      147858.0272         505.4705           23.62m\n",
      "        10      149169.7619         500.3959           23.82m\n",
      "        11      146300.9654         433.1719           21.81m\n",
      "        11      146266.2333         417.3707           22.01m\n",
      "        11      146746.8564         412.2840           22.16m\n",
      "        11      146785.4798         421.3901           23.32m\n",
      "        11      145506.7220         425.6435           23.63m\n",
      "        12      144032.7752         350.5551           21.45m\n",
      "        12      144182.3375         350.0259           21.77m\n",
      "        12      144808.4738         350.0171           22.23m\n",
      "        12      144644.6664         346.7142           23.13m\n",
      "        13      141974.4492         294.5226           21.42m\n",
      "        12      143337.9064         358.1800           23.56m\n",
      "        13      142007.8830         299.7237           21.49m\n",
      "        13      142813.2113         301.8742           22.44m\n",
      "        13      142803.6465         313.7542           22.55m\n",
      "        13      141418.4773         314.1905           22.85m\n",
      "        14      140745.8361         268.7389           21.06m\n",
      "        14      140371.9357         338.9382           21.49m\n",
      "        14      141000.4613         261.5749           21.94m\n",
      "        15      139355.6355         241.0251           20.64m\n",
      "        14      141108.9146         278.5711           22.66m\n",
      "        14      140255.2234         276.1325           22.81m\n",
      "        15      138856.6683         243.3051           21.21m\n",
      "        15      139826.8812         224.0789           21.73m\n",
      "        16      138412.6435         207.3938           20.82m\n",
      "        15      139734.1253         223.3364           22.74m\n",
      "        16      137685.0285         236.3557           21.09m\n",
      "        15      138419.0684         233.3948           22.84m\n",
      "        16      138428.8587         206.6171           21.63m\n",
      "        17      137049.6821         169.5477           20.74m\n",
      "        16      137233.0504         206.2796           22.46m\n",
      "        17      136393.9648         186.3607           20.84m\n",
      "        16      138645.3774         191.9048           22.60m\n",
      "        17      137569.5989         171.7806           21.39m\n",
      "        18      135996.1185         146.3457           20.31m\n",
      "        18      135071.7458         189.7381           20.29m\n",
      "        17      136175.6419         176.1259           21.86m\n",
      "        17      137459.7376         180.9746           22.48m\n",
      "        19      135250.8341         135.6893           19.82m\n",
      "        18      135331.9609         160.9576           21.37m\n",
      "        19      134292.0474         165.1905           19.95m\n",
      "        18      136623.6144         166.8446           21.37m\n",
      "        18      136797.5496         153.1699           21.93m\n",
      "        20      134491.2699         125.2420           19.63m\n",
      "        19      135709.5277         132.0606           20.91m\n",
      "        19      134159.9870         154.4708           21.18m\n",
      "        20      133462.9025         121.8179           19.83m\n",
      "        19      135873.1117         136.6800           21.71m\n",
      "        21      133925.5800         103.2198           19.41m\n",
      "        20      135028.9319         126.6032           20.62m\n",
      "        20      133621.9327         124.6658           21.05m\n",
      "        21      132581.5646         154.2891           19.93m\n",
      "        20      134959.5707         126.3024           21.30m\n",
      "        21      133925.3649         106.7606           20.38m\n",
      "        22      132819.9225         157.1266           19.35m\n",
      "        21      132742.7288         125.6139           20.63m\n",
      "        22      131550.9783         130.0764           19.79m\n",
      "        21      134424.5685         110.2769           21.23m\n",
      "        23      132293.5069          89.1866           19.32m\n",
      "        22      133629.7446         102.6618           20.47m\n",
      "        22      132088.7852         103.9969           20.56m\n",
      "        22      133944.1258          92.9928           20.76m\n",
      "        23      131034.1811          84.0213           19.60m\n",
      "        23      133229.0295          80.1778           20.03m\n",
      "        23      131306.6491          88.9318           20.12m\n",
      "        23      133318.1830          81.4436           20.23m\n",
      "        24      131686.5944         107.9042           19.21m\n",
      "        24      130699.2919          99.2011           19.49m\n",
      "        24      131120.2053          79.6133           19.65m\n",
      "        24      132395.9023          80.6010           19.64m\n",
      "        24      132747.2805          75.5967           19.78m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        25      131260.9456          70.5429           19.10m\n",
      "        25      131790.2712          64.3585           19.25m\n",
      "        25      130470.2446          64.5351           19.32m\n",
      "        25      129974.8874          89.5361           19.29m\n",
      "        25      132375.3434          73.2803           19.38m\n",
      "        26      130602.9984          59.8059           18.81m\n",
      "        26      129366.0704          59.0256           19.11m\n",
      "        26      131661.7097          66.7616           19.13m\n",
      "        26      131685.4927          64.5620           19.16m\n",
      "        26      130089.2476          74.3051           19.27m\n",
      "        27      130267.0428          68.5756           18.65m\n",
      "        27      131391.8165          59.5905           18.91m\n",
      "        27      131217.4754          55.8546           18.94m\n",
      "        27      129094.5699          59.0073           19.00m\n",
      "        27      129593.4575          58.0785           19.07m\n",
      "        28      129878.9578          48.9681           18.39m\n",
      "        28      131157.0035          51.2008           18.65m\n",
      "        28      128634.2907          63.6474           18.71m\n",
      "        28      129250.0413          48.0151           18.79m\n",
      "        28      130721.8407          53.2697           18.78m\n",
      "        29      129539.3388          49.7380           18.04m\n",
      "        29      130795.5871          49.0328           18.43m\n",
      "        29      130610.2551          40.9854           18.44m\n",
      "        29      128869.3478          45.6657           18.50m\n",
      "        29      128190.9937          51.0846           18.53m\n",
      "        30      129174.0509          45.9175           17.79m\n",
      "        30      130358.1782          44.4320           18.19m\n",
      "        30      130159.4264          39.0824           18.21m\n",
      "        30      128531.2668          44.4049           18.24m\n",
      "        30      127888.3035          40.1459           18.30m\n",
      "        31      128802.2946          60.0545           17.61m\n",
      "        31      130162.7263          34.9251           17.86m\n",
      "        31      129952.5139          33.1724           17.89m\n",
      "        31      128174.6692          44.4325           18.05m\n",
      "        31      127486.7552          58.1862           18.04m\n",
      "        32      128506.6195          33.2585           17.36m\n",
      "        32      129790.3733          36.3511           17.59m\n",
      "        32      129583.3958          32.9831           17.70m\n",
      "        32      128126.8442          40.9758           17.84m\n",
      "        32      127248.8505          49.6741           17.84m\n",
      "        33      128329.7529          45.3859           17.07m\n",
      "        33      129524.8939          29.9542           17.30m\n",
      "        33      129299.9359          33.7948           17.48m\n",
      "        33      126959.7710          41.6370           17.53m\n",
      "        33      127984.1053          30.8063           17.63m\n",
      "        34      127950.4396          36.8518           17.00m\n",
      "        34      129332.5773          34.5881           17.06m\n",
      "        34      128982.0971          49.2613           17.20m\n",
      "        34      126549.7128          31.7514           17.29m\n",
      "        34      127675.0018          29.5807           17.44m\n",
      "        35      127461.1204          28.9570           16.75m\n",
      "        35      129326.0624          22.0499           16.81m\n",
      "        35      126045.6201          30.0181           17.04m\n",
      "        35      128846.0372          35.5987           17.06m\n",
      "        35      127255.9874          30.1586           17.20m\n",
      "        36      127522.3548          18.7860           16.48m\n",
      "        36      129066.5979          21.9075           16.52m\n",
      "        36      128552.1606          20.7184           16.80m\n",
      "        36      126061.1676          41.9606           16.90m\n",
      "        37      127311.3879          20.2778           16.22m\n",
      "        36      126916.8754          28.9172           16.94m\n",
      "        37      128613.3097          22.7319           16.24m\n",
      "        37      128344.2951          21.3946           16.65m\n",
      "        37      126779.9909          23.3720           16.71m\n",
      "        38      128595.7575          19.6958           16.03m\n",
      "        38      127120.0069          31.1997           16.08m\n",
      "        37      125643.9432          38.5793           16.79m\n",
      "        38      128174.8858          20.7073           16.36m\n",
      "        39      128401.6875          17.1137           15.74m\n",
      "        38      126788.8099          22.4701           16.47m\n",
      "        39      126949.0088          26.7518           15.84m\n",
      "        38      125564.1991          20.0558           16.53m\n",
      "        39      128314.5107          17.1083           16.05m\n",
      "        40      128058.1375          15.3992           15.43m\n",
      "        39      126499.9176          24.6562           16.24m\n",
      "        40      126569.2051          19.8453           15.59m\n",
      "        39      125557.9324          22.5109           16.28m\n",
      "        41      128185.2564          19.1156           15.14m\n",
      "        40      127915.1311          16.8803           15.86m\n",
      "        40      126069.1379          19.1019           15.95m\n",
      "        41      126631.3979          13.9924           15.34m\n",
      "        40      125294.5070          13.6344           15.99m\n",
      "        42      127737.2727          18.0075           14.98m\n",
      "        41      126326.6424          19.9822           15.68m\n",
      "        41      127691.9529          23.5555           15.68m\n",
      "        42      126206.0873          13.7525           15.11m\n",
      "        41      125282.6780          18.8388           15.78m\n",
      "        42      125723.4410          12.9658           15.39m\n",
      "        43      127649.5584          14.5485           14.81m\n",
      "        42      127675.7857          16.3309           15.47m\n",
      "        43      126231.8225          19.8170           14.91m\n",
      "        42      124652.3769          31.6909           15.53m\n",
      "        43      125609.2121          16.3151           15.15m\n",
      "        44      127544.5849           9.7575           14.55m\n",
      "        43      127329.9002          13.5047           15.21m\n",
      "        43      124673.6927          17.7884           15.26m\n",
      "        44      126236.3455          13.3011           14.67m\n",
      "        44      125548.8079          14.8709           14.85m\n",
      "        45      127215.4602          17.3913           14.30m\n",
      "        44      126900.8530          12.8755           14.88m\n",
      "        45      125932.4565          12.2988           14.37m\n",
      "        44      124485.0317          19.9157           15.06m\n",
      "        45      125411.3453          16.0686           14.57m\n",
      "        46      127362.3262           7.1281           14.00m\n",
      "        45      127076.5244          12.2203           14.61m\n",
      "        46      125584.0846          22.7640           14.08m\n",
      "        45      124326.1506          17.3353           14.76m\n",
      "        46      125421.7051          12.0391           14.28m\n",
      "        47      127105.1177          10.0547           13.75m\n",
      "        46      126938.0496          12.2597           14.32m\n",
      "        47      125787.2249          18.7522           13.81m\n",
      "        46      124084.5772           8.8004           14.51m\n",
      "        47      125196.9063          12.3650           13.98m\n",
      "        48      127098.8916          19.9210           13.48m\n",
      "        47      126785.7027          17.6351           14.02m\n",
      "        48      125371.6273          10.7147           13.54m\n",
      "        47      124088.0231          28.6529           14.23m\n",
      "        48      125156.2283           6.9281           13.70m\n",
      "        49      126691.2598           9.6980           13.19m\n",
      "        48      126846.7476           9.0956           13.74m\n",
      "        49      125006.5754           9.2739           13.28m\n",
      "        50      126448.7392           9.7342           12.93m\n",
      "        49      124874.3343          17.2072           13.45m\n",
      "        48      123976.5619           9.4720           14.00m\n",
      "        49      126405.2676           9.5036           13.47m\n",
      "        50      125130.1282          10.6765           13.05m\n",
      "        49      123540.0836           7.0662           13.70m\n",
      "        51      126670.5564           8.4034           12.66m\n",
      "        50      124875.2528          12.5857           13.19m\n",
      "        50      126478.5927          25.1465           13.24m\n",
      "        51      124784.2271           8.3022           12.79m\n",
      "        52      126182.5710          11.5990           12.39m\n",
      "        51      124526.7877           9.6515           12.90m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        50      123667.3811           8.4860           13.44m\n",
      "        51      126021.9229           9.3638           12.98m\n",
      "        52      124937.1768           8.3417           12.51m\n",
      "        53      126414.2124           7.7585           12.11m\n",
      "        52      124701.3279           9.4575           12.64m\n",
      "        51      123329.1813          13.7334           13.17m\n",
      "        53      124717.9898          44.7235           12.22m\n",
      "        52      126148.9134           7.4453           12.73m\n",
      "        54      126261.4459           7.9316           11.83m\n",
      "        53      124134.1676           6.1708           12.36m\n",
      "        54      124260.5620           7.3272           11.93m\n",
      "        52      123481.1744           8.5537           12.92m\n",
      "        53      125923.3455           6.3120           12.44m\n",
      "        55      126236.4401          11.7172           11.58m\n",
      "        54      124376.8744           6.1632           12.09m\n",
      "        55      124001.3543           7.3796           11.69m\n",
      "        54      125799.3462           5.3630           12.17m\n",
      "        53      123344.0365           7.1470           12.67m\n",
      "        56      126046.0891           5.8876           11.33m\n",
      "        55      124022.9364           5.4665           11.82m\n",
      "        56      124320.8213           6.9440           11.43m\n",
      "        54      123072.2548           5.1724           12.40m\n",
      "        55      125632.9974           5.8459           11.91m\n",
      "        57      125856.7248           3.0104           11.08m\n",
      "        56      124166.2764           5.6954           11.57m\n",
      "        57      124179.6296           3.4260           11.18m\n",
      "        55      122836.9474           6.8423           12.12m\n",
      "        56      125853.3026          23.7490           11.68m\n",
      "        58      125712.0572           5.9101           10.82m\n",
      "        57      123885.7118          10.6944           11.31m\n",
      "        56      122832.7679          17.8984           11.85m\n",
      "        58      124113.1066          11.4221           10.93m\n",
      "        57      125488.4201           9.7168           11.41m\n",
      "        59      125668.1956           8.9613           10.55m\n",
      "        58      123974.5316           5.5210           11.05m\n",
      "        59      124058.0974           0.1835           10.66m\n",
      "        57      122877.2771           6.7022           11.60m\n",
      "        58      125256.2767           5.2855           11.15m\n",
      "        60      125619.2979           4.7500           10.29m\n",
      "        59      123686.6428           9.8829           10.80m\n",
      "        60      123970.4998           9.2940           10.39m\n",
      "        59      125031.3807           1.9779           10.85m\n",
      "        58      122625.0001           6.2120           11.31m\n",
      "        61      125683.0403           4.2916           10.00m\n",
      "        60      123463.9262           5.5333           10.51m\n",
      "        61      123791.8102           4.6832           10.11m\n",
      "        62      125535.4836           5.6547            9.71m\n",
      "        60      125194.6096           4.7188           10.58m\n",
      "        59      122596.2577           7.8347           11.03m\n",
      "        61      123363.4362           7.4754           10.22m\n",
      "        62      123757.4418           4.1490            9.84m\n",
      "        63      125162.7425           1.9121            9.44m\n",
      "        61      125276.5378           6.1049           10.29m\n",
      "        60      122627.5798          10.3521           10.74m\n",
      "        62      123350.5554           5.1255            9.93m\n",
      "        63      123683.6724           5.4004            9.55m\n",
      "        64      125367.7814           2.6523            9.16m\n",
      "        61      122259.7831           3.2206           10.47m\n",
      "        62      124854.8737           6.4676           10.05m\n",
      "        63      123564.1699           7.6596            9.64m\n",
      "        64      123655.0441           9.6410            9.27m\n",
      "        65      125144.2024           4.9353            8.91m\n",
      "        62      122256.2198           6.6573           10.19m\n",
      "        63      125225.5253           3.1211            9.78m\n",
      "        64      123076.0968           4.9273            9.40m\n",
      "        65      123284.4333           4.0755            9.00m\n",
      "        66      124858.1566           8.2434            8.64m\n",
      "        63      122314.2158           4.2251            9.88m\n",
      "        64      124723.6970           6.2723            9.49m\n",
      "        65      123318.9016           4.1203            9.11m\n",
      "        66      123509.2803           4.6664            8.74m\n",
      "        67      125014.8022           7.1110            8.37m\n",
      "        64      122265.9135           2.1253            9.58m\n",
      "        65      124879.3674           2.5418            9.21m\n",
      "        66      122940.2440           2.3852            8.83m\n",
      "        68      124895.7492           2.0795            8.10m\n",
      "        65      121857.0222          11.1595            9.27m\n",
      "        67      123160.9271           5.1219            8.49m\n",
      "        67      122883.1560           7.0462            8.55m\n",
      "        66      124532.6380           3.5798            8.94m\n",
      "        69      124746.2939           3.5147            7.82m\n",
      "        66      122065.2562           5.0841            8.97m\n",
      "        68      123059.6275          20.9341            8.25m\n",
      "        68      122534.9071           1.7321            8.27m\n",
      "        67      124247.9140          -3.3451            8.67m\n",
      "        70      124369.1709           2.0480            7.56m\n",
      "        67      121877.6954           6.1261            8.70m\n",
      "        69      122806.2098          12.7141            7.98m\n",
      "        69      122607.0809           4.7330            8.00m\n",
      "        68      124588.8803           2.6792            8.40m\n",
      "        71      124688.4520           2.6758            7.30m\n",
      "        68      121671.9208           7.3651            8.45m\n",
      "        70      122983.6336           2.3206            7.72m\n",
      "        70      122502.1967           4.3705            7.73m\n",
      "        72      124423.8819           4.6626            7.04m\n",
      "        69      124337.6199           0.3480            8.13m\n",
      "        69      121399.7091           4.0832            8.16m\n",
      "        71      122753.4382           1.9292            7.44m\n",
      "        71      122678.9929           1.4775            7.46m\n",
      "        73      124192.5791           0.6102            6.76m\n",
      "        70      121671.4789           2.9437            7.85m\n",
      "        70      124411.7287           1.7665            7.87m\n",
      "        72      122194.2921           2.6522            7.17m\n",
      "        74      124464.5494           0.5581            6.48m\n",
      "        71      121552.7677           1.6958            7.55m\n",
      "        72      122941.4224           3.6455            7.20m\n",
      "        73      122433.0753           2.5117            6.88m\n",
      "        75      124168.1880           4.4763            6.21m\n",
      "        71      124304.0748           4.4511            7.61m\n",
      "        72      121486.7696          11.4336            7.27m\n",
      "        73      122581.0036           5.9650            6.94m\n",
      "        74      122212.3198           3.8220            6.60m\n",
      "        76      124332.1924           5.6308            5.95m\n",
      "        73      121125.1300           6.6032            6.98m\n",
      "        72      124097.6688           1.6179            7.35m\n",
      "        75      122095.7030          -0.3155            6.32m\n",
      "        74      122497.7391           2.1511            6.69m\n",
      "        77      123963.0432           2.6560            5.69m\n",
      "        74      121207.6564           1.6659            6.70m\n",
      "        73      124033.7211           2.0318            7.08m\n",
      "        76      122389.9208           7.0325            6.06m\n",
      "        75      122233.8639           2.8294            6.41m\n",
      "        78      124161.6925           2.1850            5.43m\n",
      "        75      120805.8871           4.1252            6.43m\n",
      "        77      122173.0469           0.0845            5.79m\n",
      "        74      123979.2867          -0.3975            6.80m\n",
      "        79      123995.6191           0.9881            5.17m\n",
      "        76      122433.8897           1.7990            6.15m\n",
      "        76      120970.9583           2.6095            6.16m\n",
      "        78      122060.8817           9.2981            5.52m\n",
      "        75      124140.2914          -0.6768            6.53m\n",
      "        80      123986.2108           1.5855            4.91m\n",
      "        77      121129.3245           7.7602            5.89m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        79      122026.0854           2.3248            5.25m\n",
      "        77      122299.6946           0.7860            5.90m\n",
      "        81      123759.9217           1.9628            4.65m\n",
      "        76      123943.2189           5.9327            6.27m\n",
      "        78      120852.2469           0.5406            5.61m\n",
      "        80      121870.9571           0.7163            4.98m\n",
      "        78      122140.7951           3.6820            5.64m\n",
      "        82      123710.6754           3.4192            4.39m\n",
      "        77      123547.9178           1.5327            6.01m\n",
      "        79      120557.0464           3.3758            5.35m\n",
      "        81      121729.7212           0.1867            4.73m\n",
      "        83      123457.7405           3.0262            4.14m\n",
      "        79      121883.1487           0.9690            5.38m\n",
      "        80      120607.3767           1.2562            5.08m\n",
      "        78      123501.3892           3.5924            5.74m\n",
      "        82      121469.6202           3.7054            4.48m\n",
      "        80      122167.6317           2.3655            5.10m\n",
      "        84      123497.3133           2.0958            3.90m\n",
      "        81      120563.7295          10.7136            4.81m\n",
      "        79      123591.3361           6.0492            5.47m\n",
      "        83      121777.2657           0.9182            4.22m\n",
      "        81      121952.2961          26.2571            4.85m\n",
      "        85      123537.3414           1.3678            3.65m\n",
      "        82      120446.1691          18.5825            4.55m\n",
      "        80      123559.1222           0.9634            5.19m\n",
      "        84      121783.4351           4.2873            3.96m\n",
      "        86      123334.4096           4.3565            3.41m\n",
      "        82      121865.7123           4.6603            4.60m\n",
      "        83      120043.9708           1.8203            4.29m\n",
      "        81      123458.5396           1.8731            4.92m\n",
      "        85      121508.1026           5.6671            3.71m\n",
      "        87      123395.7453           2.7934            3.16m\n",
      "        83      121669.5447           0.4347            4.33m\n",
      "        82      123260.8403           1.7073            4.66m\n",
      "        84      120193.7698           2.7791            4.04m\n",
      "        86      121263.5913           2.0144            3.46m\n",
      "        84      121663.5665           5.6820            4.06m\n",
      "        88      122982.9117           2.2534            2.91m\n",
      "        83      123078.2857           3.8437            4.39m\n",
      "        85      120222.1286           1.2908            3.78m\n",
      "        87      121205.4666          -0.1008            3.21m\n",
      "        85      121604.4794           9.4611            3.80m\n",
      "        89      123499.8281          -0.8899            2.66m\n",
      "        86      120339.5064           1.6554            3.52m\n",
      "        84      123251.0343           2.2559            4.12m\n",
      "        88      121263.5003          -0.4654            2.96m\n",
      "        90      123190.6038           3.2580            2.41m\n",
      "        85      123343.9140           2.1814            3.85m\n",
      "        86      121479.6745           4.8206            3.55m\n",
      "        87      119830.7335           0.1572            3.26m\n",
      "        91      123153.6301           1.9328            2.17m\n",
      "        89      121101.6789           1.7709            2.71m\n",
      "        86      122969.9054           3.9031            3.58m\n",
      "        88      119950.2028           1.9254            3.00m\n",
      "        87      121187.8681          -0.3892            3.29m\n",
      "        92      123042.1150           1.1482            1.92m\n",
      "        90      121157.8966           4.3720            2.46m\n",
      "        87      122902.2143           4.8575            3.32m\n",
      "        89      119843.8492           4.4478            2.75m\n",
      "        93      123126.9528           4.2581            1.68m\n",
      "        88      121343.9039          -0.1989            3.04m\n",
      "        91      121191.0608           2.4504            2.21m\n",
      "        88      122686.0838           0.0395            3.05m\n",
      "        94      122976.1271           1.3122            1.43m\n",
      "        90      119985.3917           0.6274            2.50m\n",
      "        89      121143.8031           0.4303            2.78m\n",
      "        92      120821.5285           1.3525            1.96m\n",
      "        89      122714.4294           0.2199            2.79m\n",
      "        95      122655.7073          -0.9500            1.19m\n",
      "        91      119696.1692          -9.6720            2.25m\n",
      "        90      121349.2461          -0.1420            2.53m\n",
      "        93      120833.9036           1.8908            1.71m\n",
      "        90      122704.3882           1.1187            2.53m\n",
      "        96      123035.6799           1.1180           57.13s\n",
      "        94      120593.5879           1.2519            1.46m\n",
      "        92      119794.5020           3.0259            2.00m\n",
      "        91      121063.5741           0.2386            2.27m\n",
      "        91      122803.8786           2.6108            2.27m\n",
      "        97      122748.1835           1.2333           42.76s\n",
      "        95      120799.2912           1.5541            1.22m\n",
      "        93      119586.6619          -0.3333            1.74m\n",
      "        92      122540.2617           1.4836            2.02m\n",
      "        98      122565.6843           0.3297           28.45s\n",
      "        92      121063.7298           4.1351            2.02m\n",
      "        96      120779.3278           0.8788           58.39s\n",
      "        94      119502.0829           0.2678            1.49m\n",
      "        93      120992.9371          -1.1159            1.76m\n",
      "        99      122654.4854          -0.1832           14.20s\n",
      "        93      122605.0738          -0.5703            1.76m\n",
      "        97      120772.3129           1.2608           43.79s\n",
      "        95      119551.1247           2.0406            1.24m\n",
      "       100      122753.2504           2.4124            0.00s\n",
      "        94      120720.0313          18.7427            1.51m\n",
      "[CV]  subsample=0.85, max_features=219, max_depth=5, learning_rate=0.1, criterion=mse, score=0.7354575620677248, total=23.7min\n",
      "        94      122734.0448          -0.7546            1.51m\n",
      "        96      119281.7038           3.5437           59.53s\n",
      "        98      120322.3220           1.1057           29.18s\n",
      "        95      120818.8868           1.8621            1.26m\n",
      "        95      122363.7902           0.0726            1.26m\n",
      "        97      119206.4830           7.2712           44.52s\n",
      "        99      120602.9883           0.2587           14.55s\n",
      "        96      120604.1678           0.7370            1.00m\n",
      "        96      122425.7989          -0.1019            1.00m\n",
      "       100      120321.9572          -0.0004            0.00s\n",
      "[CV]  subsample=0.85, max_features=219, max_depth=5, learning_rate=0.1, criterion=mse, score=0.5684612462765638, total=24.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed: 24.3min remaining: 36.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        98      119204.8673          -0.3653           29.67s\n",
      "        97      120454.8527           0.6704           45.04s\n",
      "        97      122649.9935           1.5442           45.05s\n",
      "        99      119376.0769          -1.7122           14.76s\n",
      "        98      120710.5844          -0.5303           29.87s\n",
      "        98      122225.9260          -0.1993           29.88s\n",
      "        99      120561.4348          -0.7700           14.85s\n",
      "        99      122276.3991           1.6159           14.85s\n",
      "       100      118931.5327           9.8559            0.00s\n",
      "[CV]  subsample=0.85, max_features=219, max_depth=5, learning_rate=0.1, criterion=mse, score=0.4258156085079162, total=24.6min\n",
      "       100      120280.0149           0.7943            0.00s\n",
      "[CV]  subsample=0.85, max_features=219, max_depth=5, learning_rate=0.1, criterion=mse, score=0.6805533343994883, total=24.7min\n",
      "       100      122380.6869           0.4769            0.00s\n",
      "[CV]  subsample=0.85, max_features=219, max_depth=5, learning_rate=0.1, criterion=mse, score=0.7145627186406797, total=24.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed: 24.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1      259877.0596        3681.6961           16.08m\n",
      "         2      243628.3064        2860.3215           16.09m\n",
      "         3      230783.2506        2275.3221           15.75m\n",
      "         4      220268.2554        1823.9603           15.59m\n",
      "         5      211760.4000        1486.9702           15.30m\n",
      "         6      204936.0137        1223.2421           15.09m\n",
      "         7      199132.1452        1015.3677           15.01m\n",
      "         8      194382.8840         848.8493           14.74m\n",
      "         9      189852.2246         711.5909           14.67m\n",
      "        10      186474.8949         593.5842           14.65m\n",
      "        11      183439.4333         532.2967           14.47m\n",
      "        12      181201.3566         445.9496           14.27m\n",
      "        13      178814.0952         377.4467           14.06m\n",
      "        14      176667.5666         329.7077           13.92m\n",
      "        15      175012.7039         287.4436           13.88m\n",
      "        16      173443.3898         249.1773           13.75m\n",
      "        17      172208.3864         207.3109           13.51m\n",
      "        18      171148.3922         199.7979           13.42m\n",
      "        19      170006.4596         184.9004           13.28m\n",
      "        20      169219.3637         146.3175           13.11m\n",
      "        21      168104.4905         134.1902           12.84m\n",
      "        22      167382.0273         118.1144           12.62m\n",
      "        23      166940.1794         116.5824           12.38m\n",
      "        24      166023.3874         105.9096           12.18m\n",
      "        25      165489.6865         100.8282           12.04m\n",
      "        26      165041.0714          74.9721           11.83m\n",
      "        27      164540.9095          71.5817           11.61m\n",
      "        28      163933.7639          72.9014           11.38m\n",
      "        29      163668.7385          50.4392           11.16m\n",
      "        30      163204.3199          64.7290           10.98m\n",
      "        31      162848.3538          47.7760           10.80m\n",
      "        32      162328.4627          44.0207           10.61m\n",
      "        33      162120.7072          39.4983           10.40m\n",
      "        34      161934.4966          31.6664           10.18m\n",
      "        35      161642.1612          35.4606            9.99m\n",
      "        36      161580.3006          29.7413            9.78m\n",
      "        37      161279.7024          31.9718            9.60m\n",
      "        38      160762.3448          26.7193            9.43m\n",
      "        39      160542.3089          28.4828            9.24m\n",
      "        40      160461.4179          25.7069            9.04m\n",
      "        41      160237.7902          23.1499            8.85m\n",
      "        42      160210.6985          20.2473            8.67m\n",
      "        43      160214.7266          25.9928            8.50m\n",
      "        44      159736.3961          14.8800            8.34m\n",
      "        45      159817.5612          15.0573            8.15m\n",
      "        46      159259.6997          17.4003            7.98m\n",
      "        47      159168.2166          13.7970            7.80m\n",
      "        48      159247.8957          19.3644            7.67m\n",
      "        49      158486.3464          11.4995            7.50m\n",
      "        50      158820.2998          12.1620            7.33m\n",
      "        51      158552.1931          13.2606            7.16m\n",
      "        52      158360.2773           7.9107            6.99m\n",
      "        53      158422.8952          14.0511            6.85m\n",
      "        54      158255.5956          12.6031            6.67m\n",
      "        55      157981.8570           6.7533            6.52m\n",
      "        56      157733.4099           9.2395            6.36m\n",
      "        57      158008.0966           6.6155            6.21m\n",
      "        58      157197.1546           4.9851            6.05m\n",
      "        59      157796.5103           6.2138            5.88m\n",
      "        60      157630.7112           7.6154            5.74m\n",
      "        61      157489.5030           6.7727            5.58m\n",
      "        62      157255.5760           6.3702            5.43m\n",
      "        63      157234.9034           6.2554            5.27m\n",
      "        64      157160.7093           5.0660            5.11m\n",
      "        65      156951.2414           6.6518            4.96m\n",
      "        66      156617.3814           7.4621            4.83m\n",
      "        67      156596.0235           4.8605            4.67m\n",
      "        68      156542.0559           4.5044            4.52m\n",
      "        69      156603.2086           4.7916            4.37m\n",
      "        70      156530.5287           2.5885            4.21m\n",
      "        71      156343.6713           0.9351            4.07m\n",
      "        72      156198.6280           9.3984            3.92m\n",
      "        73      156280.2485           4.4053            3.78m\n",
      "        74      155954.2092           7.2772            3.63m\n",
      "        75      155589.0986           4.3402            3.48m\n",
      "        76      156048.4768           2.4969            3.33m\n",
      "        77      155898.8010           4.4566            3.18m\n",
      "        78      155638.0811           1.8353            3.04m\n",
      "        79      155582.3335           1.5156            2.89m\n",
      "        80      155658.3853           5.0009            2.75m\n",
      "        81      155704.6601           3.1743            2.61m\n",
      "        82      155444.0972           1.8160            2.47m\n",
      "        83      155398.9894           3.9272            2.33m\n",
      "        84      155129.1591           2.1196            2.19m\n",
      "        85      155011.2127           1.6205            2.05m\n",
      "        86      155036.0737          -0.1546            1.91m\n",
      "        87      154886.5747           6.4730            1.77m\n",
      "        88      155025.6000           0.8839            1.63m\n",
      "        89      155078.3812          -0.6189            1.49m\n",
      "        90      154686.8321           2.4337            1.35m\n",
      "        91      154793.0143           2.5789            1.22m\n",
      "        92      154796.8955           3.0540            1.08m\n",
      "        93      154536.0333           0.7913           56.61s\n",
      "        94      154557.7439           1.4538           48.43s\n",
      "        95      154539.4918           3.0640           40.33s\n",
      "        96      154240.1800           1.3903           32.21s\n",
      "        97      154075.2563           2.7599           24.09s\n",
      "        98      154149.1511           1.0353           16.05s\n",
      "        99      153933.1061           2.0422            8.02s\n",
      "       100      153939.7768           0.6651            0.00s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals.joblib import parallel_backend\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "\n",
    "\n",
    "params = {\n",
    "    'criterion': ['friedman_mse', 'mse', 'mae'],\n",
    "#     'loss': ['deviance'],\n",
    "#     'learning_rate': [0.0983, 0.1],\n",
    "    'learning_rate': [0.09, 0.1],\n",
    "    'max_depth': [5, 6, 7],\n",
    "    'max_features': [None, len(list(X_train.columns.values))],\n",
    "    'subsample': [0.85, 0.9, 0.85],\n",
    "#     'verbose': [3],\n",
    "#     'random_state': [0],\n",
    "\n",
    "}\n",
    "\n",
    "gbc = GradientBoostingClassifier(verbose=3, random_state=0)\n",
    "clf = RandomizedSearchCV(gbc, params, scoring='accuracy', cv=5, verbose=3, n_iter=1)\n",
    "\n",
    "with parallel_backend('threading'):\n",
    "    clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T23:14:35.836968Z",
     "start_time": "2018-05-24T23:14:34.867145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.728882136574\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T23:14:35.843014Z",
     "start_time": "2018-05-24T23:14:35.838047Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='mse', init=None, learning_rate=0.1,\n",
       "              loss='deviance', max_depth=5, max_features=219,\n",
       "              max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "              min_impurity_split=None, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=100, presort='auto', random_state=0,\n",
       "              subsample=0.85, verbose=3, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T23:14:35.852638Z",
     "start_time": "2018-05-24T23:14:35.844142Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pato/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/pato/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/pato/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/pato/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/pato/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/pato/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/pato/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 1464.13193541]),\n",
       " 'mean_score_time': array([ 0.92445889]),\n",
       " 'mean_test_score': array([ 0.62497201]),\n",
       " 'mean_train_score': array([ 0.75491662]),\n",
       " 'param_criterion': masked_array(data = ['mse'],\n",
       "              mask = [False],\n",
       "        fill_value = ?),\n",
       " 'param_learning_rate': masked_array(data = [0.1],\n",
       "              mask = [False],\n",
       "        fill_value = ?),\n",
       " 'param_max_depth': masked_array(data = [5],\n",
       "              mask = [False],\n",
       "        fill_value = ?),\n",
       " 'param_max_features': masked_array(data = [219],\n",
       "              mask = [False],\n",
       "        fill_value = ?),\n",
       " 'param_subsample': masked_array(data = [0.85],\n",
       "              mask = [False],\n",
       "        fill_value = ?),\n",
       " 'params': [{'criterion': 'mse',\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 5,\n",
       "   'max_features': 219,\n",
       "   'subsample': 0.85}],\n",
       " 'rank_test_score': array([1], dtype=int32),\n",
       " 'split0_test_score': array([ 0.73545756]),\n",
       " 'split0_train_score': array([ 0.74983258]),\n",
       " 'split1_test_score': array([ 0.71456272]),\n",
       " 'split1_train_score': array([ 0.75118319]),\n",
       " 'split2_test_score': array([ 0.68055333]),\n",
       " 'split2_train_score': array([ 0.75486267]),\n",
       " 'split3_test_score': array([ 0.42581561]),\n",
       " 'split3_train_score': array([ 0.76015513]),\n",
       " 'split4_test_score': array([ 0.56846125]),\n",
       " 'split4_train_score': array([ 0.75854952]),\n",
       " 'std_fit_time': array([ 24.81824044]),\n",
       " 'std_score_time': array([ 0.09595826]),\n",
       " 'std_test_score': array([ 0.11504784]),\n",
       " 'std_train_score': array([ 0.00401071])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T23:14:35.856765Z",
     "start_time": "2018-05-24T23:14:35.853711Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'mse',\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 5,\n",
       " 'max_features': 219,\n",
       " 'subsample': 0.85}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T23:14:35.860336Z",
     "start_time": "2018-05-24T23:14:35.857876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62497201343355191"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal parameters with Stage 6 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T20:51:41.917534Z",
     "start_time": "2018-05-25T20:38:12.932845Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1      259877.0596        3681.6961           14.99m\n",
      "         2      243628.3064        2860.3215           15.02m\n",
      "         3      230783.2506        2275.3221           14.79m\n",
      "         4      220268.2554        1823.9603           14.78m\n",
      "         5      211760.4000        1486.9702           14.66m\n",
      "         6      204936.0137        1223.2421           14.40m\n",
      "         7      199132.1452        1015.3677           14.40m\n",
      "         8      194382.8840         848.8493           14.18m\n",
      "         9      189852.2246         711.5909           14.17m\n",
      "        10      186474.8949         593.5842           14.17m\n",
      "        11      183439.4333         532.2967           14.06m\n",
      "        12      181201.3566         445.9496           13.90m\n",
      "        13      178814.0952         377.4467           13.73m\n",
      "        14      176667.5666         329.7077           13.54m\n",
      "        15      175012.7039         287.4436           13.49m\n",
      "        16      173443.3898         249.1773           13.36m\n",
      "        17      172208.3864         207.3109           13.14m\n",
      "        18      171148.3922         199.7979           13.02m\n",
      "        19      170006.4596         184.9004           12.86m\n",
      "        20      169219.3637         146.3175           12.71m\n",
      "        21      168104.4905         134.1902           12.47m\n",
      "        22      167382.0273         118.1144           12.30m\n",
      "        23      166940.1794         116.5824           12.09m\n",
      "        24      166023.3874         105.9096           11.90m\n",
      "        25      165489.6865         100.8282           11.79m\n",
      "        26      165041.0714          74.9721           11.60m\n",
      "        27      164540.9095          71.5817           11.39m\n",
      "        28      163933.7639          72.9014           11.17m\n",
      "        29      163668.7385          50.4392           10.96m\n",
      "        30      163204.3199          64.7290           10.79m\n",
      "        31      162848.3538          47.7760           10.63m\n",
      "        32      162328.4627          44.0207           10.46m\n",
      "        33      162120.7072          39.4983           10.26m\n",
      "        34      161934.4966          31.6664           10.05m\n",
      "        35      161642.1612          35.4606            9.88m\n",
      "        36      161580.3006          29.7413            9.67m\n",
      "        37      161279.7024          31.9718            9.50m\n",
      "        38      160762.3448          26.7193            9.33m\n",
      "        39      160542.3089          28.4828            9.15m\n",
      "        40      160461.4179          25.7069            8.96m\n",
      "        41      160237.7902          23.1499            8.78m\n",
      "        42      160210.6985          20.2473            8.60m\n",
      "        43      160214.7266          25.9928            8.43m\n",
      "        44      159736.3961          14.8800            8.27m\n",
      "        45      159817.5612          15.0573            8.10m\n",
      "        46      159259.6997          17.4003            7.93m\n",
      "        47      159168.2166          13.7970            7.75m\n",
      "        48      159247.8957          19.3644            7.63m\n",
      "        49      158486.3464          11.4995            7.46m\n",
      "        50      158820.2998          12.1620            7.29m\n",
      "        51      158552.1931          13.2606            7.13m\n",
      "        52      158360.2773           7.9107            6.96m\n",
      "        53      158422.8952          14.0511            6.81m\n",
      "        54      158255.5956          12.6031            6.64m\n",
      "        55      157981.8570           6.7533            6.49m\n",
      "        56      157733.4099           9.2395            6.34m\n",
      "        57      158008.0966           6.6155            6.18m\n",
      "        58      157197.1546           4.9851            6.02m\n",
      "        59      157796.5103           6.2138            5.86m\n",
      "        60      157630.7112           7.6154            5.72m\n",
      "        61      157489.5030           6.7727            5.56m\n",
      "        62      157255.5760           6.3702            5.41m\n",
      "        63      157234.9034           6.2554            5.25m\n",
      "        64      157160.7093           5.0660            5.10m\n",
      "        65      156951.2414           6.6518            4.95m\n",
      "        66      156617.3814           7.4621            4.82m\n",
      "        67      156596.0235           4.8605            4.66m\n",
      "        68      156542.0559           4.5044            4.51m\n",
      "        69      156603.2086           4.7916            4.36m\n",
      "        70      156530.5287           2.5885            4.20m\n",
      "        71      156343.6713           0.9351            4.05m\n",
      "        72      156198.6280           9.3984            3.91m\n",
      "        73      156280.2485           4.4053            3.77m\n",
      "        74      155954.2092           7.2772            3.62m\n",
      "        75      155589.0986           4.3402            3.47m\n",
      "        76      156048.4768           2.4969            3.33m\n",
      "        77      155898.8010           4.4566            3.18m\n",
      "        78      155638.0811           1.8353            3.03m\n",
      "        79      155582.3335           1.5156            2.89m\n",
      "        80      155658.3853           5.0009            2.75m\n",
      "        81      155704.6601           3.1743            2.61m\n",
      "        82      155444.0972           1.8160            2.47m\n",
      "        83      155398.9894           3.9272            2.33m\n",
      "        84      155129.1591           2.1196            2.19m\n",
      "        85      155011.2127           1.6205            2.05m\n",
      "        86      155036.0737          -0.1546            1.91m\n",
      "        87      154886.5747           6.4730            1.77m\n",
      "        88      155025.6000           0.8839            1.63m\n",
      "        89      155078.3812          -0.6189            1.50m\n",
      "        90      154686.8321           2.4337            1.36m\n",
      "        91      154793.0143           2.5789            1.22m\n",
      "        92      154796.8955           3.0540            1.08m\n",
      "        93      154536.0333           0.7913           56.86s\n",
      "        94      154557.7439           1.4538           48.66s\n",
      "        95      154539.4918           3.0640           40.52s\n",
      "        96      154240.1800           1.3903           32.38s\n",
      "        97      154075.2563           2.7599           24.23s\n",
      "        98      154149.1511           1.0353           16.15s\n",
      "        99      153933.1061           2.0422            8.07s\n",
      "       100      153939.7768           0.6651            0.00s\n",
      "0.7288821365744442\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(criterion='mse', learning_rate=0.1, max_depth=5, max_features=219,\n",
    "                                 subsample=0.85, verbose=3, random_state=0)\n",
    "gbc.fit(X_train, y_train)\n",
    "print('{}'.format(gbc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T20:55:05.308945Z",
     "start_time": "2018-05-25T20:55:04.285465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         Arrest       0.53      0.36      0.43      1408\n",
      "        Summons       0.66      0.27      0.38      2657\n",
      "         Ticket       0.76      0.96      0.85     43224\n",
      " Verbal Warning       0.49      0.26      0.34      8743\n",
      "Written Warning       0.58      0.12      0.20      6498\n",
      "\n",
      "    avg / total       0.69      0.73      0.68     62530\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf_report = classification_report(y_test, gbc.predict(X_test), target_names=['Arrest', 'Summons', 'Ticket',\n",
    "                                                                              'Verbal Warning', 'Written Warning'])\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison against other stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T01:32:50.033014Z",
     "start_time": "2018-05-25T00:58:47.680387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1:\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1      260150.4974        3640.4853            4.06m\n",
      "         2      244207.2398        2849.4365            4.04m\n",
      "         3      231167.1396        2236.9900            4.03m\n",
      "         4      221023.9044        1816.6583            3.98m\n",
      "         5      212572.7266        1469.7807            3.95m\n",
      "         6      205823.0086        1202.1373            3.88m\n",
      "         7      200032.6123         991.1782            3.83m\n",
      "         8      195291.8255         820.9246            3.80m\n",
      "         9      191250.9904         695.6237            3.77m\n",
      "        10      187873.7384         582.1326            3.76m\n",
      "        11      185143.0292         489.8997            3.74m\n",
      "        12      182707.0548         432.7195            3.72m\n",
      "        13      180733.2744         358.9886            3.67m\n",
      "        14      178834.0952         317.7685            3.64m\n",
      "        15      177112.8396         264.3266            3.60m\n",
      "        16      175664.5332         237.2220            3.57m\n",
      "        17      174494.9568         209.5543            3.54m\n",
      "        18      173418.0467         170.2342            3.50m\n",
      "        19      172382.3193         158.0151            3.46m\n",
      "        20      171674.0548         132.5385            3.43m\n",
      "        21      170918.0508         127.2493            3.38m\n",
      "        22      170087.8970         109.6896            3.35m\n",
      "        23      169721.3417          98.4287            3.30m\n",
      "        24      168801.3578          81.8505            3.26m\n",
      "        25      168727.8973          80.5305            3.23m\n",
      "        26      168125.2196          61.8727            3.19m\n",
      "        27      167750.0459          57.1519            3.15m\n",
      "        28      167170.5689          53.9427            3.11m\n",
      "        29      167172.9930          49.1348            3.06m\n",
      "        30      166316.6313          45.4037            3.02m\n",
      "        31      166524.6995          38.5728            2.98m\n",
      "        32      166240.6760          35.5827            2.94m\n",
      "        33      165921.8326          32.4361            2.90m\n",
      "        34      165478.3194          31.4066            2.85m\n",
      "        35      165332.6895          29.2555            2.81m\n",
      "        36      165256.4366          22.9018            2.76m\n",
      "        37      165259.0494          25.4844            2.71m\n",
      "        38      164699.8961          16.6662            2.66m\n",
      "        39      164757.5274          22.5579            2.62m\n",
      "        40      164465.2255          16.7476            2.58m\n",
      "        41      164231.5178          15.6359            2.54m\n",
      "        42      164087.2141          12.1484            2.49m\n",
      "        43      164177.4007          14.6009            2.45m\n",
      "        44      163792.4210           8.0520            2.41m\n",
      "        45      163947.9891          14.6921            2.36m\n",
      "        46      163918.3632           6.3544            2.31m\n",
      "        47      163587.3264          13.4508            2.27m\n",
      "        48      163786.1981           6.4250            2.23m\n",
      "        49      163056.7486           9.5574            2.18m\n",
      "        50      163272.5413           3.7733            2.14m\n",
      "        51      163384.5517         -13.4411            2.10m\n",
      "        52      163647.2894           4.8497            2.06m\n",
      "        53      163055.3714           4.6165            2.02m\n",
      "        54      162705.6666           2.2882            1.98m\n",
      "        55      163123.2654           4.3331            1.93m\n",
      "        56      162708.0044           4.4656            1.89m\n",
      "        57      162711.5255           7.6867            1.85m\n",
      "        58      162729.0738           6.9474            1.81m\n",
      "        59      162643.5955           4.5639            1.77m\n",
      "        60      162669.0611           4.3240            1.73m\n",
      "        61      162345.8616           3.8309            1.69m\n",
      "        62      162285.7270           0.5387            1.64m\n",
      "        63      162055.6755           2.7166            1.60m\n",
      "        64      162269.5725           3.0753            1.56m\n",
      "        65      162047.2385           3.7049            1.52m\n",
      "        66      162087.0734           3.2139            1.47m\n",
      "        67      161792.6805           0.4334            1.43m\n",
      "        68      161827.0855          -1.1905            1.38m\n",
      "        69      161827.5015           0.3128            1.34m\n",
      "        70      162074.9784           0.1551            1.30m\n",
      "        71      161601.6725           1.5521            1.26m\n",
      "        72      161786.5442           2.6314            1.22m\n",
      "        73      161550.1589           2.5251            1.17m\n",
      "        74      161526.2422           1.4731            1.13m\n",
      "        75      161216.0555           2.9409            1.09m\n",
      "        76      161550.2178          -0.1021            1.04m\n",
      "        77      160952.0929           1.1321            1.00m\n",
      "        78      161025.2572           0.3844           57.42s\n",
      "        79      161102.6638           0.8270           54.80s\n",
      "        80      161182.1103           0.1096           52.19s\n",
      "        81      161158.6046           0.8632           49.52s\n",
      "        82      161099.5542           1.0282           46.91s\n",
      "        83      161105.4500           0.3148           44.29s\n",
      "        84      160919.4476           3.5110           41.69s\n",
      "        85      160747.4190          -1.9893           39.09s\n",
      "        86      160840.6425           3.1478           36.55s\n",
      "        87      160398.2606          -0.7268           33.93s\n",
      "        88      160704.8155          -3.5323           31.34s\n",
      "        89      160702.8155           2.1401           28.71s\n",
      "        90      160616.3190          -1.1177           26.10s\n",
      "        91      160467.2894           0.5710           23.48s\n",
      "        92      160680.3097          -1.1384           20.86s\n",
      "        93      160328.5747           1.5888           18.24s\n",
      "        94      160365.4966           2.5569           15.64s\n",
      "        95      160191.0197          -0.0850           13.03s\n",
      "        96      160135.2664          -2.6392           10.42s\n",
      "        97      160262.0510          -1.2222            7.81s\n",
      "        98      160164.5424          -0.8877            5.20s\n",
      "        99      159780.2591          -1.1142            2.60s\n",
      "       100      160207.1650          -1.0736            0.00s\n",
      "stage 1: 0.7188229649768111\n",
      "Stage 2:\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1      259999.1994        3708.4993           15.77m\n",
      "         2      243719.5787        2875.8210           15.39m\n",
      "         3      230667.2571        2271.5898           15.03m\n",
      "         4      220095.3619        1807.4857           15.06m\n",
      "         5      211738.4728        1491.0984           15.14m\n",
      "         6      204822.1334        1223.1651           15.08m\n",
      "         7      198944.9045        1037.2326           14.83m\n",
      "         8      194285.0148         850.0066           14.76m\n",
      "         9      189745.6606         708.1282           14.68m\n",
      "        10      186445.2294         603.7483           14.67m\n",
      "        11      183465.4853         519.6331           14.56m\n",
      "        12      180772.1115         432.5763           14.40m\n",
      "        13      178671.1059         383.1650           14.27m\n",
      "        14      176413.1247         326.6192           14.18m\n",
      "        15      174797.8961         291.7553           13.89m\n",
      "        16      173191.8715         272.6771           13.89m\n",
      "        17      171750.6286         220.8924           13.80m\n",
      "        18      170804.2268         193.1545           13.54m\n",
      "        19      169627.7164         178.4973           13.36m\n",
      "        20      168543.4175         154.9973           13.11m\n",
      "        21      167869.4729         142.0016           12.93m\n",
      "        22      166976.7929         117.5971           12.75m\n",
      "        23      166441.7573         109.1058           12.48m\n",
      "        24      165745.3240         107.4412           12.41m\n",
      "        25      165331.3463          85.6149           12.21m\n",
      "        26      164695.8212          85.3263           12.05m\n",
      "        27      164246.2808          71.5859           11.82m\n",
      "        28      163582.1247          66.3335           11.60m\n",
      "        29      163044.0644          57.3668           11.41m\n",
      "        30      162803.8442          53.8519           11.20m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        31      162651.6885          46.2085           11.03m\n",
      "        32      161937.4980          44.1212           10.82m\n",
      "        33      161696.2806          41.8545           10.63m\n",
      "        34      161624.5975          39.5745           10.43m\n",
      "        35      161233.1431          30.7241           10.22m\n",
      "        36      160999.7758          41.9000           10.03m\n",
      "        37      160768.6611          31.0172            9.85m\n",
      "        38      160577.4196          31.1709            9.66m\n",
      "        39      160461.8050          22.0131            9.49m\n",
      "        40      159684.1772          20.8480            9.30m\n",
      "        41      159774.3044          22.3677            9.11m\n",
      "        42      159951.9903          22.0196            8.93m\n",
      "        43      159280.2664          14.3319            8.74m\n",
      "        44      159125.4297          18.4275            8.58m\n",
      "        45      159160.2310          19.3984            8.43m\n",
      "        46      159052.7927          17.3781            8.26m\n",
      "        47      158895.5005          11.6547            8.08m\n",
      "        48      158998.0281          12.0059            7.90m\n",
      "        49      158398.3816          13.8074            7.74m\n",
      "        50      158270.0498          15.4741            7.57m\n",
      "        51      158001.6045          10.8631            7.41m\n",
      "        52      157855.5391          12.5455            7.25m\n",
      "        53      157843.4054          14.7056            7.09m\n",
      "        54      157694.8209           9.1431            6.92m\n",
      "        55      157395.1238          10.9713            6.76m\n",
      "        56      157448.4114          12.3456            6.59m\n",
      "        57      157285.2914           4.5646            6.43m\n",
      "        58      156957.5961           7.3215            6.27m\n",
      "        59      157129.2210           6.0025            6.10m\n",
      "        60      156853.0661           7.6650            5.96m\n",
      "        61      156992.1799           7.1748            5.82m\n",
      "        62      156753.5798           8.0012            5.65m\n",
      "        63      156795.7510           5.7744            5.50m\n",
      "        64      156764.8855           5.6990            5.34m\n",
      "        65      156797.5676           7.3475            5.19m\n",
      "        66      156577.7655           3.5697            5.03m\n",
      "        67      156217.3931           5.2806            4.87m\n",
      "        68      156163.1372           6.7674            4.71m\n",
      "        69      156183.1751           3.9669            4.55m\n",
      "        70      155684.1058           5.1888            4.40m\n",
      "        71      155754.5716          11.1185            4.25m\n",
      "        72      155637.0007           6.8442            4.10m\n",
      "        73      155629.0277           2.1213            3.94m\n",
      "        74      155577.7883           3.2924            3.79m\n",
      "        75      155446.6333           5.3051            3.64m\n",
      "        76      155330.7751           1.9222            3.48m\n",
      "        77      155293.5082           2.1568            3.34m\n",
      "        78      155258.6063           3.4552            3.19m\n",
      "        79      154856.2678          -1.3641            3.04m\n",
      "        80      155365.4378           4.2257            2.89m\n",
      "        81      155164.6594          -0.3310            2.74m\n",
      "        82      154854.5464           1.8483            2.59m\n",
      "        83      154732.0803           7.7446            2.46m\n",
      "        84      155079.5924           2.8228            2.31m\n",
      "        85      154414.9759           3.5077            2.16m\n",
      "        86      154896.9365           9.2773            2.01m\n",
      "        87      154643.9367           1.0207            1.87m\n",
      "        88      154449.4662           1.7506            1.72m\n",
      "        89      154358.9564           1.4868            1.58m\n",
      "        90      154139.5156           1.7871            1.43m\n",
      "        91      154077.5553          -0.6010            1.29m\n",
      "        92      154209.5292          -2.2152            1.14m\n",
      "        93      154224.0456           2.0861           59.89s\n",
      "        94      153998.3937           4.3980           51.29s\n",
      "        95      153934.0411           5.1870           42.69s\n",
      "        96      153804.1170           0.3520           34.10s\n",
      "        97      153439.8591           4.0256           25.54s\n",
      "        98      153676.1048           1.3191           17.01s\n",
      "        99      153395.8987           0.6106            8.50s\n",
      "       100      153613.3167           0.6118            0.00s\n",
      "stage 2: 0.7280679310455113\n",
      "Stage 3:\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1      260374.3710        3647.1838            3.40m\n",
      "         2      244417.7279        2819.4029            3.27m\n",
      "         3      231485.7750        2245.1193            3.21m\n",
      "         4      221134.9875        1776.5862            3.19m\n",
      "         5      212808.5951        1478.9455            3.15m\n",
      "         6      206073.4172        1193.0062            3.10m\n",
      "         7      200440.1695         985.0305            3.04m\n",
      "         8      195931.0805         832.1434            3.02m\n",
      "         9      191555.1539         691.0337            2.99m\n",
      "        10      188412.6191         575.3596            2.96m\n",
      "        11      185302.9610         545.7819            2.94m\n",
      "        12      182570.9711         443.7126            2.92m\n",
      "        13      180609.8060         364.0814            2.90m\n",
      "        14      178344.0991         319.1556            2.89m\n",
      "        15      176720.3135         299.0849            2.87m\n",
      "        16      175207.6407         249.2643            2.85m\n",
      "        17      173747.5867         237.4495            2.83m\n",
      "        18      172998.3339         167.9790            2.80m\n",
      "        19      171865.7953         162.4003            2.78m\n",
      "        20      170551.9936         208.9516            2.76m\n",
      "        21      169920.4742         125.3996            2.73m\n",
      "        22      168857.9514         153.2367            2.71m\n",
      "        23      168168.6427         135.3114            2.68m\n",
      "        24      167513.4388         106.1225            2.65m\n",
      "        25      167046.1529          89.9587            2.61m\n",
      "        26      166443.5230          83.2229            2.58m\n",
      "        27      166036.6143          72.2364            2.55m\n",
      "        28      165302.7985          82.7961            2.52m\n",
      "        29      164800.6412          58.4710            2.49m\n",
      "        30      164579.4835          57.6690            2.46m\n",
      "        31      164445.1358          50.1485            2.42m\n",
      "        32      163615.7475          51.6719            2.38m\n",
      "        33      163392.0483          43.2721            2.34m\n",
      "        34      163292.9157          51.5979            2.31m\n",
      "        35      162688.5721          79.9574            2.28m\n",
      "        36      162464.5261          27.4047            2.24m\n",
      "        37      162254.9322          35.3821            2.21m\n",
      "        38      162043.8642          26.1327            2.18m\n",
      "        39      161790.1713          53.7046            2.15m\n",
      "        40      160994.8547          27.2175            2.11m\n",
      "        41      161103.8131          24.6373            2.07m\n",
      "        42      161237.0471          27.1903            2.03m\n",
      "        43      160590.8492          16.4859            2.00m\n",
      "        44      160327.6697          31.5998            1.96m\n",
      "        45      160306.3884          29.5461            1.93m\n",
      "        46      160228.6157          18.2823            1.90m\n",
      "        47      160006.8241          23.9402            1.86m\n",
      "        48      160120.0056          20.6123            1.83m\n",
      "        49      159477.4611          15.4803            1.79m\n",
      "        50      159376.7715          13.0844            1.75m\n",
      "        51      159137.5970          16.5801            1.71m\n",
      "        52      158917.4295          20.2079            1.68m\n",
      "        53      158975.1186           9.5670            1.64m\n",
      "        54      158803.5788          19.5234            1.60m\n",
      "        55      158465.5719          15.7638            1.57m\n",
      "        56      158548.6612           6.7529            1.53m\n",
      "        57      158431.8198           7.6883            1.49m\n",
      "        58      158036.2317          24.0773            1.46m\n",
      "        59      158205.5570           7.7719            1.43m\n",
      "        60      157918.4746           3.2100            1.39m\n",
      "        61      158099.1546          11.2886            1.36m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        62      157817.0018          15.8444            1.32m\n",
      "        63      157829.9779          13.7327            1.29m\n",
      "        64      157734.1803           8.4775            1.25m\n",
      "        65      157760.0830          16.0029            1.22m\n",
      "        66      157539.2611          11.1498            1.18m\n",
      "        67      157037.7869          24.9820            1.15m\n",
      "        68      157007.0942           4.1191            1.11m\n",
      "        69      157003.5625          11.8693            1.08m\n",
      "        70      156532.3365           7.7500            1.04m\n",
      "        71      156657.7230           6.6248            1.01m\n",
      "        72      156481.1265           9.9868           58.19s\n",
      "        73      156472.4517          11.6450           56.11s\n",
      "        74      156409.4941          11.5859           54.04s\n",
      "        75      156277.8755           7.4734           51.92s\n",
      "        76      156125.9265           8.8934           49.86s\n",
      "        77      156086.3549           2.5482           47.78s\n",
      "        78      156038.7254           1.5000           45.68s\n",
      "        79      155666.0948          14.6334           43.67s\n",
      "        80      156206.8575           0.0282           41.56s\n",
      "        81      155924.0262           7.0884           39.42s\n",
      "        82      155682.7852          -8.9168           37.32s\n",
      "        83      155616.3077           4.5111           35.25s\n",
      "        84      155973.4682           3.4556           33.16s\n",
      "        85      155256.6453           5.4214           31.07s\n",
      "        86      155755.7874           5.7985           28.99s\n",
      "        87      155491.6370           2.1472           26.90s\n",
      "        88      155301.5532           7.7532           24.84s\n",
      "        89      155199.2179           7.1514           22.76s\n",
      "        90      154964.0696           2.3695           20.67s\n",
      "        91      154903.1369           8.1538           18.61s\n",
      "        92      155039.2023           6.1323           16.53s\n",
      "        93      154984.6052           7.6228           14.46s\n",
      "        94      154807.8607           7.6165           12.40s\n",
      "        95      154692.3869           1.5771           10.32s\n",
      "        96      154641.9524          -0.4080            8.25s\n",
      "        97      154268.8641           6.2470            6.19s\n",
      "        98      154464.5327           8.1122            4.13s\n",
      "        99      154167.3542           0.5318            2.07s\n",
      "       100      154361.6261           4.4950            0.00s\n",
      "stage 3: 0.7280519397447789\n",
      "Stage 4:\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1      381157.5920        3776.9273            5.02m\n",
      "         2      364473.4989        2947.4411            4.98m\n",
      "         3      351001.9438        2363.5402            4.96m\n",
      "         4      339680.6466        1969.3262            4.93m\n",
      "         5      330613.8438        1613.7791            4.85m\n",
      "         6      322862.6173        1324.3682            4.78m\n",
      "         7      316242.4448        1191.3881            4.72m\n",
      "         8      310481.3274        1023.9203            4.68m\n",
      "         9      305625.2949         830.4493            4.62m\n",
      "        10      301806.8696         693.2476            4.55m\n",
      "        11      298181.4578         615.2237            4.56m\n",
      "        12      294733.1487         577.4958            4.53m\n",
      "        13      291946.0778         460.2483            4.48m\n",
      "        14      289560.7158         454.3082            4.45m\n",
      "        15      287359.8980         380.6899            4.40m\n",
      "        16      285451.5145         359.9921            4.36m\n",
      "        17      283426.0590         283.2654            4.31m\n",
      "        18      281553.3768         289.9523            4.26m\n",
      "        19      280281.3949         254.8394            4.22m\n",
      "        20      278909.2044         208.3188            4.17m\n",
      "        21      277515.5691         283.5273            4.13m\n",
      "        22      276100.7255         173.3856            4.09m\n",
      "        23      275305.4605         178.0682            4.04m\n",
      "        24      273957.1702         201.5922            4.01m\n",
      "        25      273287.0663         118.0532            3.95m\n",
      "        26      272205.1439         165.9056            3.91m\n",
      "        27      271019.5180         155.8125            3.86m\n",
      "        28      270734.7800         137.1294            3.81m\n",
      "        29      269831.1053          94.6288            3.76m\n",
      "        30      269417.5588          78.8551            3.71m\n",
      "        31      269038.8096          75.4611            3.66m\n",
      "        32      267839.5694          99.0422            3.61m\n",
      "        33      267641.5589          72.5529            3.55m\n",
      "        34      267244.1471          92.0027            3.49m\n",
      "        35      266488.6874          56.9468            3.43m\n",
      "        36      266444.8375          61.7893            3.38m\n",
      "        37      265447.1233          90.3842            3.34m\n",
      "        38      265134.8894          96.9723            3.29m\n",
      "        39      264874.0819          45.2342            3.24m\n",
      "        40      264562.9121          58.3544            3.18m\n",
      "        41      263972.2790          49.5993            3.12m\n",
      "        42      264083.6341          66.7107            3.07m\n",
      "        43      263401.5855          55.3711            3.01m\n",
      "        44      262819.8780          50.1268            2.96m\n",
      "        45      262782.8532          50.5117            2.91m\n",
      "        46      262298.2449          62.3581            2.85m\n",
      "        47      262015.9443          28.0015            2.79m\n",
      "        48      261623.4672          39.9264            2.74m\n",
      "        49      261205.3562          56.6647            2.69m\n",
      "        50      260719.3709          45.1307            2.64m\n",
      "        51      260904.0982          25.2527            2.59m\n",
      "        52      260370.6214          23.3701            2.54m\n",
      "        53      260135.1750          40.2675            2.49m\n",
      "        54      259940.1500          30.8101            2.43m\n",
      "        55      259796.8012          30.1496            2.38m\n",
      "        56      259295.5809          31.3924            2.32m\n",
      "        57      259051.4958          29.7375            2.27m\n",
      "        58      259095.7330          21.1090            2.21m\n",
      "        59      258741.2544          41.7393            2.16m\n",
      "        60      258462.2754          17.9870            2.10m\n",
      "        61      258610.0538          27.2524            2.05m\n",
      "        62      258143.6291          25.2604            2.00m\n",
      "        63      257819.0711          24.4537            1.95m\n",
      "        64      258015.9028          17.4708            1.89m\n",
      "        65      257295.7255          23.4282            1.84m\n",
      "        66      257730.3950          30.6577            1.78m\n",
      "        67      257308.7642          26.3247            1.73m\n",
      "        68      257341.7003          12.9974            1.68m\n",
      "        69      256956.7112          19.1001            1.62m\n",
      "        70      256881.8190          16.5370            1.57m\n",
      "        71      256871.3615          15.3773            1.52m\n",
      "        72      256497.7307          19.4064            1.47m\n",
      "        73      256384.6821           9.8807            1.41m\n",
      "        74      256177.0208          15.1390            1.36m\n",
      "        75      256149.9025          27.9389            1.31m\n",
      "        76      256155.4754          14.6301            1.26m\n",
      "        77      255733.5077           8.9390            1.20m\n",
      "        78      255595.4960          20.5679            1.15m\n",
      "        79      255612.1138          25.6787            1.10m\n",
      "        80      255176.6966          15.5483            1.04m\n",
      "        81      254924.6539          15.5059           59.58s\n",
      "        82      254885.7035          19.4049           56.45s\n",
      "        83      254782.3280           7.8765           53.32s\n",
      "        84      254698.4045          12.9667           50.17s\n",
      "        85      254807.7147          18.4988           46.99s\n",
      "        86      254318.1092          12.6602           43.80s\n",
      "        87      254143.4296           9.9789           40.71s\n",
      "        88      254062.2226          19.5381           37.59s\n",
      "        89      254001.1210           8.2581           34.46s\n",
      "        90      254002.5501          10.3987           31.30s\n",
      "        91      254047.0077          11.6731           28.16s\n",
      "        92      253968.2868          15.1027           25.04s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        93      253390.3753          27.7840           21.93s\n",
      "        94      253127.0060          28.7590           18.81s\n",
      "        95      253278.3873          12.8418           15.67s\n",
      "        96      252922.5937          13.9353           12.55s\n",
      "        97      253221.1126           8.2895            9.42s\n",
      "        98      252699.7726          15.3596            6.28s\n",
      "        99      252634.8926           9.1583            3.14s\n",
      "       100      252370.8124          19.0865            0.00s\n",
      "stage 4: 0.7090542744746857\n",
      "Stage 5:\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1      259025.3294        3609.1022            3.17m\n",
      "         2      243154.4236        2779.3629            3.17m\n",
      "         3      230605.3140        2208.2835            3.13m\n",
      "         4      220331.4866        1788.0763            3.11m\n",
      "         5      212011.8174        1462.9877            3.08m\n",
      "         6      205069.1404        1198.5737            3.04m\n",
      "         7      199518.6593         975.0681            3.00m\n",
      "         8      195003.9416         823.7411            2.97m\n",
      "         9      190861.4571         731.8010            2.95m\n",
      "        10      187527.7030         586.2466            2.92m\n",
      "        11      184514.9753         497.9265            2.91m\n",
      "        12      182089.2181         429.0191            2.89m\n",
      "        13      179900.7879         356.8374            2.88m\n",
      "        14      177732.6149         350.0103            2.87m\n",
      "        15      176168.5811         273.9649            2.85m\n",
      "        16      174899.3373         248.3787            2.83m\n",
      "        17      173370.4840         237.5773            2.80m\n",
      "        18      172227.7322         228.8473            2.78m\n",
      "        19      170928.5889         158.9014            2.76m\n",
      "        20      170176.6906         144.0992            2.74m\n",
      "        21      169162.9557         133.6888            2.71m\n",
      "        22      168418.9115         137.8132            2.68m\n",
      "        23      167831.9114         107.9137            2.65m\n",
      "        24      166914.9047         111.5061            2.62m\n",
      "        25      166654.5153         109.0509            2.59m\n",
      "        26      166099.1607          77.6809            2.56m\n",
      "        27      165500.8080          89.2869            2.53m\n",
      "        28      164801.0479          61.2512            2.49m\n",
      "        29      164229.4846          53.8954            2.46m\n",
      "        30      163990.1072          64.7607            2.42m\n",
      "        31      163436.7984          65.2775            2.39m\n",
      "        32      163205.5213          64.1459            2.35m\n",
      "        33      162608.3304          54.8514            2.32m\n",
      "        34      162732.0370          34.4033            2.28m\n",
      "        35      162065.1588          63.1942            2.25m\n",
      "        36      161738.7714          32.0076            2.22m\n",
      "        37      161618.5886          55.1244            2.18m\n",
      "        38      161284.4617          26.2503            2.14m\n",
      "        39      160884.6496          45.5171            2.11m\n",
      "        40      160738.3777          60.2805            2.08m\n",
      "        41      160420.8130          25.0440            2.05m\n",
      "        42      159927.0883          35.2521            2.01m\n",
      "        43      159905.6321          25.6130            1.98m\n",
      "        44      159659.3944          22.1259            1.95m\n",
      "        45      159435.3034          28.6326            1.91m\n",
      "        46      159245.9880          40.3234            1.88m\n",
      "        47      159406.6072          10.3302            1.84m\n",
      "        48      158905.6389          23.2957            1.80m\n",
      "        49      158754.6078          14.9203            1.77m\n",
      "        50      158470.9749           9.2770            1.73m\n",
      "        51      158227.5888          23.1318            1.69m\n",
      "        52      158213.0190          16.1779            1.66m\n",
      "        53      158140.6303          10.2609            1.63m\n",
      "        54      158039.2687          16.8441            1.59m\n",
      "        55      157713.3785          18.1726            1.56m\n",
      "        56      157630.3397          24.5796            1.52m\n",
      "        57      157504.3623          17.6003            1.49m\n",
      "        58      157694.4514           4.7165            1.45m\n",
      "        59      157359.0217           7.4076            1.42m\n",
      "        60      157436.0895           9.7368            1.38m\n",
      "        61      157065.6213          14.2981            1.34m\n",
      "        62      156801.9327           7.8466            1.31m\n",
      "        63      157049.4944          24.4614            1.27m\n",
      "        64      156497.0698          13.0708            1.24m\n",
      "        65      156781.3285           4.8623            1.21m\n",
      "        66      156689.5918          12.5370            1.17m\n",
      "        67      156353.4824          11.2611            1.14m\n",
      "        68      156333.4320          10.1281            1.10m\n",
      "        69      155969.6195          11.3349            1.07m\n",
      "        70      156205.6465           4.0991            1.03m\n",
      "        71      155754.5110          10.5377           59.85s\n",
      "        72      155695.0106          10.4916           57.76s\n",
      "        73      155427.0611           2.0375           55.68s\n",
      "        74      155664.7545           1.2672           53.67s\n",
      "        75      155304.8247           6.4431           51.57s\n",
      "        76      155503.7330          10.6453           49.52s\n",
      "        77      155401.5280           9.2245           47.46s\n",
      "        78      155228.9034          10.5020           45.41s\n",
      "        79      155302.9742           5.6525           43.35s\n",
      "        80      155054.9672           7.5994           41.28s\n",
      "        81      154928.2341           3.7001           39.21s\n",
      "        82      155021.3250           7.7812           37.17s\n",
      "        83      154674.5565           2.8990           35.08s\n",
      "        84      154678.8407           4.2847           33.00s\n",
      "        85      154719.4275           4.9930           30.91s\n",
      "        86      154122.8262           3.6350           28.85s\n",
      "        87      154593.1130           8.8608           26.77s\n",
      "        88      154471.3162           3.5902           24.71s\n",
      "        89      154109.9454           3.0732           22.62s\n",
      "        90      154215.0047           2.1721           20.55s\n",
      "        91      154034.1494           1.6978           18.49s\n",
      "        92      153914.1810           3.2833           16.42s\n",
      "        93      154029.1726           4.4491           14.37s\n",
      "        94      153777.6290           5.6609           12.32s\n",
      "        95      153665.1756           2.4344           10.26s\n",
      "        96      153828.5289           3.0043            8.20s\n",
      "        97      153701.5312           8.7984            6.15s\n",
      "        98      153605.5480           8.9057            4.10s\n",
      "        99      153414.1129           5.6760            2.05s\n",
      "       100      153341.1223           0.4842            0.00s\n",
      "stage 5: 0.704560718968881\n",
      "Stage 7:\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1      260249.5521        3624.4643            3.08m\n",
      "         2      244299.1586        2805.8043            3.04m\n",
      "         3      231584.5606        2251.4017            3.01m\n",
      "         4      221260.3725        1789.0924            3.00m\n",
      "         5      212873.4255        1464.4100            2.97m\n",
      "         6      206165.9739        1202.8292            2.94m\n",
      "         7      200496.1703        1010.5174            2.90m\n",
      "         8      195892.4400         821.6126            2.87m\n",
      "         9      191301.1367         721.3521            2.85m\n",
      "        10      187927.6617         603.0384            2.84m\n",
      "        11      185099.7410         490.8312            2.82m\n",
      "        12      182981.5227         432.7584            2.80m\n",
      "        13      180694.2934         362.1889            2.78m\n",
      "        14      178480.7488         333.9540            2.77m\n",
      "        15      176924.1240         270.5937            2.74m\n",
      "        16      175327.6527         268.6377            2.72m\n",
      "        17      174024.0971         214.9178            2.69m\n",
      "        18      172979.2739         198.4791            2.69m\n",
      "        19      171915.5300         171.8952            2.66m\n",
      "        20      171189.4767         133.7389            2.63m\n",
      "        21      170031.4478         138.8985            2.59m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        22      169126.2437         154.8284            2.57m\n",
      "        23      168583.7932         124.6246            2.54m\n",
      "        24      167668.8186         119.6037            2.52m\n",
      "        25      167143.2222         106.4544            2.49m\n",
      "        26      166683.9643          78.9303            2.46m\n",
      "        27      166076.2753          92.6175            2.42m\n",
      "        28      165514.6066          64.9475            2.39m\n",
      "        29      165246.4616          58.1935            2.36m\n",
      "        30      164735.0308          74.4801            2.33m\n",
      "        31      164306.6895          69.4609            2.29m\n",
      "        32      163653.3621          61.1924            2.26m\n",
      "        33      163441.5995          47.7971            2.23m\n",
      "        34      163306.6831          32.2378            2.19m\n",
      "        35      162913.4514          52.1031            2.16m\n",
      "        36      162904.5780          37.2692            2.12m\n",
      "        37      162531.7841          35.1588            2.09m\n",
      "        38      161993.5005          49.4393            2.06m\n",
      "        39      161694.6116          34.6376            2.03m\n",
      "        40      161482.3542          45.0250            2.00m\n",
      "        41      161320.0302          19.9920            1.96m\n",
      "        42      161248.1095          28.1058            1.93m\n",
      "        43      161275.3104          16.0586            1.89m\n",
      "        44      160774.6297          23.7892            1.86m\n",
      "        45      160806.7194          31.0383            1.83m\n",
      "        46      160327.5324          25.0440            1.79m\n",
      "        47      160040.4321          32.7584            1.76m\n",
      "        48      160118.6205          16.5399            1.73m\n",
      "        49      159392.4459          11.9846            1.69m\n",
      "        50      159765.4323          16.8354            1.66m\n",
      "        51      159440.0798          22.1573            1.62m\n",
      "        52      159227.3304          11.7239            1.59m\n",
      "        53      159321.3845           7.2328            1.55m\n",
      "        54      159217.5770          15.0230            1.52m\n",
      "        55      158917.5627          18.0669            1.49m\n",
      "        56      158620.9679           7.3727            1.45m\n",
      "        57      158879.4447          16.4494            1.42m\n",
      "        58      158097.8974           5.1784            1.39m\n",
      "        59      158606.1722          18.6763            1.35m\n",
      "        60      158355.9912          21.7181            1.32m\n",
      "        61      158238.5561           9.9036            1.29m\n",
      "        62      157912.8784          15.5216            1.26m\n",
      "        63      157867.4075          18.6007            1.23m\n",
      "        64      157754.1324          11.8882            1.19m\n",
      "        65      157614.3405           4.4348            1.16m\n",
      "        66      157177.9604          10.9615            1.13m\n",
      "        67      157196.0089           6.9695            1.09m\n",
      "        68      157169.0155           2.7345            1.06m\n",
      "        69      157252.3105           5.9426            1.02m\n",
      "        70      157100.8630          11.9447           59.35s\n",
      "        71      156975.4734           5.1052           57.38s\n",
      "        72      156842.9397           2.2191           55.33s\n",
      "        73      156916.6604          10.5400           53.31s\n",
      "        74      156556.7600           6.5238           51.24s\n",
      "        75      156203.9704          11.1225           49.29s\n",
      "        76      156629.9763          10.3036           47.36s\n",
      "        77      156459.9347          11.6016           45.35s\n",
      "        78      156260.6152           6.1014           43.34s\n",
      "        79      156127.1058           6.0064           41.39s\n",
      "        80      156197.6945           6.1391           39.42s\n",
      "        81      156279.9754           4.5608           37.42s\n",
      "        82      156002.0548           3.5799           35.45s\n",
      "        83      156007.8798           7.3832           33.47s\n",
      "        84      155700.6268           3.8255           31.47s\n",
      "        85      155590.3266           1.8662           29.51s\n",
      "        86      155652.2523           0.4142           27.52s\n",
      "        87      155534.2676           3.0236           25.56s\n",
      "        88      155751.9947           2.5809           23.56s\n",
      "        89      155649.5367           2.8185           21.60s\n",
      "        90      155218.3132          -0.0336           19.63s\n",
      "        91      155458.9524           1.7052           17.66s\n",
      "        92      155421.6263           5.4354           15.71s\n",
      "        93      155163.6328           1.9445           13.74s\n",
      "        94      155086.0969           9.6269           11.79s\n",
      "        95      155170.0091           3.4328            9.82s\n",
      "        96      154876.5592           3.0619            7.85s\n",
      "        97      154716.9835           0.0993            5.89s\n",
      "        98      154813.6257           1.8846            3.92s\n",
      "        99      154565.2980           6.3943            1.96s\n",
      "       100      154643.3114           1.5714            0.00s\n",
      "stage 7: 0.727810650887574\n"
     ]
    }
   ],
   "source": [
    "# Test model against other stage test sets\n",
    "for i in range(1, 8):\n",
    "    if i == 6:\n",
    "        continue\n",
    "    print('Stage {}:'.format(i))\n",
    "    with open('./data/stage{}-train.pkl'.format(i), 'rb') as ftrain:\n",
    "        X_train = pickle.load(ftrain)\n",
    "        y_train = X_train.pop('stop_outcome')\n",
    "        with open('./data/stage{}-test.pkl'.format(i), 'rb') as ftest:\n",
    "            X_test = pickle.load(ftest)\n",
    "            y_test = X_test.pop('stop_outcome')\n",
    "            gbc = GradientBoostingClassifier(criterion='mse', learning_rate=0.1, max_depth=5,\n",
    "                                             max_features=X_train.columns.values.shape[0], subsample=0.85,\n",
    "                                             verbose=3, random_state=0)\n",
    "            gbc.fit(X_train, y_train)\n",
    "            print('stage {}: {}'.format(i, gbc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T03:45:28.914285Z",
     "start_time": "2018-05-25T03:45:28.514123Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "Confusion matrix, without normalization\n",
      "[[13  0  0]\n",
      " [ 0 10  6]\n",
      " [ 0  0  9]]\n",
      "Normalized confusion matrix\n",
      "[[ 1.    0.    0.  ]\n",
      " [ 0.    0.62  0.38]\n",
      " [ 0.    0.    1.  ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVAAAAEmCAYAAAA0k8gFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/w8Zm4AIys4fgAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc090580240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVMAAAEmCAYAAADfpHMGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc090551240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "class_names = iris.target_names\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Run classifier, using a model that is too regularized (C too low) to see\n",
    "# the impact on the results\n",
    "classifier = svm.SVC(kernel='linear', C=0.01)\n",
    "y_pred = classifier.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
