{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T20:39:22.943363Z",
     "start_time": "2018-05-04T16:39:22.909274-04:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import humanize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T20:39:23.743524Z",
     "start_time": "2018-05-04T16:39:22.944386-04:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_features = pd.read_csv('./final_features.csv', header=0, index_col=0)\n",
    "outcomes = pd.read_csv('./labels.csv', header=None, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T20:39:23.749508Z",
     "start_time": "2018-05-04T16:39:23.744493-04:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313274, 1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T20:39:23.759534Z",
     "start_time": "2018-05-04T16:39:23.750511-04:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313274, 43)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T20:39:23.783597Z",
     "start_time": "2018-05-04T16:39:23.760537-04:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driver_age_raw</th>\n",
       "      <th>search_conducted</th>\n",
       "      <th>contraband_found</th>\n",
       "      <th>is_male</th>\n",
       "      <th>violation_cell_phone</th>\n",
       "      <th>violation_display_of_plates</th>\n",
       "      <th>violation_equipment</th>\n",
       "      <th>violation_incomplete_stop</th>\n",
       "      <th>violation_license</th>\n",
       "      <th>violation_lights</th>\n",
       "      <th>...</th>\n",
       "      <th>stop_duration_16-30 min</th>\n",
       "      <th>stop_duration_30+ min</th>\n",
       "      <th>day_period_Afternoon</th>\n",
       "      <th>day_period_Evening</th>\n",
       "      <th>day_period_Morning</th>\n",
       "      <th>day_period_Small Hours</th>\n",
       "      <th>season_Fall</th>\n",
       "      <th>season_Spring</th>\n",
       "      <th>season_Summer</th>\n",
       "      <th>season_Winter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.69697</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   driver_age_raw  search_conducted  contraband_found  is_male  \\\n",
       "0         0.69697                 0                 0        0   \n",
       "\n",
       "   violation_cell_phone  violation_display_of_plates  violation_equipment  \\\n",
       "0                     0                            0                    0   \n",
       "\n",
       "   violation_incomplete_stop  violation_license  violation_lights  \\\n",
       "0                          0                  0                 0   \n",
       "\n",
       "       ...        stop_duration_16-30 min  stop_duration_30+ min  \\\n",
       "0      ...                              0                      0   \n",
       "\n",
       "   day_period_Afternoon  day_period_Evening  day_period_Morning  \\\n",
       "0                     0                   0                   0   \n",
       "\n",
       "   day_period_Small Hours  season_Fall  season_Spring  season_Summer  \\\n",
       "0                       1            1              0              0   \n",
       "\n",
       "   season_Winter  \n",
       "0              0  \n",
       "\n",
       "[1 rows x 43 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_features.iloc[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T20:39:23.799641Z",
     "start_time": "2018-05-04T16:39:23.784602-04:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driver_age_raw</th>\n",
       "      <th>search_conducted</th>\n",
       "      <th>contraband_found</th>\n",
       "      <th>is_male</th>\n",
       "      <th>violation_cell_phone</th>\n",
       "      <th>violation_display_of_plates</th>\n",
       "      <th>violation_equipment</th>\n",
       "      <th>violation_incomplete_stop</th>\n",
       "      <th>violation_license</th>\n",
       "      <th>violation_lights</th>\n",
       "      <th>...</th>\n",
       "      <th>stop_duration_16-30 min</th>\n",
       "      <th>stop_duration_30+ min</th>\n",
       "      <th>day_period_Afternoon</th>\n",
       "      <th>day_period_Evening</th>\n",
       "      <th>day_period_Morning</th>\n",
       "      <th>day_period_Small Hours</th>\n",
       "      <th>season_Fall</th>\n",
       "      <th>season_Spring</th>\n",
       "      <th>season_Summer</th>\n",
       "      <th>season_Winter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>318668</th>\n",
       "      <td>0.191919</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        driver_age_raw  search_conducted  contraband_found  is_male  \\\n",
       "318668        0.191919                 0                 0        1   \n",
       "\n",
       "        violation_cell_phone  violation_display_of_plates  \\\n",
       "318668                     0                            0   \n",
       "\n",
       "        violation_equipment  violation_incomplete_stop  violation_license  \\\n",
       "318668                    0                          0                  0   \n",
       "\n",
       "        violation_lights      ...        stop_duration_16-30 min  \\\n",
       "318668                 0      ...                              0   \n",
       "\n",
       "        stop_duration_30+ min  day_period_Afternoon  day_period_Evening  \\\n",
       "318668                      0                     1                   0   \n",
       "\n",
       "        day_period_Morning  day_period_Small Hours  season_Fall  \\\n",
       "318668                   0                       0            0   \n",
       "\n",
       "        season_Spring  season_Summer  season_Winter  \n",
       "318668              1              0              0  \n",
       "\n",
       "[1 rows x 43 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_features.iloc[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T20:39:23.807663Z",
     "start_time": "2018-05-04T16:39:23.800642-04:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>318668</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             1\n",
       "0             \n",
       "318668  Ticket"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes.iloc[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T20:39:23.822701Z",
     "start_time": "2018-05-04T16:39:23.808664-04:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Verbal Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Written Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Verbal Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Verbal Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Verbal Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Verbal Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Verbal Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Verbal Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Verbal Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Verbal Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Verbal Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Verbal Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Written Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Verbal Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318639</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318640</th>\n",
       "      <td>Verbal Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318641</th>\n",
       "      <td>Verbal Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318642</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318643</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318644</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318645</th>\n",
       "      <td>Verbal Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318646</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318647</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318648</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318649</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318650</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318651</th>\n",
       "      <td>Verbal Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318652</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318653</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318654</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318655</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318656</th>\n",
       "      <td>Arrest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318657</th>\n",
       "      <td>Verbal Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318658</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318659</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318660</th>\n",
       "      <td>Verbal Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318661</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318662</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318663</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318664</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318665</th>\n",
       "      <td>Written Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318666</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318667</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318668</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>313274 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      1\n",
       "0                      \n",
       "0                Ticket\n",
       "1        Verbal Warning\n",
       "2                Ticket\n",
       "3       Written Warning\n",
       "4                Ticket\n",
       "5        Verbal Warning\n",
       "6                Ticket\n",
       "7        Verbal Warning\n",
       "8                Ticket\n",
       "9        Verbal Warning\n",
       "10               Ticket\n",
       "11       Verbal Warning\n",
       "12       Verbal Warning\n",
       "13               Ticket\n",
       "14               Ticket\n",
       "15               Ticket\n",
       "16       Verbal Warning\n",
       "17       Verbal Warning\n",
       "18       Verbal Warning\n",
       "19               Ticket\n",
       "20       Verbal Warning\n",
       "21       Verbal Warning\n",
       "22               Ticket\n",
       "23               Ticket\n",
       "24               Ticket\n",
       "25               Ticket\n",
       "26      Written Warning\n",
       "27               Ticket\n",
       "28       Verbal Warning\n",
       "29               Ticket\n",
       "...                 ...\n",
       "318639           Ticket\n",
       "318640   Verbal Warning\n",
       "318641   Verbal Warning\n",
       "318642           Ticket\n",
       "318643           Ticket\n",
       "318644           Ticket\n",
       "318645   Verbal Warning\n",
       "318646           Ticket\n",
       "318647           Ticket\n",
       "318648           Ticket\n",
       "318649           Ticket\n",
       "318650           Ticket\n",
       "318651   Verbal Warning\n",
       "318652           Ticket\n",
       "318653           Ticket\n",
       "318654           Ticket\n",
       "318655           Ticket\n",
       "318656           Arrest\n",
       "318657   Verbal Warning\n",
       "318658           Ticket\n",
       "318659           Ticket\n",
       "318660   Verbal Warning\n",
       "318661           Ticket\n",
       "318662           Ticket\n",
       "318663           Ticket\n",
       "318664           Ticket\n",
       "318665  Written Warning\n",
       "318666           Ticket\n",
       "318667           Ticket\n",
       "318668           Ticket\n",
       "\n",
       "[313274 rows x 1 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T20:39:23.840750Z",
     "start_time": "2018-05-04T16:39:23.823706-04:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driver_age_raw</th>\n",
       "      <th>search_conducted</th>\n",
       "      <th>contraband_found</th>\n",
       "      <th>is_male</th>\n",
       "      <th>violation_cell_phone</th>\n",
       "      <th>violation_display_of_plates</th>\n",
       "      <th>violation_equipment</th>\n",
       "      <th>violation_incomplete_stop</th>\n",
       "      <th>violation_license</th>\n",
       "      <th>violation_lights</th>\n",
       "      <th>...</th>\n",
       "      <th>stop_duration_16-30 min</th>\n",
       "      <th>stop_duration_30+ min</th>\n",
       "      <th>day_period_Afternoon</th>\n",
       "      <th>day_period_Evening</th>\n",
       "      <th>day_period_Morning</th>\n",
       "      <th>day_period_Small Hours</th>\n",
       "      <th>season_Fall</th>\n",
       "      <th>season_Spring</th>\n",
       "      <th>season_Summer</th>\n",
       "      <th>season_Winter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.696970</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.202020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.343434</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.464646</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.303030</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   driver_age_raw  search_conducted  contraband_found  is_male  \\\n",
       "0        0.696970                 0                 0        0   \n",
       "1        0.202020                 0                 0        1   \n",
       "2        0.343434                 0                 0        1   \n",
       "3        0.464646                 0                 0        1   \n",
       "4        0.303030                 0                 0        1   \n",
       "\n",
       "   violation_cell_phone  violation_display_of_plates  violation_equipment  \\\n",
       "0                     0                            0                    0   \n",
       "1                     0                            0                    0   \n",
       "2                     0                            0                    0   \n",
       "3                     0                            0                    0   \n",
       "4                     0                            0                    0   \n",
       "\n",
       "   violation_incomplete_stop  violation_license  violation_lights  \\\n",
       "0                          0                  0                 0   \n",
       "1                          0                  0                 0   \n",
       "2                          0                  0                 0   \n",
       "3                          0                  0                 0   \n",
       "4                          0                  0                 0   \n",
       "\n",
       "       ...        stop_duration_16-30 min  stop_duration_30+ min  \\\n",
       "0      ...                              0                      0   \n",
       "1      ...                              0                      0   \n",
       "2      ...                              0                      0   \n",
       "3      ...                              0                      0   \n",
       "4      ...                              0                      0   \n",
       "\n",
       "   day_period_Afternoon  day_period_Evening  day_period_Morning  \\\n",
       "0                     0                   0                   0   \n",
       "1                     0                   0                   0   \n",
       "2                     0                   0                   0   \n",
       "3                     0                   0                   0   \n",
       "4                     0                   0                   0   \n",
       "\n",
       "   day_period_Small Hours  season_Fall  season_Spring  season_Summer  \\\n",
       "0                       1            1              0              0   \n",
       "1                       1            1              0              0   \n",
       "2                       1            1              0              0   \n",
       "3                       1            1              0              0   \n",
       "4                       1            1              0              0   \n",
       "\n",
       "   season_Winter  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T20:39:24.003181Z",
     "start_time": "2018-05-04T16:39:23.841753-04:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 313274 entries, 0 to 318668\n",
      "Data columns (total 43 columns):\n",
      "driver_age_raw                      313274 non-null float64\n",
      "search_conducted                    313274 non-null int64\n",
      "contraband_found                    313274 non-null int64\n",
      "is_male                             313274 non-null int64\n",
      "violation_cell_phone                313274 non-null int64\n",
      "violation_display_of_plates         313274 non-null int64\n",
      "violation_equipment                 313274 non-null int64\n",
      "violation_incomplete_stop           313274 non-null int64\n",
      "violation_license                   313274 non-null int64\n",
      "violation_lights                    313274 non-null int64\n",
      "violation_moving_violation          313274 non-null int64\n",
      "violation_other                     313274 non-null int64\n",
      "violation_registration              313274 non-null int64\n",
      "violation_safe_movement             313274 non-null int64\n",
      "violation_seatbelt                  313274 non-null int64\n",
      "violation_speeding                  313274 non-null int64\n",
      "violation_suspended_license         313274 non-null int64\n",
      "violation_traffic_control_signal    313274 non-null int64\n",
      "violation_window_tint               313274 non-null int64\n",
      "county_name_Fairfield County        313274 non-null int64\n",
      "county_name_Hartford County         313274 non-null int64\n",
      "county_name_Litchfield County       313274 non-null int64\n",
      "county_name_Middlesex County        313274 non-null int64\n",
      "county_name_New Haven County        313274 non-null int64\n",
      "county_name_New London County       313274 non-null int64\n",
      "county_name_Tolland County          313274 non-null int64\n",
      "county_name_Windham County          313274 non-null int64\n",
      "driver_race_Asian                   313274 non-null int64\n",
      "driver_race_Black                   313274 non-null int64\n",
      "driver_race_Hispanic                313274 non-null int64\n",
      "driver_race_Other                   313274 non-null int64\n",
      "driver_race_White                   313274 non-null int64\n",
      "stop_duration_1-15 min              313274 non-null int64\n",
      "stop_duration_16-30 min             313274 non-null int64\n",
      "stop_duration_30+ min               313274 non-null int64\n",
      "day_period_Afternoon                313274 non-null int64\n",
      "day_period_Evening                  313274 non-null int64\n",
      "day_period_Morning                  313274 non-null int64\n",
      "day_period_Small Hours              313274 non-null int64\n",
      "season_Fall                         313274 non-null int64\n",
      "season_Spring                       313274 non-null int64\n",
      "season_Summer                       313274 non-null int64\n",
      "season_Winter                       313274 non-null int64\n",
      "dtypes: float64(1), int64(42)\n",
      "memory usage: 105.2 MB\n"
     ]
    }
   ],
   "source": [
    "final_features.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T20:39:24.753203Z",
     "start_time": "2018-05-04T16:39:24.004184-04:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driver_age_raw</th>\n",
       "      <th>search_conducted</th>\n",
       "      <th>contraband_found</th>\n",
       "      <th>is_male</th>\n",
       "      <th>violation_cell_phone</th>\n",
       "      <th>violation_display_of_plates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.384508</td>\n",
       "      <td>0.016848</td>\n",
       "      <td>0.005771</td>\n",
       "      <td>0.663946</td>\n",
       "      <td>0.063890</td>\n",
       "      <td>0.018415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.145742</td>\n",
       "      <td>0.128701</td>\n",
       "      <td>0.075750</td>\n",
       "      <td>0.472358</td>\n",
       "      <td>0.244557</td>\n",
       "      <td>0.134447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.262626</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.353535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.494949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       driver_age_raw  search_conducted  contraband_found        is_male  \\\n",
       "count   313274.000000     313274.000000     313274.000000  313274.000000   \n",
       "mean         0.384508          0.016848          0.005771       0.663946   \n",
       "std          0.145742          0.128701          0.075750       0.472358   \n",
       "min          0.000000          0.000000          0.000000       0.000000   \n",
       "25%          0.262626          0.000000          0.000000       0.000000   \n",
       "50%          0.353535          0.000000          0.000000       1.000000   \n",
       "75%          0.494949          0.000000          0.000000       1.000000   \n",
       "max          1.000000          1.000000          1.000000       1.000000   \n",
       "\n",
       "       violation_cell_phone  violation_display_of_plates  \n",
       "count         313274.000000                313274.000000  \n",
       "mean               0.063890                     0.018415  \n",
       "std                0.244557                     0.134447  \n",
       "min                0.000000                     0.000000  \n",
       "25%                0.000000                     0.000000  \n",
       "50%                0.000000                     0.000000  \n",
       "75%                0.000000                     0.000000  \n",
       "max                1.000000                     1.000000  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description = final_features.describe()\n",
    "description.iloc[:,:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T20:39:24.758203Z",
     "start_time": "2018-05-04T16:39:24.754179-04:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['driver_age_raw', 'search_conducted', 'contraband_found', 'is_male',\n",
       "       'violation_cell_phone', 'violation_display_of_plates',\n",
       "       'violation_equipment', 'violation_incomplete_stop',\n",
       "       'violation_license', 'violation_lights',\n",
       "       'violation_moving_violation', 'violation_other',\n",
       "       'violation_registration', 'violation_safe_movement',\n",
       "       'violation_seatbelt', 'violation_speeding',\n",
       "       'violation_suspended_license', 'violation_traffic_control_signal',\n",
       "       'violation_window_tint', 'county_name_Fairfield County',\n",
       "       'county_name_Hartford County', 'county_name_Litchfield County',\n",
       "       'county_name_Middlesex County', 'county_name_New Haven County',\n",
       "       'county_name_New London County', 'county_name_Tolland County',\n",
       "       'county_name_Windham County', 'driver_race_Asian',\n",
       "       'driver_race_Black', 'driver_race_Hispanic', 'driver_race_Other',\n",
       "       'driver_race_White', 'stop_duration_1-15 min',\n",
       "       'stop_duration_16-30 min', 'stop_duration_30+ min',\n",
       "       'day_period_Afternoon', 'day_period_Evening', 'day_period_Morning',\n",
       "       'day_period_Small Hours', 'season_Fall', 'season_Spring',\n",
       "       'season_Summer', 'season_Winter'], dtype=object)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T20:39:24.776238Z",
     "start_time": "2018-05-04T16:39:24.759191-04:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>violation_equipment</th>\n",
       "      <th>violation_incomplete_stop</th>\n",
       "      <th>violation_license</th>\n",
       "      <th>violation_lights</th>\n",
       "      <th>violation_moving_violation</th>\n",
       "      <th>violation_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.009442</td>\n",
       "      <td>0.022673</td>\n",
       "      <td>0.009366</td>\n",
       "      <td>0.038647</td>\n",
       "      <td>0.089133</td>\n",
       "      <td>0.278989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.096711</td>\n",
       "      <td>0.148860</td>\n",
       "      <td>0.096322</td>\n",
       "      <td>0.192752</td>\n",
       "      <td>0.284936</td>\n",
       "      <td>0.448503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       violation_equipment  violation_incomplete_stop  violation_license  \\\n",
       "count        313274.000000              313274.000000      313274.000000   \n",
       "mean              0.009442                   0.022673           0.009366   \n",
       "std               0.096711                   0.148860           0.096322   \n",
       "min               0.000000                   0.000000           0.000000   \n",
       "25%               0.000000                   0.000000           0.000000   \n",
       "50%               0.000000                   0.000000           0.000000   \n",
       "75%               0.000000                   0.000000           0.000000   \n",
       "max               1.000000                   1.000000           1.000000   \n",
       "\n",
       "       violation_lights  violation_moving_violation  violation_other  \n",
       "count     313274.000000               313274.000000    313274.000000  \n",
       "mean           0.038647                    0.089133         0.278989  \n",
       "std            0.192752                    0.284936         0.448503  \n",
       "min            0.000000                    0.000000         0.000000  \n",
       "25%            0.000000                    0.000000         0.000000  \n",
       "50%            0.000000                    0.000000         0.000000  \n",
       "75%            0.000000                    0.000000         1.000000  \n",
       "max            1.000000                    1.000000         1.000000  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description.iloc[:,6:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T20:39:24.787266Z",
     "start_time": "2018-05-04T16:39:24.777240-04:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>violation_registration</th>\n",
       "      <th>violation_safe_movement</th>\n",
       "      <th>violation_seatbelt</th>\n",
       "      <th>violation_speeding</th>\n",
       "      <th>violation_suspended_license</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.119927</td>\n",
       "      <td>0.015989</td>\n",
       "      <td>0.038592</td>\n",
       "      <td>0.321147</td>\n",
       "      <td>0.009366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.324877</td>\n",
       "      <td>0.125434</td>\n",
       "      <td>0.192622</td>\n",
       "      <td>0.466918</td>\n",
       "      <td>0.096322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       violation_registration  violation_safe_movement  violation_seatbelt  \\\n",
       "count           313274.000000            313274.000000       313274.000000   \n",
       "mean                 0.119927                 0.015989            0.038592   \n",
       "std                  0.324877                 0.125434            0.192622   \n",
       "min                  0.000000                 0.000000            0.000000   \n",
       "25%                  0.000000                 0.000000            0.000000   \n",
       "50%                  0.000000                 0.000000            0.000000   \n",
       "75%                  0.000000                 0.000000            0.000000   \n",
       "max                  1.000000                 1.000000            1.000000   \n",
       "\n",
       "       violation_speeding  violation_suspended_license  \n",
       "count       313274.000000                313274.000000  \n",
       "mean             0.321147                     0.009366  \n",
       "std              0.466918                     0.096322  \n",
       "min              0.000000                     0.000000  \n",
       "25%              0.000000                     0.000000  \n",
       "50%              0.000000                     0.000000  \n",
       "75%              1.000000                     0.000000  \n",
       "max              1.000000                     1.000000  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description.iloc[:,12:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T20:39:24.797293Z",
     "start_time": "2018-05-04T16:39:24.788270-04:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>violation_traffic_control_signal</th>\n",
       "      <th>violation_window_tint</th>\n",
       "      <th>county_name_Fairfield County</th>\n",
       "      <th>county_name_Hartford County</th>\n",
       "      <th>county_name_Litchfield County</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.015989</td>\n",
       "      <td>0.007221</td>\n",
       "      <td>0.132118</td>\n",
       "      <td>0.125571</td>\n",
       "      <td>0.085551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.125434</td>\n",
       "      <td>0.084666</td>\n",
       "      <td>0.338619</td>\n",
       "      <td>0.331365</td>\n",
       "      <td>0.279701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       violation_traffic_control_signal  violation_window_tint  \\\n",
       "count                     313274.000000          313274.000000   \n",
       "mean                           0.015989               0.007221   \n",
       "std                            0.125434               0.084666   \n",
       "min                            0.000000               0.000000   \n",
       "25%                            0.000000               0.000000   \n",
       "50%                            0.000000               0.000000   \n",
       "75%                            0.000000               0.000000   \n",
       "max                            1.000000               1.000000   \n",
       "\n",
       "       county_name_Fairfield County  county_name_Hartford County  \\\n",
       "count                 313274.000000                313274.000000   \n",
       "mean                       0.132118                     0.125571   \n",
       "std                        0.338619                     0.331365   \n",
       "min                        0.000000                     0.000000   \n",
       "25%                        0.000000                     0.000000   \n",
       "50%                        0.000000                     0.000000   \n",
       "75%                        0.000000                     0.000000   \n",
       "max                        1.000000                     1.000000   \n",
       "\n",
       "       county_name_Litchfield County  \n",
       "count                  313274.000000  \n",
       "mean                        0.085551  \n",
       "std                         0.279701  \n",
       "min                         0.000000  \n",
       "25%                         0.000000  \n",
       "50%                         0.000000  \n",
       "75%                         0.000000  \n",
       "max                         1.000000  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description.iloc[:,17:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T20:39:24.811330Z",
     "start_time": "2018-05-04T16:39:24.798295-04:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_name_Middlesex County</th>\n",
       "      <th>county_name_New Haven County</th>\n",
       "      <th>county_name_New London County</th>\n",
       "      <th>county_name_Tolland County</th>\n",
       "      <th>county_name_Windham County</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.117919</td>\n",
       "      <td>0.157689</td>\n",
       "      <td>0.146753</td>\n",
       "      <td>0.144331</td>\n",
       "      <td>0.090068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.322513</td>\n",
       "      <td>0.364450</td>\n",
       "      <td>0.353860</td>\n",
       "      <td>0.351425</td>\n",
       "      <td>0.286280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       county_name_Middlesex County  county_name_New Haven County  \\\n",
       "count                 313274.000000                 313274.000000   \n",
       "mean                       0.117919                      0.157689   \n",
       "std                        0.322513                      0.364450   \n",
       "min                        0.000000                      0.000000   \n",
       "25%                        0.000000                      0.000000   \n",
       "50%                        0.000000                      0.000000   \n",
       "75%                        0.000000                      0.000000   \n",
       "max                        1.000000                      1.000000   \n",
       "\n",
       "       county_name_New London County  county_name_Tolland County  \\\n",
       "count                  313274.000000               313274.000000   \n",
       "mean                        0.146753                    0.144331   \n",
       "std                         0.353860                    0.351425   \n",
       "min                         0.000000                    0.000000   \n",
       "25%                         0.000000                    0.000000   \n",
       "50%                         0.000000                    0.000000   \n",
       "75%                         0.000000                    0.000000   \n",
       "max                         1.000000                    1.000000   \n",
       "\n",
       "       county_name_Windham County  \n",
       "count               313274.000000  \n",
       "mean                     0.090068  \n",
       "std                      0.286280  \n",
       "min                      0.000000  \n",
       "25%                      0.000000  \n",
       "50%                      0.000000  \n",
       "75%                      0.000000  \n",
       "max                      1.000000  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description.iloc[:,22:27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T20:39:24.824365Z",
     "start_time": "2018-05-04T16:39:24.812335-04:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driver_race_Asian</th>\n",
       "      <th>driver_race_Black</th>\n",
       "      <th>driver_race_Hispanic</th>\n",
       "      <th>driver_race_Other</th>\n",
       "      <th>driver_race_White</th>\n",
       "      <th>stop_duration_1-15 min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.018843</td>\n",
       "      <td>0.117724</td>\n",
       "      <td>0.098119</td>\n",
       "      <td>0.005510</td>\n",
       "      <td>0.759805</td>\n",
       "      <td>0.910886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.135970</td>\n",
       "      <td>0.322282</td>\n",
       "      <td>0.297475</td>\n",
       "      <td>0.074022</td>\n",
       "      <td>0.427203</td>\n",
       "      <td>0.284908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       driver_race_Asian  driver_race_Black  driver_race_Hispanic  \\\n",
       "count      313274.000000      313274.000000         313274.000000   \n",
       "mean            0.018843           0.117724              0.098119   \n",
       "std             0.135970           0.322282              0.297475   \n",
       "min             0.000000           0.000000              0.000000   \n",
       "25%             0.000000           0.000000              0.000000   \n",
       "50%             0.000000           0.000000              0.000000   \n",
       "75%             0.000000           0.000000              0.000000   \n",
       "max             1.000000           1.000000              1.000000   \n",
       "\n",
       "       driver_race_Other  driver_race_White  stop_duration_1-15 min  \n",
       "count      313274.000000      313274.000000           313274.000000  \n",
       "mean            0.005510           0.759805                0.910886  \n",
       "std             0.074022           0.427203                0.284908  \n",
       "min             0.000000           0.000000                0.000000  \n",
       "25%             0.000000           1.000000                1.000000  \n",
       "50%             0.000000           1.000000                1.000000  \n",
       "75%             0.000000           1.000000                1.000000  \n",
       "max             1.000000           1.000000                1.000000  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description.iloc[:,27:33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T20:39:24.838403Z",
     "start_time": "2018-05-04T16:39:24.825368-04:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_duration_16-30 min</th>\n",
       "      <th>stop_duration_30+ min</th>\n",
       "      <th>day_period_Afternoon</th>\n",
       "      <th>day_period_Evening</th>\n",
       "      <th>day_period_Morning</th>\n",
       "      <th>day_period_Small Hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.070635</td>\n",
       "      <td>0.018479</td>\n",
       "      <td>0.232799</td>\n",
       "      <td>0.196314</td>\n",
       "      <td>0.363155</td>\n",
       "      <td>0.207732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.256214</td>\n",
       "      <td>0.134676</td>\n",
       "      <td>0.422616</td>\n",
       "      <td>0.397209</td>\n",
       "      <td>0.480910</td>\n",
       "      <td>0.405684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       stop_duration_16-30 min  stop_duration_30+ min  day_period_Afternoon  \\\n",
       "count            313274.000000          313274.000000         313274.000000   \n",
       "mean                  0.070635               0.018479              0.232799   \n",
       "std                   0.256214               0.134676              0.422616   \n",
       "min                   0.000000               0.000000              0.000000   \n",
       "25%                   0.000000               0.000000              0.000000   \n",
       "50%                   0.000000               0.000000              0.000000   \n",
       "75%                   0.000000               0.000000              0.000000   \n",
       "max                   1.000000               1.000000              1.000000   \n",
       "\n",
       "       day_period_Evening  day_period_Morning  day_period_Small Hours  \n",
       "count       313274.000000       313274.000000           313274.000000  \n",
       "mean             0.196314            0.363155                0.207732  \n",
       "std              0.397209            0.480910                0.405684  \n",
       "min              0.000000            0.000000                0.000000  \n",
       "25%              0.000000            0.000000                0.000000  \n",
       "50%              0.000000            0.000000                0.000000  \n",
       "75%              0.000000            1.000000                0.000000  \n",
       "max              1.000000            1.000000                1.000000  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description.iloc[:,33:39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T20:39:24.849432Z",
     "start_time": "2018-05-04T16:39:24.840408-04:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season_Fall</th>\n",
       "      <th>season_Spring</th>\n",
       "      <th>season_Summer</th>\n",
       "      <th>season_Winter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.288217</td>\n",
       "      <td>0.263319</td>\n",
       "      <td>0.212137</td>\n",
       "      <td>0.236327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.452934</td>\n",
       "      <td>0.440435</td>\n",
       "      <td>0.408822</td>\n",
       "      <td>0.424826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         season_Fall  season_Spring  season_Summer  season_Winter\n",
       "count  313274.000000  313274.000000  313274.000000  313274.000000\n",
       "mean        0.288217       0.263319       0.212137       0.236327\n",
       "std         0.452934       0.440435       0.408822       0.424826\n",
       "min         0.000000       0.000000       0.000000       0.000000\n",
       "25%         0.000000       0.000000       0.000000       0.000000\n",
       "50%         0.000000       0.000000       0.000000       0.000000\n",
       "75%         1.000000       1.000000       0.000000       0.000000\n",
       "max         1.000000       1.000000       1.000000       1.000000"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description.iloc[:,39:43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T20:53:00.922504Z",
     "start_time": "2018-05-04T16:53:00.478324-04:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(185698, 44)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6oAAADlCAYAAABamgo6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6VzBVgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x143010efe10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined = pd.concat([outcomes, final_features], axis=1)\n",
    "combined.rename(columns={1: 'stop_outcome'}, inplace=True)\n",
    "combined.drop_duplicates(inplace=True)\n",
    "print(combined.shape)\n",
    "\n",
    "outcome_breakdown = combined['stop_outcome'].value_counts(normalize=True).mul(100).plot.bar(figsize=(15, 3), table=True)\n",
    "outcome_breakdown.axes.get_xaxis().set_visible(False)\n",
    "outcome_breakdown.axes.set_ylabel('%')\n",
    "outcome_breakdown.tables[0].scale(1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T18:46:30.094857Z",
     "start_time": "2018-05-04T14:46:29.976543-04:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Split the 'features' and 'income' data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_features, \n",
    "                                                    outcomes, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T18:46:30.105887Z",
     "start_time": "2018-05-04T14:46:30.095860-04:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313274"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes.count().values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T18:46:30.252276Z",
     "start_time": "2018-05-04T14:46:30.106890-04:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Arrest', 'Summons', 'Ticket', 'Verbal Warning', 'Written Warning'], dtype=object),\n",
       " array([  7303,  12203, 218951,  47750,  27067], dtype=int64))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(outcomes, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T18:46:30.381620Z",
     "start_time": "2018-05-04T14:46:30.253280-04:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218951"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(outcomes, return_counts=True)[1].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T18:46:30.536060Z",
     "start_time": "2018-05-04T14:46:30.382623-04:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Predictor: [Accuracy score: 0.6989, F-score: 0.7437]\n"
     ]
    }
   ],
   "source": [
    "# Most frequent outcome, 'Ticket,' count\n",
    "tp = np.unique(outcomes, return_counts=True)[1].max()\n",
    "total_outcomes = outcomes.count().values[0]\n",
    "fp = total_outcomes - tp\n",
    "tn = 0\n",
    "fn = 0\n",
    "\n",
    "accuracy = float(tp) / total_outcomes\n",
    "recall = float(tp) / (tp + fn)\n",
    "precision = float(tp) / (tp + fp)\n",
    "\n",
    "# TODO: Calculate F-score using the formula above for beta = 0.5 and correct values for precision and recall.\n",
    "beta = 0.5\n",
    "fscore = (1 + beta**2) * (precision * recall) / (beta**2 * precision + recall)\n",
    "\n",
    "# Print the results \n",
    "print(\"Naive Predictor: [Accuracy score: {:.4f}, F-score: {:.4f}]\".format(accuracy, fscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T18:46:31.773320Z",
     "start_time": "2018-05-04T14:46:30.537033-04:00"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AppData\\Local\\conda\\conda\\envs\\kaggle\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7173569547522145"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "clf_sgd = linear_model.SGDClassifier()\n",
    "clf_sgd.fit(X_train, y_train)\n",
    "clf_sgd.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T18:46:31.779336Z",
     "start_time": "2018-05-04T14:46:31.774323-04:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T18:53:36.794873Z",
     "start_time": "2018-05-04T14:46:31.780340-04:00"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AppData\\Local\\conda\\conda\\envs\\kaggle\\lib\\site-packages\\sklearn\\preprocessing\\label.py:112: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\AppData\\Local\\conda\\conda\\envs\\kaggle\\lib\\site-packages\\sklearn\\preprocessing\\label.py:147: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eclf1 score: 0.7188253132232064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AppData\\Local\\conda\\conda\\envs\\kaggle\\lib\\site-packages\\sklearn\\preprocessing\\label.py:112: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\AppData\\Local\\conda\\conda\\envs\\kaggle\\lib\\site-packages\\sklearn\\preprocessing\\label.py:147: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eclf2 score: 0.7072859308913894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AppData\\Local\\conda\\conda\\envs\\kaggle\\lib\\site-packages\\sklearn\\preprocessing\\label.py:112: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\AppData\\Local\\conda\\conda\\envs\\kaggle\\lib\\site-packages\\sklearn\\preprocessing\\label.py:147: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eclf3 score: 0.7072859308913894\n"
     ]
    }
   ],
   "source": [
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "clf4 = DecisionTreeClassifier(random_state=0)\n",
    "clf5 = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[\n",
    "        ('lr', clf1), ('rf', clf2), ('gnb', clf3), ('dt', clf4), ('gb', clf5)], voting='hard')\n",
    "eclf1 = eclf1.fit(X_train, y_train)\n",
    "print('eclf1 score: {}'.format(eclf1.score(X_test, y_test)))\n",
    "\n",
    "eclf2 = VotingClassifier(estimators=[\n",
    "        ('lr', clf1), ('rf', clf2), ('gnb', clf3), ('dt', clf4), ('gb', clf5)],\n",
    "        voting='soft')\n",
    "eclf2 = eclf2.fit(X_train, y_train)\n",
    "print('eclf2 score: {}'.format(eclf2.score(X_test, y_test)))\n",
    "\n",
    "eclf3 = VotingClassifier(estimators=[\n",
    "       ('lr', clf1), ('rf', clf2), ('gnb', clf3), ('dt', clf4), ('gb', clf5)],\n",
    "       voting='soft', weights=[1,1,1,1,1])\n",
    "eclf3 = eclf3.fit(X_train, y_train)\n",
    "print('eclf3 score: {}'.format(eclf3.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T18:53:40.168845Z",
     "start_time": "2018-05-04T14:53:36.795877-04:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 250619, 5)\n"
     ]
    }
   ],
   "source": [
    "print(eclf3.transform(X_train).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T18:53:41.416162Z",
     "start_time": "2018-05-04T14:53:40.169850-04:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arrest</th>\n",
       "      <th>Summons</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Verbal Warning</th>\n",
       "      <th>Written Warning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Arrest</th>\n",
       "      <td>474</td>\n",
       "      <td>146</td>\n",
       "      <td>799</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Summons</th>\n",
       "      <td>202</td>\n",
       "      <td>881</td>\n",
       "      <td>1386</td>\n",
       "      <td>41</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket</th>\n",
       "      <td>307</td>\n",
       "      <td>489</td>\n",
       "      <td>41745</td>\n",
       "      <td>849</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Verbal Warning</th>\n",
       "      <td>55</td>\n",
       "      <td>93</td>\n",
       "      <td>7392</td>\n",
       "      <td>1554</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Written Warning</th>\n",
       "      <td>33</td>\n",
       "      <td>58</td>\n",
       "      <td>4351</td>\n",
       "      <td>614</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Arrest  Summons  Ticket  Verbal Warning  Written Warning\n",
       "Arrest              474      146     799              25               10\n",
       "Summons             202      881    1386              41               15\n",
       "Ticket              307      489   41745             849              406\n",
       "Verbal Warning       55       93    7392            1554              346\n",
       "Written Warning      33       58    4351             614              384"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, precision_recall_fscore_support, log_loss\n",
    "\n",
    "eclf = eclf1\n",
    "labels = ['Arrest', 'Summons', 'Ticket', 'Verbal Warning', 'Written Warning']\n",
    "cm = confusion_matrix(y_test, eclf.predict(X_test), labels=labels)\n",
    "pd.DataFrame(cm, columns=labels, index=['Arrest', 'Summons', 'Ticket', 'Verbal Warning', 'Written Warning'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision, recall, and f- scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-04T18:53:45.309543Z",
     "start_time": "2018-05-04T14:53:41.417166-04:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>macro</th>\n",
       "      <th>micro</th>\n",
       "      <th>weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.511140</td>\n",
       "      <td>0.718825</td>\n",
       "      <td>0.660360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.372657</td>\n",
       "      <td>0.718825</td>\n",
       "      <td>0.718825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fscore</th>\n",
       "      <td>0.399931</td>\n",
       "      <td>0.718825</td>\n",
       "      <td>0.659859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              macro     micro  weighted\n",
       "precision  0.511140  0.718825  0.660360\n",
       "recall     0.372657  0.718825  0.718825\n",
       "fscore     0.399931  0.718825  0.659859"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = {\n",
    "    'micro': precision_recall_fscore_support(y_test, eclf.predict(X_test), average='micro'),\n",
    "    'macro': precision_recall_fscore_support(y_test, eclf.predict(X_test), average='macro'),\n",
    "    'weighted': precision_recall_fscore_support(y_test, eclf.predict(X_test), average='weighted'),\n",
    "}\n",
    "\n",
    "df_scores = pd.DataFrame(scores, index=['precision', 'recall', 'fscore', 'support']).iloc[:3,:]\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Donors Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score, accuracy_score\n",
    "\n",
    "\n",
    "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test): \n",
    "    '''\n",
    "    inputs:\n",
    "       - learner: the learning algorithm to be trained and predicted on\n",
    "       - sample_size: the size of samples (number) to be drawn from training set\n",
    "       - X_train: features training set\n",
    "       - y_train: income training set\n",
    "       - X_test: features testing set\n",
    "       - y_test: income testing set\n",
    "    '''\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # TODO: Fit the learner to the training data using slicing with 'sample_size' using .fit(training_features[:], training_labels[:])\n",
    "    start = time() # Get start time\n",
    "    learner = learner.fit(X_train[:sample_size], y_train[:sample_size])\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # Calculate the training time\n",
    "    results['train_time'] = end - start\n",
    "        \n",
    "    # Get the predictions on the test set(X_test),\n",
    "    # then get predictions on the first 300 training samples(X_train) using .predict()\n",
    "    start = time() # Get start time\n",
    "    predictions_test = learner.predict(X_test)\n",
    "    predictions_train = learner.predict(X_train[:300])\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # Calculate the total prediction time\n",
    "    results['pred_time'] = end - start\n",
    "            \n",
    "    # Compute accuracy on the first 300 training samples which is y_train[:300]\n",
    "    results['acc_train'] = accuracy_score(y_train[:300], predictions_train)\n",
    "        \n",
    "    # Compute accuracy on test set using accuracy_score()\n",
    "    results['acc_test'] = accuracy_score(y_test, predictions_test)\n",
    "    \n",
    "    # Compute F-score on the the first 300 training samples using fbeta_score()\n",
    "    results['f_train'] = fbeta_score(y_train[:300], predictions_train, 0.5, average='weighted')\n",
    "        \n",
    "    # Compute F-score on the test set which is y_test\n",
    "    results['f_test'] = fbeta_score(y_test, predictions_test, 0.5, average='weighted')\n",
    "       \n",
    "    # Success\n",
    "    print(\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n",
    "    # Return the results\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "\n",
    "import visuals as vs\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# TODO: Initialize the three models\n",
    "clf_A = SVC()\n",
    "clf_B = KNeighborsClassifier()\n",
    "clf_C = AdaBoostClassifier(random_state=0)\n",
    "\n",
    "# TODO: Calculate the number of samples for 1%, 10%, and 100% of the training data\n",
    "# HINT: samples_100 is the entire training set i.e. len(y_train)\n",
    "# HINT: samples_10 is 10% of samples_100\n",
    "# HINT: samples_1 is 1% of samples_100\n",
    "samples_100 = len(X_train)\n",
    "samples_10 = int(samples_100 * 0.1)\n",
    "samples_1 = int(samples_100 * 0.01)\n",
    "\n",
    "# Collect results on the learners\n",
    "# samples = [samples_1, samples_10, samples_100]\n",
    "samples = [samples_1, samples_10]\n",
    "results = {}\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "clf4 = DecisionTreeClassifier(random_state=0)\n",
    "clf5 = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "# for clf in [clf_A, clf_B, clf_C]:\n",
    "for clf in [clf1, clf2, clf3, clf4, clf5, clf_A, clf_B, clf_C]:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    results[clf_name] = {}\n",
    "    for i, samples in enumerate([samples_1, samples_10]):\n",
    "        results[clf_name][i] = train_predict(clf, samples, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# vs.evaluate(results, accuracy, fscore)\n",
    "# vs.evaluate(results, fscore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "algos_perf_100 = {\n",
    "    'AdaBoostClassifier': {\n",
    "        0: {\n",
    "            'acc_test': 0.72201739685579758,\n",
    "            'acc_train': 0.75666666666666671,\n",
    "            'f_test': 0.6347034296654146,\n",
    "            'f_train': 0.67410907596277725,\n",
    "            'pred_time': 0.543445348739624,\n",
    "            'train_time': 19.627169847488403\n",
    "        }\n",
    "    },\n",
    "    'DecisionTreeClassifier': {\n",
    "        0: {\n",
    "            'acc_test': 0.64998802968637781,\n",
    "            'acc_train': 0.87666666666666671,\n",
    "            'f_test': 0.61633367656940052,\n",
    "            'f_train': 0.86302242865468659,\n",
    "            'pred_time': 0.03910422325134277,\n",
    "            'train_time': 1.6804695129394531\n",
    "        }\n",
    "    },\n",
    "    'GaussianNB': {\n",
    "        0: {\n",
    "            'acc_test': 0.6477695315617269,\n",
    "            'acc_train': 0.65000000000000002,\n",
    "            'f_test': 0.64894363195314964,\n",
    "            'f_train': 0.6660681002181974,\n",
    "            'pred_time': 0.1474158763885498,\n",
    "            'train_time': 0.4652097225189209\n",
    "        }\n",
    "    },\n",
    "    'GradientBoostingClassifier': {\n",
    "        0: {\n",
    "            'acc_test': 0.72653419519591411,\n",
    "            'acc_train': 0.75666666666666671,\n",
    "            'f_test': 0.64379215256892308,\n",
    "            'f_train': 0.69227822649893855,\n",
    "            'pred_time': 0.4522271156311035,\n",
    "            'train_time': 134.945702791214\n",
    "        }\n",
    "    },\n",
    "    'KNeighborsClassifier': {\n",
    "        0: {\n",
    "            'acc_test': 0.70182746787965844,\n",
    "            'acc_train': 0.76333333333333331,\n",
    "            'f_test': 0.63953157257657978,\n",
    "            'f_train': 0.72221990752796439,\n",
    "            'pred_time': 469.2406713962555,\n",
    "            'train_time': 105.75855588912964\n",
    "        }\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        0: {\n",
    "            'acc_test': 0.72195355518314575,\n",
    "            'acc_train': 0.74333333333333329,\n",
    "            'f_test': 0.63036907824787092,\n",
    "            'f_train': 0.65587459707390683,\n",
    "            'pred_time': 0.015039205551147461,\n",
    "            'train_time': 7.507376670837402\n",
    "        }\n",
    "    },\n",
    "    'RandomForestClassifier': {\n",
    "        0: {\n",
    "            'acc_test': 0.66138376825472822,\n",
    "            'acc_train': 0.85666666666666669,\n",
    "            'f_test': 0.62684278836520912,\n",
    "            'f_train': 0.84386648286820054,\n",
    "            'pred_time': 0.2316434383392334,\n",
    "            'train_time': 3.1453657150268555\n",
    "        }\n",
    "    },\n",
    "    'SVC': {\n",
    "        0: {\n",
    "            'acc_test': 0.72153858431090889,\n",
    "            'acc_train': 0.74333333333333329,\n",
    "            'f_test': 0.62665356067781552,\n",
    "            'f_train': 0.66433167343078081,\n",
    "            'pred_time': 415.1082410812378,\n",
    "            'train_time': 12675.905246019363\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "algos_perf_1_10 = {\n",
    "    'AdaBoostClassifier': {\n",
    "        0: {\n",
    "            'acc_test': 0.6880376665868646,\n",
    "            'acc_train': 0.73333333333333328,\n",
    "            'f_test': 0.62455695148950785,\n",
    "            'f_train': 0.66977829504145292,\n",
    "            'pred_time': 0.539433479309082,\n",
    "            'train_time': 0.1734616756439209\n",
    "        },\n",
    "        1: {\n",
    "            'acc_test': 0.71975101747665793,\n",
    "            'acc_train': 0.74333333333333329,\n",
    "            'f_test': 0.63570748390991283,\n",
    "            'f_train': 0.653961069541102,\n",
    "            'pred_time': 0.5464534759521484,\n",
    "            'train_time': 1.5140256881713867\n",
    "        }\n",
    "    },\n",
    "    'DecisionTreeClassifier': {\n",
    "        0: {\n",
    "            'acc_test': 0.57082435559811662,\n",
    "            'acc_train': 0.99333333333333329,\n",
    "            'f_test': 0.58583779620178067,\n",
    "            'f_train': 0.99331663630843958,\n",
    "            'pred_time': 0.02102804183959961,\n",
    "            'train_time': 0.011029243469238281\n",
    "        },\n",
    "        1: {\n",
    "            'acc_test': 0.59725480807597164,\n",
    "            'acc_train': 0.94666666666666666,\n",
    "            'f_test': 0.5961071139937264,\n",
    "            'f_train': 0.94618066761588349,\n",
    "            'pred_time': 0.025066852569580078,\n",
    "            'train_time': 0.12533354759216309\n",
    "        }\n",
    "    },\n",
    "    'GaussianNB': {\n",
    "        0: {\n",
    "            'acc_test': 0.10259356795148034,\n",
    "            'acc_train': 0.083333333333333329,\n",
    "            'f_test': 0.028189924174105794,\n",
    "            'f_train': 0.029534142118342974,\n",
    "            'pred_time': 0.1323244571685791,\n",
    "            'train_time': 0.004010677337646484\n",
    "        },\n",
    "        1: {\n",
    "            'acc_test': 0.12931130795626847,\n",
    "            'acc_train': 0.12,\n",
    "            'f_test': 0.12916640033819876,\n",
    "            'f_train': 0.15739017372272129,\n",
    "            'pred_time': 0.13032174110412598,\n",
    "            'train_time': 0.03910064697265625\n",
    "        }\n",
    "    },\n",
    "    'GradientBoostingClassifier': {\n",
    "        0: {\n",
    "            'acc_test': 0.71092490623254334,\n",
    "            'acc_train': 0.81000000000000005,\n",
    "            'f_test': 0.63530485219905097,\n",
    "            'f_train': 0.78236498150146749,\n",
    "            'pred_time': 0.43916845321655273,\n",
    "            'train_time': 1.0352869033813477\n",
    "        },\n",
    "        1: {\n",
    "            'acc_test': 0.72490623254329267,\n",
    "            'acc_train': 0.76000000000000001,\n",
    "            'f_test': 0.64347985483372394,\n",
    "            'f_train': 0.69558556782166092,\n",
    "            'pred_time': 0.4291689395904541,\n",
    "            'train_time': 9.850817203521729\n",
    "        }\n",
    "    },\n",
    "    'KNeighborsClassifier': {\n",
    "        0: {\n",
    "            'acc_test': 0.6886920437315458,\n",
    "            'acc_train': 0.77333333333333332,\n",
    "            'f_test': 0.59287183310418978,\n",
    "            'f_train': 0.72444177427265255,\n",
    "            'pred_time': 7.581151485443115,\n",
    "            'train_time': 0.010005712509155273\n",
    "        },\n",
    "        1: {\n",
    "            'acc_test': 0.69636900486792752,\n",
    "            'acc_train': 0.78333333333333333,\n",
    "            'f_test': 0.62128133889347992,\n",
    "            'f_train': 0.74183674775562447,\n",
    "            'pred_time': 70.91268134117126,\n",
    "            'train_time': 0.4231266975402832\n",
    "        }\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        0: {\n",
    "            'acc_test': 0.71764424227914769,\n",
    "            'acc_train': 0.75,\n",
    "            'f_test': 0.61911581672791882,\n",
    "            'f_train': 0.67090722679839265,\n",
    "            'pred_time': 0.04411673545837402,\n",
    "            'train_time': 0.03409004211425781\n",
    "        },\n",
    "        1: {\n",
    "            'acc_test': 0.72155454472907188,\n",
    "            'acc_train': 0.73666666666666669,\n",
    "            'f_test': 0.62967738703888954,\n",
    "            'f_train': 0.64343872533090696,\n",
    "            'pred_time': 0.015011787414550781,\n",
    "            'train_time': 0.3048381805419922\n",
    "        }\n",
    "    },\n",
    "    'RandomForestClassifier': {\n",
    "        0: {\n",
    "            'acc_test': 0.66649110206687412,\n",
    "            'acc_train': 0.97666666666666668,\n",
    "            'f_test': 0.61185444064698324,\n",
    "            'f_train': 0.97659659659659648,\n",
    "            'pred_time': 0.10327458381652832,\n",
    "            'train_time': 0.02907705307006836\n",
    "        },\n",
    "        1: {\n",
    "            'acc_test': 0.65265341951959144,\n",
    "            'acc_train': 0.93000000000000005,\n",
    "            'f_test': 0.61806534585982587,\n",
    "            'f_train': 0.9292351914609287,\n",
    "            'pred_time': 0.14137554168701172,\n",
    "            'train_time': 0.21961092948913574\n",
    "        }\n",
    "    },\n",
    "    'SVC': {\n",
    "        0: {\n",
    "            'acc_test': 0.70449285771287207,\n",
    "            'acc_train': 0.73333333333333328,\n",
    "            'f_test': 0.53983227104940101,\n",
    "            'f_train': 0.5848263320603746,\n",
    "            'pred_time': 4.238268613815308,\n",
    "            'train_time': 0.30383753776550293\n",
    "        },\n",
    "        1: {\n",
    "            'acc_test': 0.71711754847977016,\n",
    "            'acc_train': 0.74333333333333329,\n",
    "            'f_test': 0.61122570948237986,\n",
    "            'f_train': 0.64742204388133662,\n",
    "            'pred_time': 41.337204933166504,\n",
    "            'train_time': 34.030903577804565\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "algos_perf = {\n",
    "    'AdaBoostClassifier': {\n",
    "        0: {\n",
    "            'acc_test': 0.6880376665868646,\n",
    "            'acc_train': 0.73333333333333328,\n",
    "            'f_test': 0.62455695148950785,\n",
    "            'f_train': 0.66977829504145292,\n",
    "            'pred_time': 0.539433479309082,\n",
    "            'train_time': 0.1734616756439209\n",
    "        },\n",
    "        1: {\n",
    "            'acc_test': 0.71975101747665793,\n",
    "            'acc_train': 0.74333333333333329,\n",
    "            'f_test': 0.63570748390991283,\n",
    "            'f_train': 0.653961069541102,\n",
    "            'pred_time': 0.5464534759521484,\n",
    "            'train_time': 1.5140256881713867\n",
    "        },\n",
    "        2: {\n",
    "            'acc_test': 0.72201739685579758,\n",
    "            'acc_train': 0.75666666666666671,\n",
    "            'f_test': 0.6347034296654146,\n",
    "            'f_train': 0.67410907596277725,\n",
    "            'pred_time': 0.543445348739624,\n",
    "            'train_time': 19.627169847488403\n",
    "        }\n",
    "\n",
    "    },\n",
    "    'DecisionTreeClassifier': {\n",
    "        0: {\n",
    "            'acc_test': 0.57082435559811662,\n",
    "            'acc_train': 0.99333333333333329,\n",
    "            'f_test': 0.58583779620178067,\n",
    "            'f_train': 0.99331663630843958,\n",
    "            'pred_time': 0.02102804183959961,\n",
    "            'train_time': 0.011029243469238281\n",
    "        },\n",
    "        1: {\n",
    "            'acc_test': 0.59725480807597164,\n",
    "            'acc_train': 0.94666666666666666,\n",
    "            'f_test': 0.5961071139937264,\n",
    "            'f_train': 0.94618066761588349,\n",
    "            'pred_time': 0.025066852569580078,\n",
    "            'train_time': 0.12533354759216309\n",
    "        },\n",
    "        2: {\n",
    "            'acc_test': 0.64998802968637781,\n",
    "            'acc_train': 0.87666666666666671,\n",
    "            'f_test': 0.61633367656940052,\n",
    "            'f_train': 0.86302242865468659,\n",
    "            'pred_time': 0.03910422325134277,\n",
    "            'train_time': 1.6804695129394531\n",
    "        }\n",
    "\n",
    "    },\n",
    "    'GaussianNB': {\n",
    "        0: {\n",
    "            'acc_test': 0.10259356795148034,\n",
    "            'acc_train': 0.083333333333333329,\n",
    "            'f_test': 0.028189924174105794,\n",
    "            'f_train': 0.029534142118342974,\n",
    "            'pred_time': 0.1323244571685791,\n",
    "            'train_time': 0.004010677337646484\n",
    "        },\n",
    "        1: {\n",
    "            'acc_test': 0.12931130795626847,\n",
    "            'acc_train': 0.12,\n",
    "            'f_test': 0.12916640033819876,\n",
    "            'f_train': 0.15739017372272129,\n",
    "            'pred_time': 0.13032174110412598,\n",
    "            'train_time': 0.03910064697265625\n",
    "        },\n",
    "        2: {\n",
    "            'acc_test': 0.6477695315617269,\n",
    "            'acc_train': 0.65000000000000002,\n",
    "            'f_test': 0.64894363195314964,\n",
    "            'f_train': 0.6660681002181974,\n",
    "            'pred_time': 0.1474158763885498,\n",
    "            'train_time': 0.4652097225189209\n",
    "        }\n",
    "\n",
    "    },\n",
    "    'GradientBoostingClassifier': {\n",
    "        0: {\n",
    "            'acc_test': 0.71092490623254334,\n",
    "            'acc_train': 0.81000000000000005,\n",
    "            'f_test': 0.63530485219905097,\n",
    "            'f_train': 0.78236498150146749,\n",
    "            'pred_time': 0.43916845321655273,\n",
    "            'train_time': 1.0352869033813477\n",
    "        },\n",
    "        1: {\n",
    "            'acc_test': 0.72490623254329267,\n",
    "            'acc_train': 0.76000000000000001,\n",
    "            'f_test': 0.64347985483372394,\n",
    "            'f_train': 0.69558556782166092,\n",
    "            'pred_time': 0.4291689395904541,\n",
    "            'train_time': 9.850817203521729\n",
    "        },\n",
    "        2: {\n",
    "            'acc_test': 0.72653419519591411,\n",
    "            'acc_train': 0.75666666666666671,\n",
    "            'f_test': 0.64379215256892308,\n",
    "            'f_train': 0.69227822649893855,\n",
    "            'pred_time': 0.4522271156311035,\n",
    "            'train_time': 134.945702791214\n",
    "        }\n",
    "    },\n",
    "    'KNeighborsClassifier': {\n",
    "        0: {\n",
    "            'acc_test': 0.6886920437315458,\n",
    "            'acc_train': 0.77333333333333332,\n",
    "            'f_test': 0.59287183310418978,\n",
    "            'f_train': 0.72444177427265255,\n",
    "            'pred_time': 7.581151485443115,\n",
    "            'train_time': 0.010005712509155273\n",
    "        },\n",
    "        1: {\n",
    "            'acc_test': 0.69636900486792752,\n",
    "            'acc_train': 0.78333333333333333,\n",
    "            'f_test': 0.62128133889347992,\n",
    "            'f_train': 0.74183674775562447,\n",
    "            'pred_time': 70.91268134117126,\n",
    "            'train_time': 0.4231266975402832\n",
    "        },\n",
    "        2: {\n",
    "            'acc_test': 0.70182746787965844,\n",
    "            'acc_train': 0.76333333333333331,\n",
    "            'f_test': 0.63953157257657978,\n",
    "            'f_train': 0.72221990752796439,\n",
    "            'pred_time': 469.2406713962555,\n",
    "            'train_time': 105.75855588912964\n",
    "        }\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        0: {\n",
    "            'acc_test': 0.71764424227914769,\n",
    "            'acc_train': 0.75,\n",
    "            'f_test': 0.61911581672791882,\n",
    "            'f_train': 0.67090722679839265,\n",
    "            'pred_time': 0.04411673545837402,\n",
    "            'train_time': 0.03409004211425781\n",
    "        },\n",
    "        1: {\n",
    "            'acc_test': 0.72155454472907188,\n",
    "            'acc_train': 0.73666666666666669,\n",
    "            'f_test': 0.62967738703888954,\n",
    "            'f_train': 0.64343872533090696,\n",
    "            'pred_time': 0.015011787414550781,\n",
    "            'train_time': 0.3048381805419922\n",
    "        },\n",
    "        2: {\n",
    "            'acc_test': 0.72195355518314575,\n",
    "            'acc_train': 0.74333333333333329,\n",
    "            'f_test': 0.63036907824787092,\n",
    "            'f_train': 0.65587459707390683,\n",
    "            'pred_time': 0.015039205551147461,\n",
    "            'train_time': 7.507376670837402\n",
    "        }\n",
    "    },\n",
    "    'RandomForestClassifier': {\n",
    "        0: {\n",
    "            'acc_test': 0.66649110206687412,\n",
    "            'acc_train': 0.97666666666666668,\n",
    "            'f_test': 0.61185444064698324,\n",
    "            'f_train': 0.97659659659659648,\n",
    "            'pred_time': 0.10327458381652832,\n",
    "            'train_time': 0.02907705307006836\n",
    "        },\n",
    "        1: {\n",
    "            'acc_test': 0.65265341951959144,\n",
    "            'acc_train': 0.93000000000000005,\n",
    "            'f_test': 0.61806534585982587,\n",
    "            'f_train': 0.9292351914609287,\n",
    "            'pred_time': 0.14137554168701172,\n",
    "            'train_time': 0.21961092948913574\n",
    "        },\n",
    "        2: {\n",
    "            'acc_test': 0.66138376825472822,\n",
    "            'acc_train': 0.85666666666666669,\n",
    "            'f_test': 0.62684278836520912,\n",
    "            'f_train': 0.84386648286820054,\n",
    "            'pred_time': 0.2316434383392334,\n",
    "            'train_time': 3.1453657150268555\n",
    "        }\n",
    "    },\n",
    "    'SVC': {\n",
    "        0: {\n",
    "            'acc_test': 0.70449285771287207,\n",
    "            'acc_train': 0.73333333333333328,\n",
    "            'f_test': 0.53983227104940101,\n",
    "            'f_train': 0.5848263320603746,\n",
    "            'pred_time': 4.238268613815308,\n",
    "            'train_time': 0.30383753776550293\n",
    "        },\n",
    "        1: {\n",
    "            'acc_test': 0.71711754847977016,\n",
    "            'acc_train': 0.74333333333333329,\n",
    "            'f_test': 0.61122570948237986,\n",
    "            'f_train': 0.64742204388133662,\n",
    "            'pred_time': 41.337204933166504,\n",
    "            'train_time': 34.030903577804565\n",
    "        },\n",
    "        2: {\n",
    "            'acc_test': 0.72153858431090889,\n",
    "            'acc_train': 0.74333333333333329,\n",
    "            'f_test': 0.62665356067781552,\n",
    "            'f_train': 0.66433167343078081,\n",
    "            'pred_time': 415.1082410812378,\n",
    "            'train_time': 12675.905246019363\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import visuals as vs\n",
    "\n",
    "results = algos_perf\n",
    "# vs.evaluate(results, accuracy, fscore)\n",
    "vs.evaluate(results, fscore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pl\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "\n",
    "def evaluate(results, accuracy, f1):\n",
    "    \"\"\"\n",
    "    Visualization code to display results of various learners.\n",
    "    \n",
    "    inputs:\n",
    "      - learners: a list of supervised learners\n",
    "      - stats: a list of dictionaries of the statistic results from 'train_predict()'\n",
    "      - accuracy: The score for the naive predictor\n",
    "      - f1: The score for the naive predictor\n",
    "    \"\"\"\n",
    "  \n",
    "    # Create figure\n",
    "#     fig, ax = pl.subplots(2, 3, figsize = (15,17))\n",
    "    fig, ax = pl.subplots(3, 2, figsize = (15,17))\n",
    "\n",
    "    # Constants\n",
    "    bar_width = 0.3\n",
    "    colors = ['#A00000','#00A0A0','#00A000', '#FF0000', '#82E0AA', '#D2B4DE', '#F1948A', '#D6EAF8']\n",
    "    \n",
    "    # Super loop to plot four panels of data\n",
    "    for k, learner in enumerate(results.keys()):\n",
    "        for j, metric in enumerate(['train_time', 'acc_train', 'f_train', 'pred_time', 'acc_test', 'f_test']):\n",
    "            for i in np.arange(3):\n",
    "                \n",
    "                # Creative plot code\n",
    "                ax[j//2, j%2].bar(i+k*bar_width, results[learner][i][metric], width = bar_width, color = colors[k])\n",
    "                ax[j//2, j%2].set_xticks([0.45, 1.45, 2.45])\n",
    "                ax[j//2, j%2].set_xticklabels([\"1%\", \"10%\", \"100%\"])\n",
    "                ax[j//2, j%2].set_xlabel(\"Training Set Size\")\n",
    "                ax[j//2, j%2].set_xlim((-0.1, 3.0))\n",
    "    \n",
    "    # Add unique y-labels\n",
    "    ax[0, 0].set_ylabel(\"Time (in seconds)\")\n",
    "    ax[0, 1].set_ylabel(\"Accuracy Score\")\n",
    "    ax[1, 0].set_ylabel(\"F-score\")\n",
    "    ax[1, 1].set_ylabel(\"Time (in seconds)\")\n",
    "    ax[2, 0].set_ylabel(\"Accuracy Score\")\n",
    "    ax[2, 1].set_ylabel(\"F-score\")\n",
    "    \n",
    "    # Add titles\n",
    "    ax[0, 0].set_title(\"Model Training\")\n",
    "    ax[0, 1].set_title(\"Accuracy Score on Training Subset\")\n",
    "    ax[1, 0].set_title(\"F-score on Training Subset\")\n",
    "    ax[1, 1].set_title(\"Model Predicting\")\n",
    "    ax[2, 0].set_title(\"Accuracy Score on Testing Set\")\n",
    "    ax[2, 1].set_title(\"F-score on Testing Set\")\n",
    "    \n",
    "    # Add horizontal lines for naive predictors\n",
    "    ax[0, 1].axhline(y = accuracy, xmin = -0.1, xmax = 3.0, linewidth = .2, color = 'k', linestyle = 'dashed')\n",
    "    ax[2, 0].axhline(y = accuracy, xmin = -0.1, xmax = 3.0, linewidth = .2, color = 'k', linestyle = 'dashed')\n",
    "    ax[1, 0].axhline(y = f1, xmin = -0.1, xmax = 8.0, linewidth = .2, color = 'k', linestyle = 'dashed')\n",
    "    ax[2, 1].axhline(y = f1, xmin = -0.1, xmax = 8.0, linewidth = .2, color = 'k', linestyle = 'dashed')\n",
    "    \n",
    "    # Set y-limits for score panels\n",
    "    ax[0, 1].set_ylim((0, 1))\n",
    "    ax[1, 0].set_ylim((0, 1))\n",
    "    ax[2, 0].set_ylim((0, 0.8))\n",
    "    ax[2, 1].set_ylim((0, 0.8))\n",
    "\n",
    "    # Create patches for the legend\n",
    "    patches = []\n",
    "    for i, learner in enumerate(results.keys()):\n",
    "        patches.append(mpatches.Patch(color = colors[i], label = learner))\n",
    "    pl.legend(handles = patches, bbox_to_anchor = (-0.1, 4), \\\n",
    "               loc = 'upper center', borderaxespad = 0., ncol = 2, fontsize = 'x-large')\n",
    "    \n",
    "    # Aesthetics\n",
    "    pl.suptitle(\"Performance Metrics for Eight Supervised Learning Models\", fontsize = 14, y = 1.05)\n",
    "    pl.tight_layout()\n",
    "    pl.show()\n",
    "\n",
    "\n",
    "evaluate(results, accuracy, fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reformatted = {}\n",
    "metrics = list(results[list(results.keys())[0]][0].keys())\n",
    "print(metrics)\n",
    "for k in results.keys():\n",
    "    algo = results[k]\n",
    "    reformatted[k] = {}\n",
    "    for m in metrics:\n",
    "#         reformatted[k][m] = [results[k][0][m], results[k][1][m], results[k][2][m]]\n",
    "        reformatted[k][m] = results[k][2][m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reformatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(reformatted)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_results[:1].plot.bar(figsize=(13, 4), title='acc_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_results[1:2].plot.bar(figsize=(13, 4), title='acc_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_results[2:3].plot.bar(figsize=(13, 4), title='f_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_results[3:4].plot.bar(figsize=(13, 4), title='f_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_results[4:5].plot.bar(figsize=(13, 4), title='pred_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_results[5:6].plot.bar(figsize=(13, 4), title='train_time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algo Testing Conclusion\n",
    "\n",
    "AdaBoostClassifier and GradientBoostingClassifier have highest test set accuracies and attractive training times.  I'll use these two to tune hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219881.7813            1.76s\n",
      "         2      218532.2381            1.58s\n",
      "         3      217188.8122            1.38s\n",
      "         4      215892.7225            1.18s\n",
      "         5      214686.0889            0.98s\n",
      "         6      213419.5165            0.78s\n",
      "         7      212189.0598            0.59s\n",
      "         8      211047.3862            0.39s\n",
      "         9      209929.2386            0.20s\n",
      "        10      208825.0296            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219881.6189            1.84s\n",
      "         2      218530.7243            1.60s\n",
      "         3      217188.5201            1.39s\n",
      "         4      215891.1910            1.19s\n",
      "         5      214684.5031            0.99s\n",
      "         6      213417.9788            0.79s\n",
      "         7      212188.0970            0.59s\n",
      "         8      211047.8455            0.39s\n",
      "         9      209931.0173            0.20s\n",
      "        10      208828.2419            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219884.5585            1.75s\n",
      "         2      218535.6299            1.57s\n",
      "         3      217195.7130            1.36s\n",
      "         4      215900.9762            1.17s\n",
      "         5      214694.8688            0.97s\n",
      "         6      213430.5692            0.78s\n",
      "         7      212202.5456            0.60s\n",
      "         8      211063.2747            0.40s\n",
      "         9      209946.4242            0.20s\n",
      "        10      208844.7087            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219824.4354            1.89s\n",
      "         2      218447.6749            1.65s\n",
      "         3      217058.0985            1.45s\n",
      "         4      215749.3635            1.24s\n",
      "         5      214522.7457            1.03s\n",
      "         6      213249.7023            0.83s\n",
      "         7      212021.1068            0.62s\n",
      "         8      210775.6574            0.41s\n",
      "         9      209640.4742            0.21s\n",
      "        10      208536.7230            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219823.8541            1.89s\n",
      "         2      218444.5305            1.66s\n",
      "         3      217055.6048            1.45s\n",
      "         4      215747.7634            1.25s\n",
      "         5      214521.1724            1.04s\n",
      "         6      213247.8707            0.83s\n",
      "         7      212019.8580            0.62s\n",
      "         8      210771.3016            0.41s\n",
      "         9      209636.8533            0.21s\n",
      "        10      208534.3676            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219828.4880            1.90s\n",
      "         2      218452.0153            1.67s\n",
      "         3      217066.4265            1.45s\n",
      "         4      215761.1205            1.26s\n",
      "         5      214534.8229            1.04s\n",
      "         6      213263.4515            0.83s\n",
      "         7      212037.2693            0.63s\n",
      "         8      210792.5944            0.42s\n",
      "         9      209658.2415            0.21s\n",
      "        10      208556.8934            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219797.3762            2.06s\n",
      "         2      218409.6591            1.86s\n",
      "         3      217020.9283            1.64s\n",
      "         4      215676.6313            1.42s\n",
      "         5      214368.6675            1.18s\n",
      "         6      213076.9951            0.94s\n",
      "         7      211837.0060            0.70s\n",
      "         8      210576.9779            0.47s\n",
      "         9      209370.1860            0.23s\n",
      "        10      208212.8071            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219798.4935            2.13s\n",
      "         2      218408.2160            1.88s\n",
      "         3      217020.1280            1.63s\n",
      "         4      215676.9804            1.39s\n",
      "         5      214370.5244            1.15s\n",
      "         6      213076.2990            0.92s\n",
      "         7      211836.9511            0.69s\n",
      "         8      210575.0292            0.46s\n",
      "         9      209366.7253            0.23s\n",
      "        10      208207.7328            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219803.4502            2.08s\n",
      "         2      218416.0353            1.84s\n",
      "         3      217031.2408            1.60s\n",
      "         4      215690.4998            1.37s\n",
      "         5      214386.2066            1.15s\n",
      "         6      213094.5798            0.91s\n",
      "         7      211856.9619            0.69s\n",
      "         8      210599.1069            0.46s\n",
      "         9      209393.2498            0.23s\n",
      "        10      208237.0663            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219802.6463            2.14s\n",
      "         2      218415.1388            1.86s\n",
      "         3      217032.9439            1.60s\n",
      "         4      215712.7703            1.37s\n",
      "         5      214426.1289            1.16s\n",
      "         6      213133.4657            0.92s\n",
      "         7      211882.3450            0.70s\n",
      "         8      210721.6606            0.47s\n",
      "         9      209587.1163            0.23s\n",
      "        10      208470.5489            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219802.9522            2.01s\n",
      "         2      218416.2250            1.83s\n",
      "         3      217036.0536            1.58s\n",
      "         4      215716.9409            1.35s\n",
      "         5      214423.5214            1.14s\n",
      "         6      213132.2539            0.91s\n",
      "         7      211882.5907            0.68s\n",
      "         8      210723.4545            0.46s\n",
      "         9      209590.2186            0.23s\n",
      "        10      208475.6789            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219807.0166            2.09s\n",
      "         2      218421.5109            1.84s\n",
      "         3      217044.1318            1.65s\n",
      "         4      215726.1794            1.40s\n",
      "         5      214435.7084            1.18s\n",
      "         6      213147.8048            0.94s\n",
      "         7      211900.9111            0.70s\n",
      "         8      210743.0542            0.47s\n",
      "         9      209610.3563            0.24s\n",
      "        10      208497.5898            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219759.9525            2.33s\n",
      "         2      218339.0549            2.07s\n",
      "         3      216927.2082            1.78s\n",
      "         4      215591.6513            1.51s\n",
      "         5      214262.0628            1.27s\n",
      "         6      212969.8848            1.01s\n",
      "         7      211700.5418            0.76s\n",
      "         8      210400.2980            0.51s\n",
      "         9      209223.5342            0.26s\n",
      "        10      208028.3861            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219758.5963            2.30s\n",
      "         2      218327.8072            2.04s\n",
      "         3      216916.3390            1.78s\n",
      "         4      215553.9026            1.53s\n",
      "         5      214216.9023            1.27s\n",
      "         6      212924.7512            1.01s\n",
      "         7      211657.4913            0.76s\n",
      "         8      210355.2030            0.50s\n",
      "         9      209178.2963            0.25s\n",
      "        10      207979.0671            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219767.8763            2.31s\n",
      "         2      218348.5614            2.03s\n",
      "         3      216941.1120            1.77s\n",
      "         4      215589.6718            1.51s\n",
      "         5      214258.9257            1.27s\n",
      "         6      212969.0756            1.01s\n",
      "         7      211703.1681            0.76s\n",
      "         8      210405.0657            0.51s\n",
      "         9      209230.0937            0.26s\n",
      "        10      208030.9435            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219739.1392            2.63s\n",
      "         2      218241.3961            2.43s\n",
      "         3      216803.8289            2.10s\n",
      "         4      215399.3057            1.80s\n",
      "         5      213996.7794            1.50s\n",
      "         6      212624.3819            1.20s\n",
      "         7      211285.7307            0.90s\n",
      "         8      209950.3130            0.60s\n",
      "         9      208646.3939            0.30s\n",
      "        10      207403.2795            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219740.4677            2.70s\n",
      "         2      218242.3632            2.42s\n",
      "         3      216804.9242            2.09s\n",
      "         4      215368.1668            1.82s\n",
      "         5      213964.2588            1.51s\n",
      "         6      212589.8605            1.21s\n",
      "         7      211250.7673            0.90s\n",
      "         8      209911.5325            0.60s\n",
      "         9      208605.9929            0.30s\n",
      "        10      207359.5251            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219746.0980            2.59s\n",
      "         2      218254.0150            2.37s\n",
      "         3      216820.9114            2.05s\n",
      "         4      215388.8519            1.76s\n",
      "         5      213989.3456            1.48s\n",
      "         6      212619.3328            1.19s\n",
      "         7      211285.2020            0.89s\n",
      "         8      209952.7639            0.59s\n",
      "         9      208652.2405            0.30s\n",
      "        10      207409.5505            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219646.9544            3.89s\n",
      "         2      218107.8664            3.41s\n",
      "         3      216614.2918            2.93s\n",
      "         4      215128.0405            2.55s\n",
      "         5      213695.1790            2.13s\n",
      "         6      212322.6638            1.70s\n",
      "         7      210962.0731            1.28s\n",
      "         8      209653.4581            0.85s\n",
      "         9      208371.3502            0.43s\n",
      "        10      207142.1361            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219646.7245            3.82s\n",
      "         2      218110.4926            3.32s\n",
      "         3      216610.7947            2.93s\n",
      "         4      215111.0579            2.55s\n",
      "         5      213684.9489            2.15s\n",
      "         6      212284.5196            1.73s\n",
      "         7      210974.6195            1.30s\n",
      "         8      209702.0689            0.86s\n",
      "         9      208422.5468            0.43s\n",
      "        10      207173.4749            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219670.4682            3.89s\n",
      "         2      218142.9752            3.46s\n",
      "         3      216647.5482            2.98s\n",
      "         4      215175.4565            2.60s\n",
      "         5      213748.4130            2.21s\n",
      "         6      212362.6484            1.76s\n",
      "         7      210983.4415            1.31s\n",
      "         8      209690.9634            0.87s\n",
      "         9      208415.8329            0.44s\n",
      "        10      207188.8390            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219654.5617            4.66s\n",
      "         2      218079.1641            4.26s\n",
      "         3      216523.4262            3.70s\n",
      "         4      215030.8280            3.12s\n",
      "         5      213539.3151            2.63s\n",
      "         6      212078.4986            2.10s\n",
      "         7      210635.2363            1.59s\n",
      "         8      209228.6078            1.06s\n",
      "         9      207893.6347            0.53s\n",
      "        10      206585.5638            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219643.2578            4.60s\n",
      "         2      218058.6088            4.24s\n",
      "         3      216496.1983            3.66s\n",
      "         4      215007.7420            3.14s\n",
      "         5      213516.7460            2.63s\n",
      "         6      212032.7880            2.12s\n",
      "         7      210618.9396            1.60s\n",
      "         8      209208.9474            1.07s\n",
      "         9      207865.5214            0.54s\n",
      "        10      206553.3180            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219646.1426            4.71s\n",
      "         2      218079.2369            4.24s\n",
      "         3      216535.8062            3.68s\n",
      "         4      215079.8170            3.18s\n",
      "         5      213582.0945            2.67s\n",
      "         6      212154.1726            2.15s\n",
      "         7      210778.2758            1.61s\n",
      "         8      209374.7571            1.08s\n",
      "         9      208031.2949            0.54s\n",
      "        10      206727.8150            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219524.8150            7.01s\n",
      "         2      217869.6919            6.27s\n",
      "         3      216251.9240            5.54s\n",
      "         4      214657.8038            4.70s\n",
      "         5      213131.0650            3.89s\n",
      "         6      211602.2988            3.13s\n",
      "         7      210127.8113            2.38s\n",
      "         8      208678.5591            1.58s\n",
      "         9      207275.9126            0.79s\n",
      "        10      205919.0588            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219520.7463            7.54s\n",
      "         2      217846.1967            6.78s\n",
      "         3      216230.0794            5.87s\n",
      "         4      214632.3409            4.99s\n",
      "         5      213101.5963            4.08s\n",
      "         6      211624.4263            3.27s\n",
      "         7      210134.7922            2.45s\n",
      "         8      208687.5604            1.63s\n",
      "         9      207277.7601            0.83s\n",
      "        10      205893.5156            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219528.3900            8.08s\n",
      "         2      217863.5853            6.83s\n",
      "         3      216252.8165            5.88s\n",
      "         4      214663.0777            4.96s\n",
      "         5      213136.3954            4.09s\n",
      "         6      211616.0671            3.29s\n",
      "         7      210137.6802            2.49s\n",
      "         8      208685.5075            1.65s\n",
      "         9      207286.3775            0.82s\n",
      "        10      205930.1738            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219548.5526            9.17s\n",
      "         2      217869.6622            8.18s\n",
      "         3      216311.3571            7.22s\n",
      "         4      214736.5748            6.29s\n",
      "         5      213237.5683            5.23s\n",
      "         6      211729.4421            4.22s\n",
      "         7      210298.4140            3.16s\n",
      "         8      208927.9958            2.11s\n",
      "         9      207591.9013            1.06s\n",
      "        10      206282.1104            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219531.7886            8.97s\n",
      "         2      217917.6280            8.10s\n",
      "         3      216307.2207            7.16s\n",
      "         4      214708.9388            6.20s\n",
      "         5      213175.9367            5.25s\n",
      "         6      211683.6439            4.25s\n",
      "         7      210258.3937            3.20s\n",
      "         8      208875.8297            2.14s\n",
      "         9      207497.0604            1.08s\n",
      "        10      206178.5781            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219586.3405            9.22s\n",
      "         2      217952.6844            8.25s\n",
      "         3      216359.7814            7.27s\n",
      "         4      214781.9470            6.37s\n",
      "         5      213292.1607            5.34s\n",
      "         6      211827.0928            4.30s\n",
      "         7      210360.8132            3.21s\n",
      "         8      208988.9323            2.14s\n",
      "         9      207614.3858            1.08s\n",
      "        10      206320.0516            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219510.0368           11.62s\n",
      "         2      217810.5628           11.13s\n",
      "         3      216179.5888            9.56s\n",
      "         4      214615.8808            8.13s\n",
      "         5      213065.0880            6.87s\n",
      "         6      211508.0110            5.54s\n",
      "         7      209990.2000            4.17s\n",
      "         8      208507.5831            2.79s\n",
      "         9      207086.3968            1.40s\n",
      "        10      205715.2159            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219498.4523           11.70s\n",
      "         2      217801.2060           11.05s\n",
      "         3      216151.4829            9.66s\n",
      "         4      214583.1769            8.21s\n",
      "         5      213001.2148            6.93s\n",
      "         6      211445.2952            5.58s\n",
      "         7      209945.5219            4.21s\n",
      "         8      208470.0846            2.83s\n",
      "         9      207025.7888            1.42s\n",
      "        10      205650.6551            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219493.7150           11.87s\n",
      "         2      217822.4221           11.00s\n",
      "         3      216208.7532            9.59s\n",
      "         4      214587.0168            8.23s\n",
      "         5      212994.9329            6.95s\n",
      "         6      211440.7001            5.57s\n",
      "         7      209967.9577            4.19s\n",
      "         8      208503.7924            2.80s\n",
      "         9      207079.5411            1.40s\n",
      "        10      205696.2175            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219440.9856           18.70s\n",
      "         2      217684.6033           16.98s\n",
      "         3      215966.1359           15.10s\n",
      "         4      214290.6798           13.00s\n",
      "         5      212668.6748           10.83s\n",
      "         6      211077.0848            8.75s\n",
      "         7      209520.7821            6.62s\n",
      "         8      207998.2028            4.42s\n",
      "         9      206521.0258            2.21s\n",
      "        10      205068.8591            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219423.7994           20.80s\n",
      "         2      217662.5094           18.14s\n",
      "         3      215941.9905           15.84s\n",
      "         4      214264.9933           13.48s\n",
      "         5      212646.4212           11.11s\n",
      "         6      211065.1329            8.87s\n",
      "         7      209496.8482            6.74s\n",
      "         8      207975.7476            4.49s\n",
      "         9      206493.9114            2.25s\n",
      "        10      205029.6309            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219430.4130           19.81s\n",
      "         2      217673.2472           17.49s\n",
      "         3      215960.6305           15.49s\n",
      "         4      214290.4717           13.26s\n",
      "         5      212667.3677           11.01s\n",
      "         6      211080.0599            8.93s\n",
      "         7      209524.3980            6.78s\n",
      "         8      208008.3499            4.50s\n",
      "         9      206524.9447            2.25s\n",
      "        10      205072.5490            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      217292.6358            1.94s\n",
      "         2      213488.0985            1.74s\n",
      "         3      209858.1286            1.49s\n",
      "         4      206525.1503            1.29s\n",
      "         5      203570.0166            1.07s\n",
      "         6      200568.1583            0.85s\n",
      "         7      197781.9175            0.63s\n",
      "         8      195323.6264            0.42s\n",
      "         9      193014.2545            0.21s\n",
      "        10      190802.9196            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      217292.1472            1.76s\n",
      "         2      213483.5450            1.75s\n",
      "         3      209857.2960            1.51s\n",
      "         4      206520.5438            1.30s\n",
      "         5      203565.2993            1.07s\n",
      "         6      200563.6909            0.85s\n",
      "         7      197779.3695            0.63s\n",
      "         8      195325.2860            0.42s\n",
      "         9      193019.7244            0.21s\n",
      "        10      190812.5847            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      217296.5415            1.82s\n",
      "         2      213493.7818            1.61s\n",
      "         3      209874.3996            1.41s\n",
      "         4      206544.9237            1.20s\n",
      "         5      203591.4509            0.99s\n",
      "         6      200595.8398            0.80s\n",
      "         7      197816.1543            0.59s\n",
      "         8      195364.7962            0.40s\n",
      "         9      193058.7992            0.20s\n",
      "        10      190854.6275            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      217122.3755            1.81s\n",
      "         2      213239.7077            1.63s\n",
      "         3      209494.1140            1.44s\n",
      "         4      206135.2857            1.23s\n",
      "         5      203120.6192            1.03s\n",
      "         6      200106.2504            0.82s\n",
      "         7      197331.4766            0.62s\n",
      "         8      194576.1780            0.41s\n",
      "         9      192213.6449            0.21s\n",
      "        10      190012.4454            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      217120.6511            1.80s\n",
      "         2      213230.4354            1.64s\n",
      "         3      209487.0340            1.45s\n",
      "         4      206129.0076            1.24s\n",
      "         5      203114.6044            1.03s\n",
      "         6      200096.5932            0.83s\n",
      "         7      197320.7239            0.62s\n",
      "         8      194556.8289            0.41s\n",
      "         9      192193.4920            0.21s\n",
      "        10      189995.5998            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      217130.0777            1.84s\n",
      "         2      213248.2635            1.64s\n",
      "         3      209514.2865            1.44s\n",
      "         4      206163.8352            1.24s\n",
      "         5      203149.9831            1.04s\n",
      "         6      200137.0928            0.86s\n",
      "         7      197365.8412            0.65s\n",
      "         8      194612.6840            0.44s\n",
      "         9      192249.2968            0.22s\n",
      "        10      190054.5021            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      217043.0238            2.05s\n",
      "         2      213127.2334            1.83s\n",
      "         3      209388.8784            1.59s\n",
      "         4      205926.4697            1.36s\n",
      "         5      202708.4204            1.14s\n",
      "         6      199649.4668            0.92s\n",
      "         7      196851.5386            0.69s\n",
      "         8      194053.6008            0.46s\n",
      "         9      191499.6121            0.23s\n",
      "        10      189184.6076            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      217046.3512            2.00s\n",
      "         2      213123.0314            1.82s\n",
      "         3      209386.7877            1.59s\n",
      "         4      205924.7482            1.36s\n",
      "         5      202681.9590            1.14s\n",
      "         6      199608.6626            0.94s\n",
      "         7      196805.8328            0.71s\n",
      "         8      194004.9322            0.47s\n",
      "         9      191450.7137            0.23s\n",
      "        10      189127.5034            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      217056.7084            2.00s\n",
      "         2      213141.8070            1.81s\n",
      "         3      209414.6232            1.59s\n",
      "         4      205959.5776            1.36s\n",
      "         5      202722.7251            1.13s\n",
      "         6      199656.2350            0.91s\n",
      "         7      196857.5865            0.68s\n",
      "         8      194065.8633            0.45s\n",
      "         9      191516.9295            0.23s\n",
      "        10      189200.2366            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      217057.5846            2.08s\n",
      "         2      213143.3690            1.83s\n",
      "         3      209407.5886            1.62s\n",
      "         4      206008.1241            1.38s\n",
      "         5      202829.0720            1.15s\n",
      "         6      199757.7561            0.91s\n",
      "         7      196923.1753            0.69s\n",
      "         8      194416.0771            0.46s\n",
      "         9      192062.7123            0.23s\n",
      "        10      189833.0183            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      217058.4843            2.07s\n",
      "         2      213146.5328            1.97s\n",
      "         3      209416.4881            1.73s\n",
      "         4      206015.6892            1.45s\n",
      "         5      202815.9510            1.23s\n",
      "         6      199748.8664            1.00s\n",
      "         7      196919.0177            0.78s\n",
      "         8      194416.0532            0.54s\n",
      "         9      192066.9911            0.27s\n",
      "        10      189835.5631            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      217066.2109            2.40s\n",
      "         2      213157.8874            2.06s\n",
      "         3      209435.9455            1.75s\n",
      "         4      206037.2307            1.48s\n",
      "         5      202863.7745            1.24s\n",
      "         6      199803.1145            0.99s\n",
      "         7      196978.1987            0.74s\n",
      "         8      194476.8331            0.49s\n",
      "         9      192128.7944            0.24s\n",
      "        10      189899.3644            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216930.4774            2.32s\n",
      "         2      212919.6014            2.08s\n",
      "         3      209118.1342            1.78s\n",
      "         4      205664.4834            1.52s\n",
      "         5      202380.8857            1.28s\n",
      "         6      199321.9492            1.02s\n",
      "         7      196447.1774            0.77s\n",
      "         8      193567.9409            0.51s\n",
      "         9      191087.8343            0.26s\n",
      "        10      188670.2078            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216926.5332            2.29s\n",
      "         2      212889.1118            2.08s\n",
      "         3      209090.9275            1.77s\n",
      "         4      205586.5328            1.55s\n",
      "         5      202283.4872            1.29s\n",
      "         6      199227.9385            1.03s\n",
      "         7      196359.7910            0.77s\n",
      "         8      193478.1708            0.51s\n",
      "         9      190998.3455            0.26s\n",
      "        10      188570.4511            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216949.5597            2.42s\n",
      "         2      212943.2371            2.08s\n",
      "         3      209153.7009            1.78s\n",
      "         4      205654.2875            1.52s\n",
      "         5      202386.2871            1.27s\n",
      "         6      199333.4897            1.02s\n",
      "         7      196467.0007            0.76s\n",
      "         8      193595.0343            0.51s\n",
      "         9      191120.0425            0.25s\n",
      "        10      188675.4265            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216869.7131            2.61s\n",
      "         2      212647.6849            2.40s\n",
      "         3      208787.6053            2.10s\n",
      "         4      205096.9883            1.81s\n",
      "         5      201590.6715            1.52s\n",
      "         6      198327.9711            1.22s\n",
      "         7      195294.2640            0.91s\n",
      "         8      192403.2804            0.61s\n",
      "         9      189668.7103            0.31s\n",
      "        10      187184.3271            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216873.6587            2.67s\n",
      "         2      212650.2905            2.43s\n",
      "         3      208790.4825            2.10s\n",
      "         4      205091.3889            1.82s\n",
      "         5      201577.0119            1.52s\n",
      "         6      198308.5947            1.22s\n",
      "         7      195272.3580            0.92s\n",
      "         8      192358.7252            0.61s\n",
      "         9      189619.0364            0.31s\n",
      "        10      187129.0185            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216886.0240            2.72s\n",
      "         2      212679.7999            2.46s\n",
      "         3      208831.6574            2.13s\n",
      "         4      205143.8059            1.83s\n",
      "         5      201642.1523            1.52s\n",
      "         6      198384.9549            1.22s\n",
      "         7      195360.8824            0.91s\n",
      "         8      192460.8178            0.64s\n",
      "         9      189732.1222            0.32s\n",
      "        10      187250.1907            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216595.7315            3.96s\n",
      "         2      212250.7434            3.43s\n",
      "         3      208214.9618            2.96s\n",
      "         4      204373.9024            2.59s\n",
      "         5      200839.9222            2.17s\n",
      "         6      197552.8740            1.73s\n",
      "         7      194478.0822            1.29s\n",
      "         8      191599.2959            0.86s\n",
      "         9      188906.0443            0.43s\n",
      "        10      186403.6770            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216594.0053            3.79s\n",
      "         2      212308.5017            3.34s\n",
      "         3      208249.4267            2.90s\n",
      "         4      204361.3960            2.56s\n",
      "         5      200837.4020            2.16s\n",
      "         6      197503.5989            1.73s\n",
      "         7      194551.7102            1.30s\n",
      "         8      191693.4891            0.86s\n",
      "         9      188994.6820            0.43s\n",
      "        10      186499.5950            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216662.2437            3.82s\n",
      "         2      212347.6585            3.37s\n",
      "         3      208303.9208            3.01s\n",
      "         4      204497.8147            2.68s\n",
      "         5      200979.1717            2.25s\n",
      "         6      197684.7430            1.78s\n",
      "         7      194654.8777            1.33s\n",
      "         8      191830.4085            0.88s\n",
      "         9      189120.0152            0.44s\n",
      "        10      186621.9435            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216619.0835            4.67s\n",
      "         2      212196.0142            4.30s\n",
      "         3      208004.8450            3.71s\n",
      "         4      204120.7621            3.20s\n",
      "         5      200393.8226            2.71s\n",
      "         6      196844.7163            2.16s\n",
      "         7      193584.1284            1.62s\n",
      "         8      190526.1567            1.08s\n",
      "         9      187735.2791            0.55s\n",
      "        10      185106.9103            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216586.4473            4.75s\n",
      "         2      212112.0770            4.41s\n",
      "         3      207910.4758            3.80s\n",
      "         4      204083.8080            3.23s\n",
      "         5      200358.1698            2.70s\n",
      "         6      196906.9668            2.16s\n",
      "         7      193712.9698            1.62s\n",
      "         8      190635.9809            1.08s\n",
      "         9      187804.6813            0.54s\n",
      "        10      185149.1269            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216581.1726            5.02s\n",
      "         2      212159.9659            4.46s\n",
      "         3      208004.7038            3.84s\n",
      "         4      204223.1276            3.28s\n",
      "         5      200535.7948            2.73s\n",
      "         6      197059.4286            2.20s\n",
      "         7      193832.1275            1.66s\n",
      "         8      190806.2493            1.10s\n",
      "         9      187973.3943            0.55s\n",
      "        10      185333.7224            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216236.8905            7.23s\n",
      "         2      211580.8712            6.31s\n",
      "         3      207234.0638            5.57s\n",
      "         4      203162.6223            4.76s\n",
      "         5      199414.7313            3.94s\n",
      "         6      195819.0851            3.16s\n",
      "         7      192495.6726            2.38s\n",
      "         8      189376.7655            1.58s\n",
      "         9      186482.4338            0.79s\n",
      "        10      183740.1078            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216223.8103            7.14s\n",
      "         2      211508.7219            6.24s\n",
      "         3      207175.9273            5.54s\n",
      "         4      203095.0245            4.74s\n",
      "         5      199338.1974            3.89s\n",
      "         6      195853.5126            3.13s\n",
      "         7      192485.6936            2.36s\n",
      "         8      189351.6534            1.57s\n",
      "         9      186448.1532            0.79s\n",
      "        10      183673.9047            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216245.5298            7.07s\n",
      "         2      211559.8884            6.24s\n",
      "         3      207236.3077            5.53s\n",
      "         4      203175.5305            4.75s\n",
      "         5      199427.0496            3.93s\n",
      "         6      195847.4725            3.16s\n",
      "         7      192515.0674            2.38s\n",
      "         8      189378.9810            1.58s\n",
      "         9      186487.3385            0.79s\n",
      "        10      183747.6700            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216243.1969            9.38s\n",
      "         2      211501.9488            8.40s\n",
      "         3      207245.6171            7.35s\n",
      "         4      203166.2306            6.40s\n",
      "         5      199461.5920            5.42s\n",
      "         6      195995.4187            4.34s\n",
      "         7      192747.3665            3.26s\n",
      "         8      189711.2867            2.18s\n",
      "         9      186875.7710            1.09s\n",
      "        10      184229.1925            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216306.1866           10.17s\n",
      "         2      211720.4271            9.06s\n",
      "         3      207375.9034            7.85s\n",
      "         4      203305.6253            6.71s\n",
      "         5      199582.9712            5.62s\n",
      "         6      196054.7011            4.46s\n",
      "         7      192916.4811            3.34s\n",
      "         8      189872.0523            2.23s\n",
      "         9      186944.0287            1.11s\n",
      "        10      184266.4679            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216333.0599            9.20s\n",
      "         2      211722.3929            8.34s\n",
      "         3      207503.3815            7.31s\n",
      "         4      203365.1495            6.32s\n",
      "         5      199686.9844            5.38s\n",
      "         6      196272.4313            4.34s\n",
      "         7      192963.1957            3.26s\n",
      "         8      189944.9123            2.16s\n",
      "         9      187082.0392            1.09s\n",
      "        10      184462.3156            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216168.0451           12.10s\n",
      "         2      211392.9739           11.25s\n",
      "         3      206986.6536            9.84s\n",
      "         4      202863.7293            8.32s\n",
      "         5      198943.3720            7.00s\n",
      "         6      195308.9938            5.62s\n",
      "         7      191930.4469            4.24s\n",
      "         8      188760.2756            2.83s\n",
      "         9      185781.8316            1.42s\n",
      "        10      183031.9699            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216136.8454           12.20s\n",
      "         2      211370.2942           11.21s\n",
      "         3      206927.6005            9.73s\n",
      "         4      202783.3128            8.33s\n",
      "         5      198923.2466            7.07s\n",
      "         6      195330.7918            5.70s\n",
      "         7      191993.5369            4.29s\n",
      "         8      188789.1614            2.86s\n",
      "         9      185781.3516            1.43s\n",
      "        10      183004.1205            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216127.8108           12.23s\n",
      "         2      211434.3667           11.26s\n",
      "         3      207096.7096            9.78s\n",
      "         4      203019.5561            8.30s\n",
      "         5      199116.8580            7.02s\n",
      "         6      195464.9168            5.61s\n",
      "         7      192125.6209            4.22s\n",
      "         8      188950.2317            2.81s\n",
      "         9      185956.1841            1.41s\n",
      "        10      183128.6694            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      215969.9949           19.23s\n",
      "         2      211035.2918           17.25s\n",
      "         3      206433.6094           15.20s\n",
      "         4      202139.7233           13.06s\n",
      "         5      198161.2346           10.92s\n",
      "         6      194421.7378            8.76s\n",
      "         7      190931.1623            6.63s\n",
      "         8      187638.1746            4.43s\n",
      "         9      184561.1016            2.21s\n",
      "        10      181679.4971            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      215899.5309           19.23s\n",
      "         2      210963.1337           17.21s\n",
      "         3      206357.6089           15.28s\n",
      "         4      202044.1361           13.15s\n",
      "         5      198078.2602           10.88s\n",
      "         6      194365.9453            8.82s\n",
      "         7      190851.8141            6.66s\n",
      "         8      187586.3700            4.43s\n",
      "         9      184530.0767            2.21s\n",
      "        10      181618.8878            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      215891.4658           19.42s\n",
      "         2      210943.2132           17.09s\n",
      "         3      206364.8605           15.16s\n",
      "         4      202089.3144           13.07s\n",
      "         5      198130.1811           10.85s\n",
      "         6      194411.6425            8.80s\n",
      "         7      190948.3013            6.62s\n",
      "         8      187674.9172            4.44s\n",
      "         9      184605.5279            2.21s\n",
      "        10      181723.5192            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221074.0449            1.72s\n",
      "         2      220935.2634            1.54s\n",
      "         3      220794.3690            1.35s\n",
      "         4      220655.3083            1.16s\n",
      "         5      220522.8301            0.97s\n",
      "         6      220381.4489            0.78s\n",
      "         7      220241.0371            0.58s\n",
      "         8      220107.5948            0.39s\n",
      "         9      219974.1779            0.20s\n",
      "        10      219840.1508            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221074.0287            1.76s\n",
      "         2      220935.1123            1.58s\n",
      "         3      220794.3391            1.37s\n",
      "         4      220655.1509            1.20s\n",
      "         5      220522.6671            0.99s\n",
      "         6      220381.2861            0.80s\n",
      "         7      220240.9250            0.60s\n",
      "         8      220107.6277            0.40s\n",
      "         9      219974.3477            0.20s\n",
      "        10      219840.4661            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221076.3086            1.71s\n",
      "         2      220937.5896            1.56s\n",
      "         3      220797.0452            1.39s\n",
      "         4      220658.1243            1.19s\n",
      "         5      220525.6980            0.99s\n",
      "         6      220384.5515            0.79s\n",
      "         7      220244.3943            0.60s\n",
      "         8      220111.1994            0.40s\n",
      "         9      219977.9241            0.20s\n",
      "        10      219844.1518            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221068.2834            1.85s\n",
      "         2      220926.7259            1.73s\n",
      "         3      220780.8474            1.53s\n",
      "         4      220640.3002            1.31s\n",
      "         5      220505.8117            1.08s\n",
      "         6      220363.6195            0.87s\n",
      "         7      220223.2301            0.66s\n",
      "         8      220079.1424            0.46s\n",
      "         9      219944.0669            0.23s\n",
      "        10      219809.9561            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221068.2250            1.85s\n",
      "         2      220926.4091            1.67s\n",
      "         3      220780.5917            1.47s\n",
      "         4      220640.1327            1.29s\n",
      "         5      220505.6480            1.07s\n",
      "         6      220363.4261            0.86s\n",
      "         7      220223.0875            0.64s\n",
      "         8      220078.6812            0.43s\n",
      "         9      219943.6841            0.21s\n",
      "        10      219809.7068            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221070.6751            1.86s\n",
      "         2      220929.1466            1.66s\n",
      "         3      220783.6723            1.49s\n",
      "         4      220643.4803            1.28s\n",
      "         5      220509.0295            1.07s\n",
      "         6      220367.0164            0.86s\n",
      "         7      220226.8813            0.64s\n",
      "         8      220082.8787            0.43s\n",
      "         9      219947.8977            0.21s\n",
      "        10      219814.0397            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221065.5503            2.02s\n",
      "         2      220922.9000            1.83s\n",
      "         3      220777.0301            1.60s\n",
      "         4      220632.8368            1.38s\n",
      "         5      220489.3871            1.16s\n",
      "         6      220345.0386            0.93s\n",
      "         7      220203.1967            0.70s\n",
      "         8      220056.4578            0.47s\n",
      "         9      219913.8245            0.24s\n",
      "        10      219773.4366            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221065.6624            2.09s\n",
      "         2      220922.7538            1.90s\n",
      "         3      220776.9450            1.65s\n",
      "         4      220632.8681            1.41s\n",
      "         5      220489.5717            1.18s\n",
      "         6      220344.9539            0.94s\n",
      "         7      220203.1794            0.71s\n",
      "         8      220056.2371            0.47s\n",
      "         9      219913.4604            0.24s\n",
      "        10      219772.9003            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221068.1453            2.05s\n",
      "         2      220925.5256            1.87s\n",
      "         3      220780.0595            1.64s\n",
      "         4      220636.2409            1.40s\n",
      "         5      220493.1860            1.17s\n",
      "         6      220348.8549            0.93s\n",
      "         7      220207.2834            0.70s\n",
      "         8      220060.8014            0.47s\n",
      "         9      219918.2809            0.23s\n",
      "        10      219778.0350            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221066.0960            2.03s\n",
      "         2      220923.4551            1.82s\n",
      "         3      220778.5182            1.60s\n",
      "         4      220637.1320            1.37s\n",
      "         5      220495.7706            1.15s\n",
      "         6      220351.6340            0.94s\n",
      "         7      220208.8962            0.71s\n",
      "         8      220073.4048            0.47s\n",
      "         9      219938.2208            0.24s\n",
      "        10      219802.7708            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221066.1268            2.19s\n",
      "         2      220923.5653            1.94s\n",
      "         3      220778.8360            1.67s\n",
      "         4      220637.3705            1.42s\n",
      "         5      220495.8793            1.19s\n",
      "         6      220351.8893            0.95s\n",
      "         7      220209.2958            0.71s\n",
      "         8      220073.9673            0.47s\n",
      "         9      219938.9217            0.24s\n",
      "        10      219803.6808            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221068.5198            2.05s\n",
      "         2      220926.0809            1.83s\n",
      "         3      220781.6351            1.60s\n",
      "         4      220640.2930            1.37s\n",
      "         5      220499.0014            1.15s\n",
      "         6      220355.3133            0.92s\n",
      "         7      220212.9701            0.69s\n",
      "         8      220077.7749            0.46s\n",
      "         9      219942.7858            0.23s\n",
      "        10      219807.7367            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221061.8113            2.26s\n",
      "         2      220915.7740            2.03s\n",
      "         3      220767.4911            1.77s\n",
      "         4      220624.0498            1.51s\n",
      "         5      220477.8485            1.26s\n",
      "         6      220333.4046            1.01s\n",
      "         7      220188.4897            0.76s\n",
      "         8      220038.0886            0.51s\n",
      "         9      219898.6805            0.25s\n",
      "        10      219754.2748            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221061.6738            2.46s\n",
      "         2      220914.5970            2.34s\n",
      "         3      220766.3102            1.94s\n",
      "         4      220620.9126            1.62s\n",
      "         5      220474.5964            1.34s\n",
      "         6      220330.1437            1.09s\n",
      "         7      220185.3736            0.83s\n",
      "         8      220034.7019            0.54s\n",
      "         9      219895.3096            0.27s\n",
      "        10      219750.3293            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221064.5937            2.28s\n",
      "         2      220918.7173            2.13s\n",
      "         3      220770.8939            1.85s\n",
      "         4      220625.8196            1.59s\n",
      "         5      220480.1961            1.36s\n",
      "         6      220335.9926            1.07s\n",
      "         7      220191.4475            0.80s\n",
      "         8      220041.2450            0.53s\n",
      "         9      219902.0213            0.27s\n",
      "        10      219757.0656            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221059.7053            2.64s\n",
      "         2      220905.6736            2.42s\n",
      "         3      220754.4755            2.11s\n",
      "         4      220603.6968            1.85s\n",
      "         5      220449.8699            1.54s\n",
      "         6      220296.7252            1.23s\n",
      "         7      220143.8651            0.92s\n",
      "         8      219988.4790            0.61s\n",
      "         9      219833.5464            0.31s\n",
      "        10      219682.4606            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221059.8388            2.76s\n",
      "         2      220905.7749            2.48s\n",
      "         3      220754.5899            2.13s\n",
      "         4      220603.7392            1.85s\n",
      "         5      220449.7142            1.56s\n",
      "         6      220296.3772            1.25s\n",
      "         7      220143.0045            0.94s\n",
      "         8      219987.0972            0.62s\n",
      "         9      219831.9022            0.31s\n",
      "        10      219680.2364            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221062.3893            2.67s\n",
      "         2      220908.9422            2.45s\n",
      "         3      220758.2156            2.11s\n",
      "         4      220607.6276            1.80s\n",
      "         5      220454.0959            1.54s\n",
      "         6      220301.2389            1.23s\n",
      "         7      220148.3990            0.92s\n",
      "         8      219993.2646            0.62s\n",
      "         9      219838.6648            0.31s\n",
      "        10      219687.4076            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221050.4387            3.97s\n",
      "         2      220892.3335            3.46s\n",
      "         3      220735.7787            2.99s\n",
      "         4      220576.6053            2.60s\n",
      "         5      220422.1179            2.17s\n",
      "         6      220268.8437            1.74s\n",
      "         7      220113.6270            1.30s\n",
      "         8      219961.0260            0.87s\n",
      "         9      219809.2773            0.44s\n",
      "        10      219661.0112            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221050.4068            4.04s\n",
      "         2      220892.5590            3.49s\n",
      "         3      220735.7976            3.00s\n",
      "         4      220577.3030            2.61s\n",
      "         5      220421.4327            2.20s\n",
      "         6      220265.1803            1.76s\n",
      "         7      220115.2384            1.32s\n",
      "         8      219967.2784            0.88s\n",
      "         9      219815.9097            0.44s\n",
      "        10      219665.4740            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221054.7786            3.90s\n",
      "         2      220897.7095            3.45s\n",
      "         3      220741.2244            2.98s\n",
      "         4      220583.4260            2.60s\n",
      "         5      220427.8164            2.20s\n",
      "         6      220272.3314            1.76s\n",
      "         7      220117.6330            1.34s\n",
      "         8      219967.4145            0.90s\n",
      "         9      219816.3407            0.45s\n",
      "        10      219668.1713            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221051.2010            4.82s\n",
      "         2      220889.2481            4.42s\n",
      "         3      220725.8688            3.79s\n",
      "         4      220566.2776            3.19s\n",
      "         5      220402.7267            2.68s\n",
      "         6      220237.9894            2.13s\n",
      "         7      220071.8857            1.60s\n",
      "         8      219908.0742            1.07s\n",
      "         9      219748.2713            0.53s\n",
      "        10      219590.4443            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221049.9824            4.66s\n",
      "         2      220887.1731            4.38s\n",
      "         3      220723.0574            3.76s\n",
      "         4      220565.0790            3.21s\n",
      "         5      220402.9068            2.68s\n",
      "         6      220235.0050            2.16s\n",
      "         7      220075.2592            1.63s\n",
      "         8      219910.8484            1.08s\n",
      "         9      219752.3689            0.54s\n",
      "        10      219593.3468            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221052.3089            4.74s\n",
      "         2      220891.1524            4.29s\n",
      "         3      220729.1183            3.71s\n",
      "         4      220571.8702            3.19s\n",
      "         5      220408.1502            2.68s\n",
      "         6      220248.2038            2.15s\n",
      "         7      220087.8439            1.62s\n",
      "         8      219924.5709            1.08s\n",
      "         9      219765.3373            0.54s\n",
      "        10      219607.1691            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221038.1135            7.32s\n",
      "         2      220867.7343            6.38s\n",
      "         3      220697.7194            5.61s\n",
      "         4      220526.3207            4.96s\n",
      "         5      220358.6717            4.15s\n",
      "         6      220187.9846            3.30s\n",
      "         7      220019.7539            2.47s\n",
      "         8      219850.0779            1.63s\n",
      "         9      219682.3816            0.81s\n",
      "        10      219516.9512            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221037.5582            7.08s\n",
      "         2      220865.2078            6.28s\n",
      "         3      220695.0760            5.59s\n",
      "         4      220523.5203            4.73s\n",
      "         5      220355.3980            3.88s\n",
      "         6      220187.7278            3.10s\n",
      "         7      220016.8231            2.32s\n",
      "         8      219847.7754            1.55s\n",
      "         9      219679.6524            0.77s\n",
      "        10      219509.4568            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221040.5591            7.07s\n",
      "         2      220868.9829            6.26s\n",
      "         3      220699.4999            5.52s\n",
      "         4      220528.5019            4.68s\n",
      "         5      220360.8693            3.87s\n",
      "         6      220189.8444            3.12s\n",
      "         7      220020.6577            2.34s\n",
      "         8      219850.6034            1.56s\n",
      "         9      219683.2836            0.78s\n",
      "        10      219517.7462            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221039.5510            9.44s\n",
      "         2      220867.4061            8.14s\n",
      "         3      220703.5072            7.11s\n",
      "         4      220532.5700            6.16s\n",
      "         5      220368.6136            5.14s\n",
      "         6      220201.9447            4.11s\n",
      "         7      220038.0672            3.06s\n",
      "         8      219878.8482            2.06s\n",
      "         9      219716.7109            1.03s\n",
      "        10      219558.9411            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221041.5116            9.05s\n",
      "         2      220875.1767            7.89s\n",
      "         3      220708.5795            6.90s\n",
      "         4      220534.7597            5.97s\n",
      "         5      220370.1133            5.03s\n",
      "         6      220202.2714            4.05s\n",
      "         7      220037.6216            3.08s\n",
      "         8      219877.9018            2.04s\n",
      "         9      219713.8500            1.03s\n",
      "        10      219554.0760            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221045.3141            9.56s\n",
      "         2      220876.6553            8.11s\n",
      "         3      220710.4682            7.03s\n",
      "         4      220542.2542            6.00s\n",
      "         5      220374.7275            5.08s\n",
      "         6      220208.3191            4.11s\n",
      "         7      220042.3213            3.05s\n",
      "         8      219881.8952            2.05s\n",
      "         9      219721.3861            1.03s\n",
      "        10      219561.9621            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221036.5907           11.58s\n",
      "         2      220861.6646           10.49s\n",
      "         3      220690.3220            9.13s\n",
      "         4      220516.7680            7.74s\n",
      "         5      220347.2457            6.53s\n",
      "         6      220175.4432            5.25s\n",
      "         7      220007.8258            3.96s\n",
      "         8      219835.4330            2.65s\n",
      "         9      219663.6990            1.33s\n",
      "        10      219497.4421            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221034.3650           11.72s\n",
      "         2      220859.9810           10.66s\n",
      "         3      220685.6340            9.32s\n",
      "         4      220520.4450            7.88s\n",
      "         5      220352.0633            6.82s\n",
      "         6      220179.5600            5.45s\n",
      "         7      220003.9234            4.09s\n",
      "         8      219831.9193            2.71s\n",
      "         9      219660.5615            1.36s\n",
      "        10      219493.4318            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221036.7703           13.29s\n",
      "         2      220864.1459           11.44s\n",
      "         3      220694.4626            9.73s\n",
      "         4      220520.9551            8.14s\n",
      "         5      220350.5356            6.76s\n",
      "         6      220176.7374            5.38s\n",
      "         7      220011.4209            4.04s\n",
      "         8      219840.5971            2.69s\n",
      "         9      219669.6902            1.35s\n",
      "        10      219501.3070            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221029.0227           19.68s\n",
      "         2      220848.1024           17.16s\n",
      "         3      220667.0519           15.08s\n",
      "         4      220486.5999           13.08s\n",
      "         5      220308.6893           11.02s\n",
      "         6      220132.4305            9.31s\n",
      "         7      219953.8845            7.12s\n",
      "         8      219775.7148            4.70s\n",
      "         9      219598.2563            2.33s\n",
      "        10      219422.6728            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221027.8951           18.50s\n",
      "         2      220846.6900           16.40s\n",
      "         3      220665.2390           14.39s\n",
      "         4      220484.7125           12.36s\n",
      "         5      220305.6500           10.23s\n",
      "         6      220124.6829            8.33s\n",
      "         7      219946.1537            6.31s\n",
      "         8      219767.1418            4.21s\n",
      "         9      219591.4560            2.11s\n",
      "        10      219413.4741            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221029.2392           18.66s\n",
      "         2      220849.1558           16.23s\n",
      "         3      220669.1504           14.48s\n",
      "         4      220488.9698           12.38s\n",
      "         5      220310.3185           10.25s\n",
      "         6      220133.2188            8.27s\n",
      "         7      219956.9361            6.26s\n",
      "         8      219778.8389            4.16s\n",
      "         9      219602.9812            2.09s\n",
      "        10      219424.4665            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      324046.9893           31.11s\n",
      "         2      316613.4970           28.00s\n",
      "         3      309736.3845           24.57s\n",
      "         4      303344.6531           20.98s\n",
      "         5      297389.2506           17.37s\n",
      "         6      291771.0689           13.98s\n",
      "         7      286571.4629           10.63s\n",
      "         8      281691.6907            7.09s\n",
      "         9      277081.5220            3.54s\n",
      "        10      272783.4891            0.00s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, fbeta_score, accuracy_score\n",
    "\n",
    "\n",
    "# TODO: Initialize the classifier\n",
    "clf = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "# TODO: Create the parameters list you wish to tune, using a dictionary if needed.\n",
    "# HINT: parameters = {'parameter_1': [value1, value2], 'parameter_2': [value1, value2]}\n",
    "parameters = {\n",
    "    'learning_rate': [0.01, 0.03, 0.001],\n",
    "    'n_estimators': [10],\n",
    "    'max_depth': [1, 2, 5, 8],\n",
    "    'max_features': [5, 8, 16],\n",
    "    'verbose': [1],\n",
    "    'random_state': [2]\n",
    "}\n",
    "\n",
    "# TODO: Make an fbeta_score scoring object using make_scorer()\n",
    "# scorer = make_scorer(fbeta_score, beta=0.5, needs_proba=True)\n",
    "# scorer = make_scorer(fbeta_score, beta=0.5, average='samples')\n",
    "scorer = make_scorer(accuracy_score)\n",
    "\n",
    "# TODO: Perform grid search on the classifier using 'scorer' as the scoring method using GridSearchCV()\n",
    "grid_obj = GridSearchCV(clf, parameters, scoring=scorer)\n",
    "\n",
    "# TODO: Fit the grid search object to the training data and find the optimal parameters using fit()\n",
    "rows, cols = y_train.shape\n",
    "grid_fit = grid_obj.fit(X_train, y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unoptimized model\n",
      "------\n",
      "Accuracy score on testing data: 0.7265\n",
      "F-score on testing data: 0.6438\n",
      "\n",
      "Optimized Model\n",
      "------\n",
      "Final accuracy score on the testing data: 0.7141\n",
      "Final F-score on the testing data: 0.5826\n"
     ]
    }
   ],
   "source": [
    "# Get the estimator\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "# Make predictions using the unoptimized and model\n",
    "predictions = (clf.fit(X_train, y_train[1])).predict(X_test)\n",
    "best_predictions = best_clf.predict(X_test)\n",
    "\n",
    "# Report the before-and-afterscores\n",
    "print(\"Unoptimized model\\n------\")\n",
    "print(\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test[1], predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test[1], predictions, beta = 0.5, average='weighted')))\n",
    "print(\"\\nOptimized Model\\n------\")\n",
    "print(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
    "print(\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test[1], best_predictions, beta = 0.5, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_s = pd.Series(y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "# TODO: Initialize the classifier\n",
    "clf = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "# TODO: Create the parameters list you wish to tune, using a dictionary if needed.\n",
    "# HINT: parameters = {'parameter_1': [value1, value2], 'parameter_2': [value1, value2]}\n",
    "parameters = {\n",
    "    'learning_rate': [0.01, 0.03, 0.001],\n",
    "    'n_estimators': [10],\n",
    "    'max_depth': [8],\n",
    "    'max_features': [5],\n",
    "    'verbose': [1],\n",
    "    'random_state': [2]\n",
    "}\n",
    "\n",
    "# TODO: Make an fbeta_score scoring object using make_scorer()\n",
    "# scorer = make_scorer(fbeta_score, beta=0.5, needs_proba=True)\n",
    "# scorer = make_scorer(fbeta_score, beta=0.5, average='samples')\n",
    "scorer = make_scorer(accuracy_score)\n",
    "\n",
    "# TODO: Perform grid search on the classifier using 'scorer' as the scoring method using GridSearchCV()\n",
    "grid_obj = GridSearchCV(clf, parameters, scoring=scorer)\n",
    "\n",
    "# TODO: Fit the grid search object to the training data and find the optimal parameters using fit()\n",
    "rows, cols = y_train.shape\n",
    "grid_fit = grid_obj.fit(X_train, y_train[1])\n",
    "\n",
    "# Get the estimator\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "# Make predictions using the unoptimized and model\n",
    "predictions = (clf.fit(X_train, y_train[1])).predict(X_test)\n",
    "best_predictions = best_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Report the before-and-afterscores\n",
    "print(\"Unoptimized model\\n------\")\n",
    "print(\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test[1], predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test[1], predictions, beta = 0.5, average='weighted')))\n",
    "print(\"\\nOptimized Model\\n------\")\n",
    "print(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
    "print(\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test[1], best_predictions, beta = 0.5, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.get_dummies(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_clf.predict_proba(pd.get_dummies(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "# Report the before-and-afterscores\n",
    "print(\"Unoptimized model\\n------\")\n",
    "print(\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test[1], predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test[1], predictions, beta = 0.5, average='weighted')))\n",
    "print(\"Log loss score on testing data: {:.4f}\".format(log_loss(y_test[1], best_clf.predict_proba(pd.get_dummies(X_test)), 0.5)))\n",
    "print(\"\\nOptimized Model\\n------\")\n",
    "print(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
    "print(\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test[1], best_predictions, beta = 0.5, average='weighted')))\n",
    "print(\"Log loss score on testing data: {:.4f}\".format(log_loss(y_test[1], best_clf.predict_proba(pd.get_dummies(X_test)), 0.5)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost un/optimized model performance\n",
    "\n",
    "average = 'weighted':\n",
    "```\n",
    "Unoptimized model\n",
    "------\n",
    "Accuracy score on testing data: 0.7220\n",
    "F-score on testing data: 0.6347\n",
    "\n",
    "Optimized Model\n",
    "------\n",
    "Final accuracy score on the testing data: 0.7066\n",
    "Final F-score on the testing data: 0.5718\n",
    "```\n",
    "\n",
    "average = 'samples':\n",
    "```\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ticket', 'Arrest', 'Summons', 'Verbal Warning', 'Written Warning'], dtype=object)"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "codes = {\n",
    "    'Ticket': 1,\n",
    "    'Arrest': 2,\n",
    "    'Summons': 3,\n",
    "    'Verbal Warning': 4,\n",
    "    'Written Warning': 5,\n",
    "}\n",
    "\n",
    "def labels_to_ints(label):\n",
    "    return codes[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, ..., 1, 1, 3], dtype=int64)"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted = y_train[1].apply(labels_to_ints)\n",
    "converted.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xg_train = xgb.DMatrix(X_train.values, label=y_train[1].apply(labels_to_ints).values)\n",
    "xg_test = xgb.DMatrix(X_test.values, label=y_test[1].apply(labels_to_ints).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     'objective': 'multi:softmax',\n",
    "#     'eta': 0.1,\n",
    "#     'max_depth': 6,\n",
    "#     'silent': 1,\n",
    "#     'nthread': 4,\n",
    "#     'num_class': 6,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'multi:softmax',\n",
    "#     'learning_rate': .03,\n",
    "    'max_depth': 10,\n",
    "    'silent': 1,\n",
    "    'nthread': 6,\n",
    "    'num_class': 7,\n",
    "#     'predictor': 'gpu_predictor',\n",
    "#     'max_bin': 512,\n",
    "    'tree_method': 'gpu_hist',\n",
    "#     'alpha': 0.8,\n",
    "#     'gamma': 10.0,\n",
    "    'subsample': 0.6,\n",
    "#     'lambda': 0.9,,\n",
    "#     'colsample_bytree': 0.9,\n",
    "#     'colsample_bylevel': 0.3,\n",
    "#     'scale_pos_weight': 0.1,\n",
    "#     'updater': 'grow_histmaker,refresh,prune',\n",
    "#     'grow_policy': 'lossguide',\n",
    "#     'max_leaves': 20000,\n",
    "#     'max_bin': 1024,\n",
    "#     'base_score': 1.0,\n",
    "#     'eval_metric': 'ndcg',\n",
    "#     'max_delta_step': 8,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.269481\ttest-merror:0.27487\n",
      "[1]\ttrain-merror:0.267585\ttest-merror:0.273035\n",
      "[2]\ttrain-merror:0.266568\ttest-merror:0.272013\n",
      "[3]\ttrain-merror:0.265718\ttest-merror:0.272077\n",
      "[4]\ttrain-merror:0.265279\ttest-merror:0.27187\n",
      "[5]\ttrain-merror:0.264561\ttest-merror:0.27187\n",
      "[6]\ttrain-merror:0.26409\ttest-merror:0.271838\n",
      "[7]\ttrain-merror:0.263743\ttest-merror:0.271471\n",
      "[8]\ttrain-merror:0.263276\ttest-merror:0.271423\n",
      "[9]\ttrain-merror:0.262502\ttest-merror:0.271407\n",
      "[10]\ttrain-merror:0.261756\ttest-merror:0.270928\n",
      "[11]\ttrain-merror:0.261157\ttest-merror:0.271008\n",
      "[12]\ttrain-merror:0.260627\ttest-merror:0.271024\n",
      "[13]\ttrain-merror:0.260136\ttest-merror:0.271008\n",
      "[14]\ttrain-merror:0.259617\ttest-merror:0.270896\n",
      "[15]\ttrain-merror:0.259031\ttest-merror:0.270641\n",
      "[16]\ttrain-merror:0.258604\ttest-merror:0.270768\n",
      "[17]\ttrain-merror:0.258085\ttest-merror:0.270497\n"
     ]
    }
   ],
   "source": [
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "num_round = 18\n",
    "bst = xgb.train(params, xg_train, num_round, watchlist)\n",
    "pred = bst.predict(xg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error using softmax = 0.2704971670257761\n"
     ]
    }
   ],
   "source": [
    "error_rate = np.sum(pred != y_test[1].apply(labels_to_ints).values) / y_test[1].shape[0]\n",
    "print('Test error using softmax = {}'.format(error_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.269481\ttest-merror:0.27487\n",
      "[1]\ttrain-merror:0.267585\ttest-merror:0.273035\n",
      "[2]\ttrain-merror:0.266568\ttest-merror:0.272013\n",
      "[3]\ttrain-merror:0.265718\ttest-merror:0.272077\n",
      "[4]\ttrain-merror:0.265279\ttest-merror:0.27187\n",
      "[5]\ttrain-merror:0.264561\ttest-merror:0.27187\n",
      "[6]\ttrain-merror:0.26409\ttest-merror:0.271838\n",
      "[7]\ttrain-merror:0.263743\ttest-merror:0.271471\n",
      "[8]\ttrain-merror:0.263276\ttest-merror:0.271423\n",
      "[9]\ttrain-merror:0.262502\ttest-merror:0.271407\n",
      "[10]\ttrain-merror:0.261756\ttest-merror:0.270928\n",
      "[11]\ttrain-merror:0.261157\ttest-merror:0.271008\n",
      "[12]\ttrain-merror:0.260627\ttest-merror:0.271024\n",
      "[13]\ttrain-merror:0.260136\ttest-merror:0.271008\n",
      "[14]\ttrain-merror:0.259617\ttest-merror:0.270896\n",
      "[15]\ttrain-merror:0.259031\ttest-merror:0.270641\n",
      "[16]\ttrain-merror:0.258604\ttest-merror:0.270768\n",
      "[17]\ttrain-merror:0.258085\ttest-merror:0.270497\n",
      "Test error using softprob = 0.2704971670257761\n"
     ]
    }
   ],
   "source": [
    "params['objective'] = 'multi:softprob'\n",
    "bst = xgb.train(params, xg_train, num_round, watchlist)\n",
    "pred_prob = bst.predict(xg_test).reshape(y_test[1].shape[0], 7)\n",
    "pred_label = np.argmax(pred_prob, axis=1)\n",
    "error_rate = np.sum(pred_label != y_test[1].apply(labels_to_ints).values) / y_test[1].shape[0]\n",
    "print('Test error using softprob = {}'.format(error_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
