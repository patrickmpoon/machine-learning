{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import humanize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "final_features = pd.read_csv('./final_features.csv', header=0, index_col=0)\n",
    "outcomes = pd.read_csv('./labels.csv', header=None, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313274, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313274, 43)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driver_age_raw</th>\n",
       "      <th>search_conducted</th>\n",
       "      <th>contraband_found</th>\n",
       "      <th>is_male</th>\n",
       "      <th>violation_cell_phone</th>\n",
       "      <th>violation_display_of_plates</th>\n",
       "      <th>violation_equipment</th>\n",
       "      <th>violation_incomplete_stop</th>\n",
       "      <th>violation_license</th>\n",
       "      <th>violation_lights</th>\n",
       "      <th>...</th>\n",
       "      <th>stop_duration_16-30 min</th>\n",
       "      <th>stop_duration_30+ min</th>\n",
       "      <th>day_period_Afternoon</th>\n",
       "      <th>day_period_Evening</th>\n",
       "      <th>day_period_Morning</th>\n",
       "      <th>day_period_Small Hours</th>\n",
       "      <th>season_Fall</th>\n",
       "      <th>season_Spring</th>\n",
       "      <th>season_Summer</th>\n",
       "      <th>season_Winter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.69697</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   driver_age_raw  search_conducted  contraband_found  is_male  \\\n",
       "0         0.69697                 0                 0        0   \n",
       "\n",
       "   violation_cell_phone  violation_display_of_plates  violation_equipment  \\\n",
       "0                     0                            0                    0   \n",
       "\n",
       "   violation_incomplete_stop  violation_license  violation_lights  \\\n",
       "0                          0                  0                 0   \n",
       "\n",
       "       ...        stop_duration_16-30 min  stop_duration_30+ min  \\\n",
       "0      ...                              0                      0   \n",
       "\n",
       "   day_period_Afternoon  day_period_Evening  day_period_Morning  \\\n",
       "0                     0                   0                   0   \n",
       "\n",
       "   day_period_Small Hours  season_Fall  season_Spring  season_Summer  \\\n",
       "0                       1            1              0              0   \n",
       "\n",
       "   season_Winter  \n",
       "0              0  \n",
       "\n",
       "[1 rows x 43 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_features.iloc[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driver_age_raw</th>\n",
       "      <th>search_conducted</th>\n",
       "      <th>contraband_found</th>\n",
       "      <th>is_male</th>\n",
       "      <th>violation_cell_phone</th>\n",
       "      <th>violation_display_of_plates</th>\n",
       "      <th>violation_equipment</th>\n",
       "      <th>violation_incomplete_stop</th>\n",
       "      <th>violation_license</th>\n",
       "      <th>violation_lights</th>\n",
       "      <th>...</th>\n",
       "      <th>stop_duration_16-30 min</th>\n",
       "      <th>stop_duration_30+ min</th>\n",
       "      <th>day_period_Afternoon</th>\n",
       "      <th>day_period_Evening</th>\n",
       "      <th>day_period_Morning</th>\n",
       "      <th>day_period_Small Hours</th>\n",
       "      <th>season_Fall</th>\n",
       "      <th>season_Spring</th>\n",
       "      <th>season_Summer</th>\n",
       "      <th>season_Winter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>318668</th>\n",
       "      <td>0.191919</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        driver_age_raw  search_conducted  contraband_found  is_male  \\\n",
       "318668        0.191919                 0                 0        1   \n",
       "\n",
       "        violation_cell_phone  violation_display_of_plates  \\\n",
       "318668                     0                            0   \n",
       "\n",
       "        violation_equipment  violation_incomplete_stop  violation_license  \\\n",
       "318668                    0                          0                  0   \n",
       "\n",
       "        violation_lights      ...        stop_duration_16-30 min  \\\n",
       "318668                 0      ...                              0   \n",
       "\n",
       "        stop_duration_30+ min  day_period_Afternoon  day_period_Evening  \\\n",
       "318668                      0                     1                   0   \n",
       "\n",
       "        day_period_Morning  day_period_Small Hours  season_Fall  \\\n",
       "318668                   0                       0            0   \n",
       "\n",
       "        season_Spring  season_Summer  season_Winter  \n",
       "318668              1              0              0  \n",
       "\n",
       "[1 rows x 43 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_features.iloc[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>318668</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             1\n",
       "0             \n",
       "318668  Ticket"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes.iloc[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Verbal Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Written Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Verbal Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Verbal Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Verbal Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Verbal Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Verbal Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Verbal Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Verbal Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Verbal Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Verbal Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Verbal Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Written Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Verbal Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318639</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318640</th>\n",
       "      <td>Verbal Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318641</th>\n",
       "      <td>Verbal Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318642</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318643</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318644</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318645</th>\n",
       "      <td>Verbal Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318646</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318647</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318648</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318649</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318650</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318651</th>\n",
       "      <td>Verbal Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318652</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318653</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318654</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318655</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318656</th>\n",
       "      <td>Arrest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318657</th>\n",
       "      <td>Verbal Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318658</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318659</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318660</th>\n",
       "      <td>Verbal Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318661</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318662</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318663</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318664</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318665</th>\n",
       "      <td>Written Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318666</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318667</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318668</th>\n",
       "      <td>Ticket</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>313274 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      1\n",
       "0                      \n",
       "0                Ticket\n",
       "1        Verbal Warning\n",
       "2                Ticket\n",
       "3       Written Warning\n",
       "4                Ticket\n",
       "5        Verbal Warning\n",
       "6                Ticket\n",
       "7        Verbal Warning\n",
       "8                Ticket\n",
       "9        Verbal Warning\n",
       "10               Ticket\n",
       "11       Verbal Warning\n",
       "12       Verbal Warning\n",
       "13               Ticket\n",
       "14               Ticket\n",
       "15               Ticket\n",
       "16       Verbal Warning\n",
       "17       Verbal Warning\n",
       "18       Verbal Warning\n",
       "19               Ticket\n",
       "20       Verbal Warning\n",
       "21       Verbal Warning\n",
       "22               Ticket\n",
       "23               Ticket\n",
       "24               Ticket\n",
       "25               Ticket\n",
       "26      Written Warning\n",
       "27               Ticket\n",
       "28       Verbal Warning\n",
       "29               Ticket\n",
       "...                 ...\n",
       "318639           Ticket\n",
       "318640   Verbal Warning\n",
       "318641   Verbal Warning\n",
       "318642           Ticket\n",
       "318643           Ticket\n",
       "318644           Ticket\n",
       "318645   Verbal Warning\n",
       "318646           Ticket\n",
       "318647           Ticket\n",
       "318648           Ticket\n",
       "318649           Ticket\n",
       "318650           Ticket\n",
       "318651   Verbal Warning\n",
       "318652           Ticket\n",
       "318653           Ticket\n",
       "318654           Ticket\n",
       "318655           Ticket\n",
       "318656           Arrest\n",
       "318657   Verbal Warning\n",
       "318658           Ticket\n",
       "318659           Ticket\n",
       "318660   Verbal Warning\n",
       "318661           Ticket\n",
       "318662           Ticket\n",
       "318663           Ticket\n",
       "318664           Ticket\n",
       "318665  Written Warning\n",
       "318666           Ticket\n",
       "318667           Ticket\n",
       "318668           Ticket\n",
       "\n",
       "[313274 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driver_age_raw</th>\n",
       "      <th>search_conducted</th>\n",
       "      <th>contraband_found</th>\n",
       "      <th>is_male</th>\n",
       "      <th>violation_cell_phone</th>\n",
       "      <th>violation_display_of_plates</th>\n",
       "      <th>violation_equipment</th>\n",
       "      <th>violation_incomplete_stop</th>\n",
       "      <th>violation_license</th>\n",
       "      <th>violation_lights</th>\n",
       "      <th>...</th>\n",
       "      <th>stop_duration_16-30 min</th>\n",
       "      <th>stop_duration_30+ min</th>\n",
       "      <th>day_period_Afternoon</th>\n",
       "      <th>day_period_Evening</th>\n",
       "      <th>day_period_Morning</th>\n",
       "      <th>day_period_Small Hours</th>\n",
       "      <th>season_Fall</th>\n",
       "      <th>season_Spring</th>\n",
       "      <th>season_Summer</th>\n",
       "      <th>season_Winter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.696970</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.202020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.343434</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.464646</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.303030</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   driver_age_raw  search_conducted  contraband_found  is_male  \\\n",
       "0        0.696970                 0                 0        0   \n",
       "1        0.202020                 0                 0        1   \n",
       "2        0.343434                 0                 0        1   \n",
       "3        0.464646                 0                 0        1   \n",
       "4        0.303030                 0                 0        1   \n",
       "\n",
       "   violation_cell_phone  violation_display_of_plates  violation_equipment  \\\n",
       "0                     0                            0                    0   \n",
       "1                     0                            0                    0   \n",
       "2                     0                            0                    0   \n",
       "3                     0                            0                    0   \n",
       "4                     0                            0                    0   \n",
       "\n",
       "   violation_incomplete_stop  violation_license  violation_lights  \\\n",
       "0                          0                  0                 0   \n",
       "1                          0                  0                 0   \n",
       "2                          0                  0                 0   \n",
       "3                          0                  0                 0   \n",
       "4                          0                  0                 0   \n",
       "\n",
       "       ...        stop_duration_16-30 min  stop_duration_30+ min  \\\n",
       "0      ...                              0                      0   \n",
       "1      ...                              0                      0   \n",
       "2      ...                              0                      0   \n",
       "3      ...                              0                      0   \n",
       "4      ...                              0                      0   \n",
       "\n",
       "   day_period_Afternoon  day_period_Evening  day_period_Morning  \\\n",
       "0                     0                   0                   0   \n",
       "1                     0                   0                   0   \n",
       "2                     0                   0                   0   \n",
       "3                     0                   0                   0   \n",
       "4                     0                   0                   0   \n",
       "\n",
       "   day_period_Small Hours  season_Fall  season_Spring  season_Summer  \\\n",
       "0                       1            1              0              0   \n",
       "1                       1            1              0              0   \n",
       "2                       1            1              0              0   \n",
       "3                       1            1              0              0   \n",
       "4                       1            1              0              0   \n",
       "\n",
       "   season_Winter  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 313274 entries, 0 to 318668\n",
      "Data columns (total 43 columns):\n",
      "driver_age_raw                      313274 non-null float64\n",
      "search_conducted                    313274 non-null int64\n",
      "contraband_found                    313274 non-null int64\n",
      "is_male                             313274 non-null int64\n",
      "violation_cell_phone                313274 non-null int64\n",
      "violation_display_of_plates         313274 non-null int64\n",
      "violation_equipment                 313274 non-null int64\n",
      "violation_incomplete_stop           313274 non-null int64\n",
      "violation_license                   313274 non-null int64\n",
      "violation_lights                    313274 non-null int64\n",
      "violation_moving_violation          313274 non-null int64\n",
      "violation_other                     313274 non-null int64\n",
      "violation_registration              313274 non-null int64\n",
      "violation_safe_movement             313274 non-null int64\n",
      "violation_seatbelt                  313274 non-null int64\n",
      "violation_speeding                  313274 non-null int64\n",
      "violation_suspended_license         313274 non-null int64\n",
      "violation_traffic_control_signal    313274 non-null int64\n",
      "violation_window_tint               313274 non-null int64\n",
      "county_name_Fairfield County        313274 non-null int64\n",
      "county_name_Hartford County         313274 non-null int64\n",
      "county_name_Litchfield County       313274 non-null int64\n",
      "county_name_Middlesex County        313274 non-null int64\n",
      "county_name_New Haven County        313274 non-null int64\n",
      "county_name_New London County       313274 non-null int64\n",
      "county_name_Tolland County          313274 non-null int64\n",
      "county_name_Windham County          313274 non-null int64\n",
      "driver_race_Asian                   313274 non-null int64\n",
      "driver_race_Black                   313274 non-null int64\n",
      "driver_race_Hispanic                313274 non-null int64\n",
      "driver_race_Other                   313274 non-null int64\n",
      "driver_race_White                   313274 non-null int64\n",
      "stop_duration_1-15 min              313274 non-null int64\n",
      "stop_duration_16-30 min             313274 non-null int64\n",
      "stop_duration_30+ min               313274 non-null int64\n",
      "day_period_Afternoon                313274 non-null int64\n",
      "day_period_Evening                  313274 non-null int64\n",
      "day_period_Morning                  313274 non-null int64\n",
      "day_period_Small Hours              313274 non-null int64\n",
      "season_Fall                         313274 non-null int64\n",
      "season_Spring                       313274 non-null int64\n",
      "season_Summer                       313274 non-null int64\n",
      "season_Winter                       313274 non-null int64\n",
      "dtypes: float64(1), int64(42)\n",
      "memory usage: 105.2 MB\n"
     ]
    }
   ],
   "source": [
    "final_features.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driver_age_raw</th>\n",
       "      <th>search_conducted</th>\n",
       "      <th>contraband_found</th>\n",
       "      <th>is_male</th>\n",
       "      <th>violation_cell_phone</th>\n",
       "      <th>violation_display_of_plates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.384508</td>\n",
       "      <td>0.016848</td>\n",
       "      <td>0.005771</td>\n",
       "      <td>0.663946</td>\n",
       "      <td>0.063890</td>\n",
       "      <td>0.018415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.145742</td>\n",
       "      <td>0.128701</td>\n",
       "      <td>0.075750</td>\n",
       "      <td>0.472358</td>\n",
       "      <td>0.244557</td>\n",
       "      <td>0.134447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.262626</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.353535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.494949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       driver_age_raw  search_conducted  contraband_found        is_male  \\\n",
       "count   313274.000000     313274.000000     313274.000000  313274.000000   \n",
       "mean         0.384508          0.016848          0.005771       0.663946   \n",
       "std          0.145742          0.128701          0.075750       0.472358   \n",
       "min          0.000000          0.000000          0.000000       0.000000   \n",
       "25%          0.262626          0.000000          0.000000       0.000000   \n",
       "50%          0.353535          0.000000          0.000000       1.000000   \n",
       "75%          0.494949          0.000000          0.000000       1.000000   \n",
       "max          1.000000          1.000000          1.000000       1.000000   \n",
       "\n",
       "       violation_cell_phone  violation_display_of_plates  \n",
       "count         313274.000000                313274.000000  \n",
       "mean               0.063890                     0.018415  \n",
       "std                0.244557                     0.134447  \n",
       "min                0.000000                     0.000000  \n",
       "25%                0.000000                     0.000000  \n",
       "50%                0.000000                     0.000000  \n",
       "75%                0.000000                     0.000000  \n",
       "max                1.000000                     1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description = final_features.describe()\n",
    "description.iloc[:,:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['driver_age_raw', 'search_conducted', 'contraband_found', 'is_male',\n",
       "       'violation_cell_phone', 'violation_display_of_plates',\n",
       "       'violation_equipment', 'violation_incomplete_stop',\n",
       "       'violation_license', 'violation_lights',\n",
       "       'violation_moving_violation', 'violation_other',\n",
       "       'violation_registration', 'violation_safe_movement',\n",
       "       'violation_seatbelt', 'violation_speeding',\n",
       "       'violation_suspended_license', 'violation_traffic_control_signal',\n",
       "       'violation_window_tint', 'county_name_Fairfield County',\n",
       "       'county_name_Hartford County', 'county_name_Litchfield County',\n",
       "       'county_name_Middlesex County', 'county_name_New Haven County',\n",
       "       'county_name_New London County', 'county_name_Tolland County',\n",
       "       'county_name_Windham County', 'driver_race_Asian',\n",
       "       'driver_race_Black', 'driver_race_Hispanic', 'driver_race_Other',\n",
       "       'driver_race_White', 'stop_duration_1-15 min',\n",
       "       'stop_duration_16-30 min', 'stop_duration_30+ min',\n",
       "       'day_period_Afternoon', 'day_period_Evening', 'day_period_Morning',\n",
       "       'day_period_Small Hours', 'season_Fall', 'season_Spring',\n",
       "       'season_Summer', 'season_Winter'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>violation_equipment</th>\n",
       "      <th>violation_incomplete_stop</th>\n",
       "      <th>violation_license</th>\n",
       "      <th>violation_lights</th>\n",
       "      <th>violation_moving_violation</th>\n",
       "      <th>violation_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.009442</td>\n",
       "      <td>0.022673</td>\n",
       "      <td>0.009366</td>\n",
       "      <td>0.038647</td>\n",
       "      <td>0.089133</td>\n",
       "      <td>0.278989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.096711</td>\n",
       "      <td>0.148860</td>\n",
       "      <td>0.096322</td>\n",
       "      <td>0.192752</td>\n",
       "      <td>0.284936</td>\n",
       "      <td>0.448503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       violation_equipment  violation_incomplete_stop  violation_license  \\\n",
       "count        313274.000000              313274.000000      313274.000000   \n",
       "mean              0.009442                   0.022673           0.009366   \n",
       "std               0.096711                   0.148860           0.096322   \n",
       "min               0.000000                   0.000000           0.000000   \n",
       "25%               0.000000                   0.000000           0.000000   \n",
       "50%               0.000000                   0.000000           0.000000   \n",
       "75%               0.000000                   0.000000           0.000000   \n",
       "max               1.000000                   1.000000           1.000000   \n",
       "\n",
       "       violation_lights  violation_moving_violation  violation_other  \n",
       "count     313274.000000               313274.000000    313274.000000  \n",
       "mean           0.038647                    0.089133         0.278989  \n",
       "std            0.192752                    0.284936         0.448503  \n",
       "min            0.000000                    0.000000         0.000000  \n",
       "25%            0.000000                    0.000000         0.000000  \n",
       "50%            0.000000                    0.000000         0.000000  \n",
       "75%            0.000000                    0.000000         1.000000  \n",
       "max            1.000000                    1.000000         1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description.iloc[:,6:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>violation_registration</th>\n",
       "      <th>violation_safe_movement</th>\n",
       "      <th>violation_seatbelt</th>\n",
       "      <th>violation_speeding</th>\n",
       "      <th>violation_suspended_license</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.119927</td>\n",
       "      <td>0.015989</td>\n",
       "      <td>0.038592</td>\n",
       "      <td>0.321147</td>\n",
       "      <td>0.009366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.324877</td>\n",
       "      <td>0.125434</td>\n",
       "      <td>0.192622</td>\n",
       "      <td>0.466918</td>\n",
       "      <td>0.096322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       violation_registration  violation_safe_movement  violation_seatbelt  \\\n",
       "count           313274.000000            313274.000000       313274.000000   \n",
       "mean                 0.119927                 0.015989            0.038592   \n",
       "std                  0.324877                 0.125434            0.192622   \n",
       "min                  0.000000                 0.000000            0.000000   \n",
       "25%                  0.000000                 0.000000            0.000000   \n",
       "50%                  0.000000                 0.000000            0.000000   \n",
       "75%                  0.000000                 0.000000            0.000000   \n",
       "max                  1.000000                 1.000000            1.000000   \n",
       "\n",
       "       violation_speeding  violation_suspended_license  \n",
       "count       313274.000000                313274.000000  \n",
       "mean             0.321147                     0.009366  \n",
       "std              0.466918                     0.096322  \n",
       "min              0.000000                     0.000000  \n",
       "25%              0.000000                     0.000000  \n",
       "50%              0.000000                     0.000000  \n",
       "75%              1.000000                     0.000000  \n",
       "max              1.000000                     1.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description.iloc[:,12:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>violation_traffic_control_signal</th>\n",
       "      <th>violation_window_tint</th>\n",
       "      <th>county_name_Fairfield County</th>\n",
       "      <th>county_name_Hartford County</th>\n",
       "      <th>county_name_Litchfield County</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.015989</td>\n",
       "      <td>0.007221</td>\n",
       "      <td>0.132118</td>\n",
       "      <td>0.125571</td>\n",
       "      <td>0.085551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.125434</td>\n",
       "      <td>0.084666</td>\n",
       "      <td>0.338619</td>\n",
       "      <td>0.331365</td>\n",
       "      <td>0.279701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       violation_traffic_control_signal  violation_window_tint  \\\n",
       "count                     313274.000000          313274.000000   \n",
       "mean                           0.015989               0.007221   \n",
       "std                            0.125434               0.084666   \n",
       "min                            0.000000               0.000000   \n",
       "25%                            0.000000               0.000000   \n",
       "50%                            0.000000               0.000000   \n",
       "75%                            0.000000               0.000000   \n",
       "max                            1.000000               1.000000   \n",
       "\n",
       "       county_name_Fairfield County  county_name_Hartford County  \\\n",
       "count                 313274.000000                313274.000000   \n",
       "mean                       0.132118                     0.125571   \n",
       "std                        0.338619                     0.331365   \n",
       "min                        0.000000                     0.000000   \n",
       "25%                        0.000000                     0.000000   \n",
       "50%                        0.000000                     0.000000   \n",
       "75%                        0.000000                     0.000000   \n",
       "max                        1.000000                     1.000000   \n",
       "\n",
       "       county_name_Litchfield County  \n",
       "count                  313274.000000  \n",
       "mean                        0.085551  \n",
       "std                         0.279701  \n",
       "min                         0.000000  \n",
       "25%                         0.000000  \n",
       "50%                         0.000000  \n",
       "75%                         0.000000  \n",
       "max                         1.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description.iloc[:,17:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_name_Middlesex County</th>\n",
       "      <th>county_name_New Haven County</th>\n",
       "      <th>county_name_New London County</th>\n",
       "      <th>county_name_Tolland County</th>\n",
       "      <th>county_name_Windham County</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.117919</td>\n",
       "      <td>0.157689</td>\n",
       "      <td>0.146753</td>\n",
       "      <td>0.144331</td>\n",
       "      <td>0.090068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.322513</td>\n",
       "      <td>0.364450</td>\n",
       "      <td>0.353860</td>\n",
       "      <td>0.351425</td>\n",
       "      <td>0.286280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       county_name_Middlesex County  county_name_New Haven County  \\\n",
       "count                 313274.000000                 313274.000000   \n",
       "mean                       0.117919                      0.157689   \n",
       "std                        0.322513                      0.364450   \n",
       "min                        0.000000                      0.000000   \n",
       "25%                        0.000000                      0.000000   \n",
       "50%                        0.000000                      0.000000   \n",
       "75%                        0.000000                      0.000000   \n",
       "max                        1.000000                      1.000000   \n",
       "\n",
       "       county_name_New London County  county_name_Tolland County  \\\n",
       "count                  313274.000000               313274.000000   \n",
       "mean                        0.146753                    0.144331   \n",
       "std                         0.353860                    0.351425   \n",
       "min                         0.000000                    0.000000   \n",
       "25%                         0.000000                    0.000000   \n",
       "50%                         0.000000                    0.000000   \n",
       "75%                         0.000000                    0.000000   \n",
       "max                         1.000000                    1.000000   \n",
       "\n",
       "       county_name_Windham County  \n",
       "count               313274.000000  \n",
       "mean                     0.090068  \n",
       "std                      0.286280  \n",
       "min                      0.000000  \n",
       "25%                      0.000000  \n",
       "50%                      0.000000  \n",
       "75%                      0.000000  \n",
       "max                      1.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description.iloc[:,22:27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driver_race_Asian</th>\n",
       "      <th>driver_race_Black</th>\n",
       "      <th>driver_race_Hispanic</th>\n",
       "      <th>driver_race_Other</th>\n",
       "      <th>driver_race_White</th>\n",
       "      <th>stop_duration_1-15 min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.018843</td>\n",
       "      <td>0.117724</td>\n",
       "      <td>0.098119</td>\n",
       "      <td>0.005510</td>\n",
       "      <td>0.759805</td>\n",
       "      <td>0.910886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.135970</td>\n",
       "      <td>0.322282</td>\n",
       "      <td>0.297475</td>\n",
       "      <td>0.074022</td>\n",
       "      <td>0.427203</td>\n",
       "      <td>0.284908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       driver_race_Asian  driver_race_Black  driver_race_Hispanic  \\\n",
       "count      313274.000000      313274.000000         313274.000000   \n",
       "mean            0.018843           0.117724              0.098119   \n",
       "std             0.135970           0.322282              0.297475   \n",
       "min             0.000000           0.000000              0.000000   \n",
       "25%             0.000000           0.000000              0.000000   \n",
       "50%             0.000000           0.000000              0.000000   \n",
       "75%             0.000000           0.000000              0.000000   \n",
       "max             1.000000           1.000000              1.000000   \n",
       "\n",
       "       driver_race_Other  driver_race_White  stop_duration_1-15 min  \n",
       "count      313274.000000      313274.000000           313274.000000  \n",
       "mean            0.005510           0.759805                0.910886  \n",
       "std             0.074022           0.427203                0.284908  \n",
       "min             0.000000           0.000000                0.000000  \n",
       "25%             0.000000           1.000000                1.000000  \n",
       "50%             0.000000           1.000000                1.000000  \n",
       "75%             0.000000           1.000000                1.000000  \n",
       "max             1.000000           1.000000                1.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description.iloc[:,27:33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_duration_16-30 min</th>\n",
       "      <th>stop_duration_30+ min</th>\n",
       "      <th>day_period_Afternoon</th>\n",
       "      <th>day_period_Evening</th>\n",
       "      <th>day_period_Morning</th>\n",
       "      <th>day_period_Small Hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.070635</td>\n",
       "      <td>0.018479</td>\n",
       "      <td>0.232799</td>\n",
       "      <td>0.196314</td>\n",
       "      <td>0.363155</td>\n",
       "      <td>0.207732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.256214</td>\n",
       "      <td>0.134676</td>\n",
       "      <td>0.422616</td>\n",
       "      <td>0.397209</td>\n",
       "      <td>0.480910</td>\n",
       "      <td>0.405684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       stop_duration_16-30 min  stop_duration_30+ min  day_period_Afternoon  \\\n",
       "count            313274.000000          313274.000000         313274.000000   \n",
       "mean                  0.070635               0.018479              0.232799   \n",
       "std                   0.256214               0.134676              0.422616   \n",
       "min                   0.000000               0.000000              0.000000   \n",
       "25%                   0.000000               0.000000              0.000000   \n",
       "50%                   0.000000               0.000000              0.000000   \n",
       "75%                   0.000000               0.000000              0.000000   \n",
       "max                   1.000000               1.000000              1.000000   \n",
       "\n",
       "       day_period_Evening  day_period_Morning  day_period_Small Hours  \n",
       "count       313274.000000       313274.000000           313274.000000  \n",
       "mean             0.196314            0.363155                0.207732  \n",
       "std              0.397209            0.480910                0.405684  \n",
       "min              0.000000            0.000000                0.000000  \n",
       "25%              0.000000            0.000000                0.000000  \n",
       "50%              0.000000            0.000000                0.000000  \n",
       "75%              0.000000            1.000000                0.000000  \n",
       "max              1.000000            1.000000                1.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description.iloc[:,33:39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season_Fall</th>\n",
       "      <th>season_Spring</th>\n",
       "      <th>season_Summer</th>\n",
       "      <th>season_Winter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "      <td>313274.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.288217</td>\n",
       "      <td>0.263319</td>\n",
       "      <td>0.212137</td>\n",
       "      <td>0.236327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.452934</td>\n",
       "      <td>0.440435</td>\n",
       "      <td>0.408822</td>\n",
       "      <td>0.424826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         season_Fall  season_Spring  season_Summer  season_Winter\n",
       "count  313274.000000  313274.000000  313274.000000  313274.000000\n",
       "mean        0.288217       0.263319       0.212137       0.236327\n",
       "std         0.452934       0.440435       0.408822       0.424826\n",
       "min         0.000000       0.000000       0.000000       0.000000\n",
       "25%         0.000000       0.000000       0.000000       0.000000\n",
       "50%         0.000000       0.000000       0.000000       0.000000\n",
       "75%         1.000000       1.000000       0.000000       0.000000\n",
       "max         1.000000       1.000000       1.000000       1.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description.iloc[:,39:43]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Shuffle and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AppData\\Local\\conda\\conda\\envs\\kaggle\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Split the 'features' and 'income' data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_features, \n",
    "                                                    outcomes, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Naive predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313274"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes.count().values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Arrest', 'Summons', 'Ticket', 'Verbal Warning', 'Written Warning'], dtype=object),\n",
       " array([  7303,  12203, 218951,  47750,  27067], dtype=int64))"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(outcomes, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218951"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(outcomes, return_counts=True)[1].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Predictor: [Accuracy score: 0.6989, F-score: 0.7437]\n"
     ]
    }
   ],
   "source": [
    "# Most frequent outcome, 'Ticket,' count\n",
    "tp = np.unique(outcomes, return_counts=True)[1].max()\n",
    "total_outcomes = outcomes.count().values[0]\n",
    "fp = total_outcomes - tp\n",
    "tn = 0\n",
    "fn = 0\n",
    "\n",
    "accuracy = float(tp) / total_outcomes\n",
    "recall = float(tp) / (tp + fn)\n",
    "precision = float(tp) / (tp + fp)\n",
    "\n",
    "# TODO: Calculate F-score using the formula above for beta = 0.5 and correct values for precision and recall.\n",
    "beta = 0.5\n",
    "fscore = (1 + beta**2) * (precision * recall) / (beta**2 * precision + recall)\n",
    "\n",
    "# Print the results \n",
    "print(\"Naive Predictor: [Accuracy score: {:.4f}, F-score: {:.4f}]\".format(accuracy, fscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Simple Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AppData\\Local\\conda\\conda\\envs\\kaggle\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.71588859628122259"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "clf_sgd = linear_model.SGDClassifier()\n",
    "clf_sgd.fit(X_train, y_train)\n",
    "clf_sgd.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AppData\\Local\\conda\\conda\\envs\\kaggle\\lib\\site-packages\\sklearn\\preprocessing\\label.py:112: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\AppData\\Local\\conda\\conda\\envs\\kaggle\\lib\\site-packages\\sklearn\\preprocessing\\label.py:147: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eclf1 score: 0.7188253132232064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AppData\\Local\\conda\\conda\\envs\\kaggle\\lib\\site-packages\\sklearn\\preprocessing\\label.py:112: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\AppData\\Local\\conda\\conda\\envs\\kaggle\\lib\\site-packages\\sklearn\\preprocessing\\label.py:147: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-432-a3ff7cf23603>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m         ('lr', clf1), ('rf', clf2), ('gnb', clf3), ('dt', clf4), ('gb', clf5)],\n\u001b[0;32m     14\u001b[0m         voting='soft')\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0meclf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meclf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'eclf2 score: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meclf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AppData\\Local\\conda\\conda\\envs\\kaggle\\lib\\site-packages\\sklearn\\ensemble\\voting_classifier.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    163\u001b[0m                 delayed(_parallel_fit_estimator)(clone(clf), X, transformed_y,\n\u001b[0;32m    164\u001b[0m                     sample_weight)\n\u001b[1;32m--> 165\u001b[1;33m                     for _, clf in self.estimators)\n\u001b[0m\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AppData\\Local\\conda\\conda\\envs\\kaggle\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AppData\\Local\\conda\\conda\\envs\\kaggle\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AppData\\Local\\conda\\conda\\envs\\kaggle\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AppData\\Local\\conda\\conda\\envs\\kaggle\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AppData\\Local\\conda\\conda\\envs\\kaggle\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AppData\\Local\\conda\\conda\\envs\\kaggle\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AppData\\Local\\conda\\conda\\envs\\kaggle\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AppData\\Local\\conda\\conda\\envs\\kaggle\\lib\\site-packages\\sklearn\\ensemble\\voting_classifier.py\u001b[0m in \u001b[0;36m_parallel_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AppData\\Local\\conda\\conda\\envs\\kaggle\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m   1026\u001b[0m         \u001b[1;31m# fit the boosting stages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[1;32m-> 1028\u001b[1;33m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[0;32m   1029\u001b[0m         \u001b[1;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AppData\\Local\\conda\\conda\\envs\\kaggle\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1081\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[0;32m   1082\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1083\u001b[1;33m                                      X_csc, X_csr)\n\u001b[0m\u001b[0;32m   1084\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1085\u001b[0m             \u001b[1;31m# track deviance (= loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AppData\\Local\\conda\\conda\\envs\\kaggle\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m             residual = loss.negative_gradient(y, y_pred, k=k,\n\u001b[1;32m--> 763\u001b[1;33m                                               sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m             \u001b[1;31m# induce regression tree on residuals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AppData\\Local\\conda\\conda\\envs\\kaggle\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36mnegative_gradient\u001b[1;34m(self, y, pred, k, **kwargs)\u001b[0m\n\u001b[0;32m    562\u001b[0m         \u001b[1;34m\"\"\"Compute negative gradient for the ``k``-th class. \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m         return y - np.nan_to_num(np.exp(pred[:, k] -\n\u001b[1;32m--> 564\u001b[1;33m                                         logsumexp(pred, axis=1)))\n\u001b[0m\u001b[0;32m    565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m     def _update_terminal_region(self, tree, terminal_regions, leaf, X, y,\n",
      "\u001b[1;32mD:\\AppData\\Local\\conda\\conda\\envs\\kaggle\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36mlogsumexp\u001b[1;34m(arr, axis)\u001b[0m\n\u001b[0;32m    408\u001b[0m     \u001b[1;31m# the less errors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m     \u001b[0mvmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mvmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    411\u001b[0m     \u001b[0mout\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mvmax\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "clf4 = DecisionTreeClassifier(random_state=0)\n",
    "clf5 = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[\n",
    "        ('lr', clf1), ('rf', clf2), ('gnb', clf3), ('dt', clf4), ('gb', clf5)], voting='hard')\n",
    "eclf1 = eclf1.fit(X_train, y_train)\n",
    "print('eclf1 score: {}'.format(eclf1.score(X_test, y_test)))\n",
    "\n",
    "eclf2 = VotingClassifier(estimators=[\n",
    "        ('lr', clf1), ('rf', clf2), ('gnb', clf3), ('dt', clf4), ('gb', clf5)],\n",
    "        voting='soft')\n",
    "eclf2 = eclf2.fit(X_train, y_train)\n",
    "print('eclf2 score: {}'.format(eclf2.score(X_test, y_test)))\n",
    "\n",
    "eclf3 = VotingClassifier(estimators=[\n",
    "       ('lr', clf1), ('rf', clf2), ('gnb', clf3), ('dt', clf4), ('gb', clf5)],\n",
    "       voting='soft', weights=[1,1,1,1,1])\n",
    "eclf3 = eclf3.fit(X_train, y_train)\n",
    "print('eclf3 score: {}'.format(eclf3.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(eclf3.transform(X_train).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Finding Donors Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score, accuracy_score\n",
    "\n",
    "\n",
    "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test): \n",
    "    '''\n",
    "    inputs:\n",
    "       - learner: the learning algorithm to be trained and predicted on\n",
    "       - sample_size: the size of samples (number) to be drawn from training set\n",
    "       - X_train: features training set\n",
    "       - y_train: income training set\n",
    "       - X_test: features testing set\n",
    "       - y_test: income testing set\n",
    "    '''\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # TODO: Fit the learner to the training data using slicing with 'sample_size' using .fit(training_features[:], training_labels[:])\n",
    "    start = time() # Get start time\n",
    "    learner = learner.fit(X_train[:sample_size], y_train[:sample_size])\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # Calculate the training time\n",
    "    results['train_time'] = end - start\n",
    "        \n",
    "    # Get the predictions on the test set(X_test),\n",
    "    # then get predictions on the first 300 training samples(X_train) using .predict()\n",
    "    start = time() # Get start time\n",
    "    predictions_test = learner.predict(X_test)\n",
    "    predictions_train = learner.predict(X_train[:300])\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # Calculate the total prediction time\n",
    "    results['pred_time'] = end - start\n",
    "            \n",
    "    # Compute accuracy on the first 300 training samples which is y_train[:300]\n",
    "    results['acc_train'] = accuracy_score(y_train[:300], predictions_train)\n",
    "        \n",
    "    # Compute accuracy on test set using accuracy_score()\n",
    "    results['acc_test'] = accuracy_score(y_test, predictions_test)\n",
    "    \n",
    "    # Compute F-score on the the first 300 training samples using fbeta_score()\n",
    "    results['f_train'] = fbeta_score(y_train[:300], predictions_train, 0.5, average='weighted')\n",
    "        \n",
    "    # Compute F-score on the test set which is y_test\n",
    "    results['f_test'] = fbeta_score(y_test, predictions_test, 0.5, average='weighted')\n",
    "       \n",
    "    # Success\n",
    "    print(\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n",
    "    # Return the results\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "\n",
    "import visuals as vs\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# TODO: Initialize the three models\n",
    "clf_A = SVC()\n",
    "clf_B = KNeighborsClassifier()\n",
    "clf_C = AdaBoostClassifier(random_state=0)\n",
    "\n",
    "# TODO: Calculate the number of samples for 1%, 10%, and 100% of the training data\n",
    "# HINT: samples_100 is the entire training set i.e. len(y_train)\n",
    "# HINT: samples_10 is 10% of samples_100\n",
    "# HINT: samples_1 is 1% of samples_100\n",
    "samples_100 = len(X_train)\n",
    "samples_10 = int(samples_100 * 0.1)\n",
    "samples_1 = int(samples_100 * 0.01)\n",
    "\n",
    "# Collect results on the learners\n",
    "# samples = [samples_1, samples_10, samples_100]\n",
    "samples = [samples_1, samples_10]\n",
    "results = {}\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "clf4 = DecisionTreeClassifier(random_state=0)\n",
    "clf5 = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "# for clf in [clf_A, clf_B, clf_C]:\n",
    "for clf in [clf1, clf2, clf3, clf4, clf5, clf_A, clf_B, clf_C]:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    results[clf_name] = {}\n",
    "    for i, samples in enumerate([samples_1, samples_10]):\n",
    "        results[clf_name][i] = train_predict(clf, samples, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# vs.evaluate(results, accuracy, fscore)\n",
    "# vs.evaluate(results, fscore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "algos_perf_100 = {\n",
    "    'AdaBoostClassifier': {\n",
    "        0: {\n",
    "            'acc_test': 0.72201739685579758,\n",
    "            'acc_train': 0.75666666666666671,\n",
    "            'f_test': 0.6347034296654146,\n",
    "            'f_train': 0.67410907596277725,\n",
    "            'pred_time': 0.543445348739624,\n",
    "            'train_time': 19.627169847488403\n",
    "        }\n",
    "    },\n",
    "    'DecisionTreeClassifier': {\n",
    "        0: {\n",
    "            'acc_test': 0.64998802968637781,\n",
    "            'acc_train': 0.87666666666666671,\n",
    "            'f_test': 0.61633367656940052,\n",
    "            'f_train': 0.86302242865468659,\n",
    "            'pred_time': 0.03910422325134277,\n",
    "            'train_time': 1.6804695129394531\n",
    "        }\n",
    "    },\n",
    "    'GaussianNB': {\n",
    "        0: {\n",
    "            'acc_test': 0.6477695315617269,\n",
    "            'acc_train': 0.65000000000000002,\n",
    "            'f_test': 0.64894363195314964,\n",
    "            'f_train': 0.6660681002181974,\n",
    "            'pred_time': 0.1474158763885498,\n",
    "            'train_time': 0.4652097225189209\n",
    "        }\n",
    "    },\n",
    "    'GradientBoostingClassifier': {\n",
    "        0: {\n",
    "            'acc_test': 0.72653419519591411,\n",
    "            'acc_train': 0.75666666666666671,\n",
    "            'f_test': 0.64379215256892308,\n",
    "            'f_train': 0.69227822649893855,\n",
    "            'pred_time': 0.4522271156311035,\n",
    "            'train_time': 134.945702791214\n",
    "        }\n",
    "    },\n",
    "    'KNeighborsClassifier': {\n",
    "        0: {\n",
    "            'acc_test': 0.70182746787965844,\n",
    "            'acc_train': 0.76333333333333331,\n",
    "            'f_test': 0.63953157257657978,\n",
    "            'f_train': 0.72221990752796439,\n",
    "            'pred_time': 469.2406713962555,\n",
    "            'train_time': 105.75855588912964\n",
    "        }\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        0: {\n",
    "            'acc_test': 0.72195355518314575,\n",
    "            'acc_train': 0.74333333333333329,\n",
    "            'f_test': 0.63036907824787092,\n",
    "            'f_train': 0.65587459707390683,\n",
    "            'pred_time': 0.015039205551147461,\n",
    "            'train_time': 7.507376670837402\n",
    "        }\n",
    "    },\n",
    "    'RandomForestClassifier': {\n",
    "        0: {\n",
    "            'acc_test': 0.66138376825472822,\n",
    "            'acc_train': 0.85666666666666669,\n",
    "            'f_test': 0.62684278836520912,\n",
    "            'f_train': 0.84386648286820054,\n",
    "            'pred_time': 0.2316434383392334,\n",
    "            'train_time': 3.1453657150268555\n",
    "        }\n",
    "    },\n",
    "    'SVC': {\n",
    "        0: {\n",
    "            'acc_test': 0.72153858431090889,\n",
    "            'acc_train': 0.74333333333333329,\n",
    "            'f_test': 0.62665356067781552,\n",
    "            'f_train': 0.66433167343078081,\n",
    "            'pred_time': 415.1082410812378,\n",
    "            'train_time': 12675.905246019363\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "algos_perf_1_10 = {\n",
    "    'AdaBoostClassifier': {\n",
    "        0: {\n",
    "            'acc_test': 0.6880376665868646,\n",
    "            'acc_train': 0.73333333333333328,\n",
    "            'f_test': 0.62455695148950785,\n",
    "            'f_train': 0.66977829504145292,\n",
    "            'pred_time': 0.539433479309082,\n",
    "            'train_time': 0.1734616756439209\n",
    "        },\n",
    "        1: {\n",
    "            'acc_test': 0.71975101747665793,\n",
    "            'acc_train': 0.74333333333333329,\n",
    "            'f_test': 0.63570748390991283,\n",
    "            'f_train': 0.653961069541102,\n",
    "            'pred_time': 0.5464534759521484,\n",
    "            'train_time': 1.5140256881713867\n",
    "        }\n",
    "    },\n",
    "    'DecisionTreeClassifier': {\n",
    "        0: {\n",
    "            'acc_test': 0.57082435559811662,\n",
    "            'acc_train': 0.99333333333333329,\n",
    "            'f_test': 0.58583779620178067,\n",
    "            'f_train': 0.99331663630843958,\n",
    "            'pred_time': 0.02102804183959961,\n",
    "            'train_time': 0.011029243469238281\n",
    "        },\n",
    "        1: {\n",
    "            'acc_test': 0.59725480807597164,\n",
    "            'acc_train': 0.94666666666666666,\n",
    "            'f_test': 0.5961071139937264,\n",
    "            'f_train': 0.94618066761588349,\n",
    "            'pred_time': 0.025066852569580078,\n",
    "            'train_time': 0.12533354759216309\n",
    "        }\n",
    "    },\n",
    "    'GaussianNB': {\n",
    "        0: {\n",
    "            'acc_test': 0.10259356795148034,\n",
    "            'acc_train': 0.083333333333333329,\n",
    "            'f_test': 0.028189924174105794,\n",
    "            'f_train': 0.029534142118342974,\n",
    "            'pred_time': 0.1323244571685791,\n",
    "            'train_time': 0.004010677337646484\n",
    "        },\n",
    "        1: {\n",
    "            'acc_test': 0.12931130795626847,\n",
    "            'acc_train': 0.12,\n",
    "            'f_test': 0.12916640033819876,\n",
    "            'f_train': 0.15739017372272129,\n",
    "            'pred_time': 0.13032174110412598,\n",
    "            'train_time': 0.03910064697265625\n",
    "        }\n",
    "    },\n",
    "    'GradientBoostingClassifier': {\n",
    "        0: {\n",
    "            'acc_test': 0.71092490623254334,\n",
    "            'acc_train': 0.81000000000000005,\n",
    "            'f_test': 0.63530485219905097,\n",
    "            'f_train': 0.78236498150146749,\n",
    "            'pred_time': 0.43916845321655273,\n",
    "            'train_time': 1.0352869033813477\n",
    "        },\n",
    "        1: {\n",
    "            'acc_test': 0.72490623254329267,\n",
    "            'acc_train': 0.76000000000000001,\n",
    "            'f_test': 0.64347985483372394,\n",
    "            'f_train': 0.69558556782166092,\n",
    "            'pred_time': 0.4291689395904541,\n",
    "            'train_time': 9.850817203521729\n",
    "        }\n",
    "    },\n",
    "    'KNeighborsClassifier': {\n",
    "        0: {\n",
    "            'acc_test': 0.6886920437315458,\n",
    "            'acc_train': 0.77333333333333332,\n",
    "            'f_test': 0.59287183310418978,\n",
    "            'f_train': 0.72444177427265255,\n",
    "            'pred_time': 7.581151485443115,\n",
    "            'train_time': 0.010005712509155273\n",
    "        },\n",
    "        1: {\n",
    "            'acc_test': 0.69636900486792752,\n",
    "            'acc_train': 0.78333333333333333,\n",
    "            'f_test': 0.62128133889347992,\n",
    "            'f_train': 0.74183674775562447,\n",
    "            'pred_time': 70.91268134117126,\n",
    "            'train_time': 0.4231266975402832\n",
    "        }\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        0: {\n",
    "            'acc_test': 0.71764424227914769,\n",
    "            'acc_train': 0.75,\n",
    "            'f_test': 0.61911581672791882,\n",
    "            'f_train': 0.67090722679839265,\n",
    "            'pred_time': 0.04411673545837402,\n",
    "            'train_time': 0.03409004211425781\n",
    "        },\n",
    "        1: {\n",
    "            'acc_test': 0.72155454472907188,\n",
    "            'acc_train': 0.73666666666666669,\n",
    "            'f_test': 0.62967738703888954,\n",
    "            'f_train': 0.64343872533090696,\n",
    "            'pred_time': 0.015011787414550781,\n",
    "            'train_time': 0.3048381805419922\n",
    "        }\n",
    "    },\n",
    "    'RandomForestClassifier': {\n",
    "        0: {\n",
    "            'acc_test': 0.66649110206687412,\n",
    "            'acc_train': 0.97666666666666668,\n",
    "            'f_test': 0.61185444064698324,\n",
    "            'f_train': 0.97659659659659648,\n",
    "            'pred_time': 0.10327458381652832,\n",
    "            'train_time': 0.02907705307006836\n",
    "        },\n",
    "        1: {\n",
    "            'acc_test': 0.65265341951959144,\n",
    "            'acc_train': 0.93000000000000005,\n",
    "            'f_test': 0.61806534585982587,\n",
    "            'f_train': 0.9292351914609287,\n",
    "            'pred_time': 0.14137554168701172,\n",
    "            'train_time': 0.21961092948913574\n",
    "        }\n",
    "    },\n",
    "    'SVC': {\n",
    "        0: {\n",
    "            'acc_test': 0.70449285771287207,\n",
    "            'acc_train': 0.73333333333333328,\n",
    "            'f_test': 0.53983227104940101,\n",
    "            'f_train': 0.5848263320603746,\n",
    "            'pred_time': 4.238268613815308,\n",
    "            'train_time': 0.30383753776550293\n",
    "        },\n",
    "        1: {\n",
    "            'acc_test': 0.71711754847977016,\n",
    "            'acc_train': 0.74333333333333329,\n",
    "            'f_test': 0.61122570948237986,\n",
    "            'f_train': 0.64742204388133662,\n",
    "            'pred_time': 41.337204933166504,\n",
    "            'train_time': 34.030903577804565\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "algos_perf = {\n",
    "    'AdaBoostClassifier': {\n",
    "        0: {\n",
    "            'acc_test': 0.6880376665868646,\n",
    "            'acc_train': 0.73333333333333328,\n",
    "            'f_test': 0.62455695148950785,\n",
    "            'f_train': 0.66977829504145292,\n",
    "            'pred_time': 0.539433479309082,\n",
    "            'train_time': 0.1734616756439209\n",
    "        },\n",
    "        1: {\n",
    "            'acc_test': 0.71975101747665793,\n",
    "            'acc_train': 0.74333333333333329,\n",
    "            'f_test': 0.63570748390991283,\n",
    "            'f_train': 0.653961069541102,\n",
    "            'pred_time': 0.5464534759521484,\n",
    "            'train_time': 1.5140256881713867\n",
    "        },\n",
    "        2: {\n",
    "            'acc_test': 0.72201739685579758,\n",
    "            'acc_train': 0.75666666666666671,\n",
    "            'f_test': 0.6347034296654146,\n",
    "            'f_train': 0.67410907596277725,\n",
    "            'pred_time': 0.543445348739624,\n",
    "            'train_time': 19.627169847488403\n",
    "        }\n",
    "\n",
    "    },\n",
    "    'DecisionTreeClassifier': {\n",
    "        0: {\n",
    "            'acc_test': 0.57082435559811662,\n",
    "            'acc_train': 0.99333333333333329,\n",
    "            'f_test': 0.58583779620178067,\n",
    "            'f_train': 0.99331663630843958,\n",
    "            'pred_time': 0.02102804183959961,\n",
    "            'train_time': 0.011029243469238281\n",
    "        },\n",
    "        1: {\n",
    "            'acc_test': 0.59725480807597164,\n",
    "            'acc_train': 0.94666666666666666,\n",
    "            'f_test': 0.5961071139937264,\n",
    "            'f_train': 0.94618066761588349,\n",
    "            'pred_time': 0.025066852569580078,\n",
    "            'train_time': 0.12533354759216309\n",
    "        },\n",
    "        2: {\n",
    "            'acc_test': 0.64998802968637781,\n",
    "            'acc_train': 0.87666666666666671,\n",
    "            'f_test': 0.61633367656940052,\n",
    "            'f_train': 0.86302242865468659,\n",
    "            'pred_time': 0.03910422325134277,\n",
    "            'train_time': 1.6804695129394531\n",
    "        }\n",
    "\n",
    "    },\n",
    "    'GaussianNB': {\n",
    "        0: {\n",
    "            'acc_test': 0.10259356795148034,\n",
    "            'acc_train': 0.083333333333333329,\n",
    "            'f_test': 0.028189924174105794,\n",
    "            'f_train': 0.029534142118342974,\n",
    "            'pred_time': 0.1323244571685791,\n",
    "            'train_time': 0.004010677337646484\n",
    "        },\n",
    "        1: {\n",
    "            'acc_test': 0.12931130795626847,\n",
    "            'acc_train': 0.12,\n",
    "            'f_test': 0.12916640033819876,\n",
    "            'f_train': 0.15739017372272129,\n",
    "            'pred_time': 0.13032174110412598,\n",
    "            'train_time': 0.03910064697265625\n",
    "        },\n",
    "        2: {\n",
    "            'acc_test': 0.6477695315617269,\n",
    "            'acc_train': 0.65000000000000002,\n",
    "            'f_test': 0.64894363195314964,\n",
    "            'f_train': 0.6660681002181974,\n",
    "            'pred_time': 0.1474158763885498,\n",
    "            'train_time': 0.4652097225189209\n",
    "        }\n",
    "\n",
    "    },\n",
    "    'GradientBoostingClassifier': {\n",
    "        0: {\n",
    "            'acc_test': 0.71092490623254334,\n",
    "            'acc_train': 0.81000000000000005,\n",
    "            'f_test': 0.63530485219905097,\n",
    "            'f_train': 0.78236498150146749,\n",
    "            'pred_time': 0.43916845321655273,\n",
    "            'train_time': 1.0352869033813477\n",
    "        },\n",
    "        1: {\n",
    "            'acc_test': 0.72490623254329267,\n",
    "            'acc_train': 0.76000000000000001,\n",
    "            'f_test': 0.64347985483372394,\n",
    "            'f_train': 0.69558556782166092,\n",
    "            'pred_time': 0.4291689395904541,\n",
    "            'train_time': 9.850817203521729\n",
    "        },\n",
    "        2: {\n",
    "            'acc_test': 0.72653419519591411,\n",
    "            'acc_train': 0.75666666666666671,\n",
    "            'f_test': 0.64379215256892308,\n",
    "            'f_train': 0.69227822649893855,\n",
    "            'pred_time': 0.4522271156311035,\n",
    "            'train_time': 134.945702791214\n",
    "        }\n",
    "    },\n",
    "    'KNeighborsClassifier': {\n",
    "        0: {\n",
    "            'acc_test': 0.6886920437315458,\n",
    "            'acc_train': 0.77333333333333332,\n",
    "            'f_test': 0.59287183310418978,\n",
    "            'f_train': 0.72444177427265255,\n",
    "            'pred_time': 7.581151485443115,\n",
    "            'train_time': 0.010005712509155273\n",
    "        },\n",
    "        1: {\n",
    "            'acc_test': 0.69636900486792752,\n",
    "            'acc_train': 0.78333333333333333,\n",
    "            'f_test': 0.62128133889347992,\n",
    "            'f_train': 0.74183674775562447,\n",
    "            'pred_time': 70.91268134117126,\n",
    "            'train_time': 0.4231266975402832\n",
    "        },\n",
    "        2: {\n",
    "            'acc_test': 0.70182746787965844,\n",
    "            'acc_train': 0.76333333333333331,\n",
    "            'f_test': 0.63953157257657978,\n",
    "            'f_train': 0.72221990752796439,\n",
    "            'pred_time': 469.2406713962555,\n",
    "            'train_time': 105.75855588912964\n",
    "        }\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        0: {\n",
    "            'acc_test': 0.71764424227914769,\n",
    "            'acc_train': 0.75,\n",
    "            'f_test': 0.61911581672791882,\n",
    "            'f_train': 0.67090722679839265,\n",
    "            'pred_time': 0.04411673545837402,\n",
    "            'train_time': 0.03409004211425781\n",
    "        },\n",
    "        1: {\n",
    "            'acc_test': 0.72155454472907188,\n",
    "            'acc_train': 0.73666666666666669,\n",
    "            'f_test': 0.62967738703888954,\n",
    "            'f_train': 0.64343872533090696,\n",
    "            'pred_time': 0.015011787414550781,\n",
    "            'train_time': 0.3048381805419922\n",
    "        },\n",
    "        2: {\n",
    "            'acc_test': 0.72195355518314575,\n",
    "            'acc_train': 0.74333333333333329,\n",
    "            'f_test': 0.63036907824787092,\n",
    "            'f_train': 0.65587459707390683,\n",
    "            'pred_time': 0.015039205551147461,\n",
    "            'train_time': 7.507376670837402\n",
    "        }\n",
    "    },\n",
    "    'RandomForestClassifier': {\n",
    "        0: {\n",
    "            'acc_test': 0.66649110206687412,\n",
    "            'acc_train': 0.97666666666666668,\n",
    "            'f_test': 0.61185444064698324,\n",
    "            'f_train': 0.97659659659659648,\n",
    "            'pred_time': 0.10327458381652832,\n",
    "            'train_time': 0.02907705307006836\n",
    "        },\n",
    "        1: {\n",
    "            'acc_test': 0.65265341951959144,\n",
    "            'acc_train': 0.93000000000000005,\n",
    "            'f_test': 0.61806534585982587,\n",
    "            'f_train': 0.9292351914609287,\n",
    "            'pred_time': 0.14137554168701172,\n",
    "            'train_time': 0.21961092948913574\n",
    "        },\n",
    "        2: {\n",
    "            'acc_test': 0.66138376825472822,\n",
    "            'acc_train': 0.85666666666666669,\n",
    "            'f_test': 0.62684278836520912,\n",
    "            'f_train': 0.84386648286820054,\n",
    "            'pred_time': 0.2316434383392334,\n",
    "            'train_time': 3.1453657150268555\n",
    "        }\n",
    "    },\n",
    "    'SVC': {\n",
    "        0: {\n",
    "            'acc_test': 0.70449285771287207,\n",
    "            'acc_train': 0.73333333333333328,\n",
    "            'f_test': 0.53983227104940101,\n",
    "            'f_train': 0.5848263320603746,\n",
    "            'pred_time': 4.238268613815308,\n",
    "            'train_time': 0.30383753776550293\n",
    "        },\n",
    "        1: {\n",
    "            'acc_test': 0.71711754847977016,\n",
    "            'acc_train': 0.74333333333333329,\n",
    "            'f_test': 0.61122570948237986,\n",
    "            'f_train': 0.64742204388133662,\n",
    "            'pred_time': 41.337204933166504,\n",
    "            'train_time': 34.030903577804565\n",
    "        },\n",
    "        2: {\n",
    "            'acc_test': 0.72153858431090889,\n",
    "            'acc_train': 0.74333333333333329,\n",
    "            'f_test': 0.62665356067781552,\n",
    "            'f_train': 0.66433167343078081,\n",
    "            'pred_time': 415.1082410812378,\n",
    "            'train_time': 12675.905246019363\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import visuals as vs\n",
    "\n",
    "results = algos_perf\n",
    "# vs.evaluate(results, accuracy, fscore)\n",
    "vs.evaluate(results, fscore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pl\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "\n",
    "def evaluate(results, accuracy, f1):\n",
    "    \"\"\"\n",
    "    Visualization code to display results of various learners.\n",
    "    \n",
    "    inputs:\n",
    "      - learners: a list of supervised learners\n",
    "      - stats: a list of dictionaries of the statistic results from 'train_predict()'\n",
    "      - accuracy: The score for the naive predictor\n",
    "      - f1: The score for the naive predictor\n",
    "    \"\"\"\n",
    "  \n",
    "    # Create figure\n",
    "#     fig, ax = pl.subplots(2, 3, figsize = (15,17))\n",
    "    fig, ax = pl.subplots(3, 2, figsize = (15,17))\n",
    "\n",
    "    # Constants\n",
    "    bar_width = 0.3\n",
    "    colors = ['#A00000','#00A0A0','#00A000', '#FF0000', '#82E0AA', '#D2B4DE', '#F1948A', '#D6EAF8']\n",
    "    \n",
    "    # Super loop to plot four panels of data\n",
    "    for k, learner in enumerate(results.keys()):\n",
    "        for j, metric in enumerate(['train_time', 'acc_train', 'f_train', 'pred_time', 'acc_test', 'f_test']):\n",
    "            for i in np.arange(3):\n",
    "                \n",
    "                # Creative plot code\n",
    "                ax[j//2, j%2].bar(i+k*bar_width, results[learner][i][metric], width = bar_width, color = colors[k])\n",
    "                ax[j//2, j%2].set_xticks([0.45, 1.45, 2.45])\n",
    "                ax[j//2, j%2].set_xticklabels([\"1%\", \"10%\", \"100%\"])\n",
    "                ax[j//2, j%2].set_xlabel(\"Training Set Size\")\n",
    "                ax[j//2, j%2].set_xlim((-0.1, 3.0))\n",
    "    \n",
    "    # Add unique y-labels\n",
    "    ax[0, 0].set_ylabel(\"Time (in seconds)\")\n",
    "    ax[0, 1].set_ylabel(\"Accuracy Score\")\n",
    "    ax[1, 0].set_ylabel(\"F-score\")\n",
    "    ax[1, 1].set_ylabel(\"Time (in seconds)\")\n",
    "    ax[2, 0].set_ylabel(\"Accuracy Score\")\n",
    "    ax[2, 1].set_ylabel(\"F-score\")\n",
    "    \n",
    "    # Add titles\n",
    "    ax[0, 0].set_title(\"Model Training\")\n",
    "    ax[0, 1].set_title(\"Accuracy Score on Training Subset\")\n",
    "    ax[1, 0].set_title(\"F-score on Training Subset\")\n",
    "    ax[1, 1].set_title(\"Model Predicting\")\n",
    "    ax[2, 0].set_title(\"Accuracy Score on Testing Set\")\n",
    "    ax[2, 1].set_title(\"F-score on Testing Set\")\n",
    "    \n",
    "    # Add horizontal lines for naive predictors\n",
    "    ax[0, 1].axhline(y = accuracy, xmin = -0.1, xmax = 3.0, linewidth = .2, color = 'k', linestyle = 'dashed')\n",
    "    ax[2, 0].axhline(y = accuracy, xmin = -0.1, xmax = 3.0, linewidth = .2, color = 'k', linestyle = 'dashed')\n",
    "    ax[1, 0].axhline(y = f1, xmin = -0.1, xmax = 8.0, linewidth = .2, color = 'k', linestyle = 'dashed')\n",
    "    ax[2, 1].axhline(y = f1, xmin = -0.1, xmax = 8.0, linewidth = .2, color = 'k', linestyle = 'dashed')\n",
    "    \n",
    "    # Set y-limits for score panels\n",
    "    ax[0, 1].set_ylim((0, 1))\n",
    "    ax[1, 0].set_ylim((0, 1))\n",
    "    ax[2, 0].set_ylim((0, 0.8))\n",
    "    ax[2, 1].set_ylim((0, 0.8))\n",
    "\n",
    "    # Create patches for the legend\n",
    "    patches = []\n",
    "    for i, learner in enumerate(results.keys()):\n",
    "        patches.append(mpatches.Patch(color = colors[i], label = learner))\n",
    "    pl.legend(handles = patches, bbox_to_anchor = (-0.1, 4), \\\n",
    "               loc = 'upper center', borderaxespad = 0., ncol = 2, fontsize = 'x-large')\n",
    "    \n",
    "    # Aesthetics\n",
    "    pl.suptitle(\"Performance Metrics for Eight Supervised Learning Models\", fontsize = 14, y = 1.05)\n",
    "    pl.tight_layout()\n",
    "    pl.show()\n",
    "\n",
    "\n",
    "evaluate(results, accuracy, fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "type(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "reformatted = {}\n",
    "metrics = list(results[list(results.keys())[0]][0].keys())\n",
    "print(metrics)\n",
    "for k in results.keys():\n",
    "    algo = results[k]\n",
    "    reformatted[k] = {}\n",
    "    for m in metrics:\n",
    "#         reformatted[k][m] = [results[k][0][m], results[k][1][m], results[k][2][m]]\n",
    "        reformatted[k][m] = results[k][2][m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "reformatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(reformatted)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_results[:1].plot.bar(figsize=(13, 4), title='acc_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_results[1:2].plot.bar(figsize=(13, 4), title='acc_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_results[2:3].plot.bar(figsize=(13, 4), title='f_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_results[3:4].plot.bar(figsize=(13, 4), title='f_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_results[4:5].plot.bar(figsize=(13, 4), title='pred_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_results[5:6].plot.bar(figsize=(13, 4), title='train_time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Algo Testing Conclusion\n",
    "\n",
    "AdaBoostClassifier and GradientBoostingClassifier have highest test set accuracies and attractive training times.  I'll use these two to tune hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Hyperparameter Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219881.7813            1.76s\n",
      "         2      218532.2381            1.58s\n",
      "         3      217188.8122            1.38s\n",
      "         4      215892.7225            1.18s\n",
      "         5      214686.0889            0.98s\n",
      "         6      213419.5165            0.78s\n",
      "         7      212189.0598            0.59s\n",
      "         8      211047.3862            0.39s\n",
      "         9      209929.2386            0.20s\n",
      "        10      208825.0296            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219881.6189            1.84s\n",
      "         2      218530.7243            1.60s\n",
      "         3      217188.5201            1.39s\n",
      "         4      215891.1910            1.19s\n",
      "         5      214684.5031            0.99s\n",
      "         6      213417.9788            0.79s\n",
      "         7      212188.0970            0.59s\n",
      "         8      211047.8455            0.39s\n",
      "         9      209931.0173            0.20s\n",
      "        10      208828.2419            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219884.5585            1.75s\n",
      "         2      218535.6299            1.57s\n",
      "         3      217195.7130            1.36s\n",
      "         4      215900.9762            1.17s\n",
      "         5      214694.8688            0.97s\n",
      "         6      213430.5692            0.78s\n",
      "         7      212202.5456            0.60s\n",
      "         8      211063.2747            0.40s\n",
      "         9      209946.4242            0.20s\n",
      "        10      208844.7087            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219824.4354            1.89s\n",
      "         2      218447.6749            1.65s\n",
      "         3      217058.0985            1.45s\n",
      "         4      215749.3635            1.24s\n",
      "         5      214522.7457            1.03s\n",
      "         6      213249.7023            0.83s\n",
      "         7      212021.1068            0.62s\n",
      "         8      210775.6574            0.41s\n",
      "         9      209640.4742            0.21s\n",
      "        10      208536.7230            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219823.8541            1.89s\n",
      "         2      218444.5305            1.66s\n",
      "         3      217055.6048            1.45s\n",
      "         4      215747.7634            1.25s\n",
      "         5      214521.1724            1.04s\n",
      "         6      213247.8707            0.83s\n",
      "         7      212019.8580            0.62s\n",
      "         8      210771.3016            0.41s\n",
      "         9      209636.8533            0.21s\n",
      "        10      208534.3676            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219828.4880            1.90s\n",
      "         2      218452.0153            1.67s\n",
      "         3      217066.4265            1.45s\n",
      "         4      215761.1205            1.26s\n",
      "         5      214534.8229            1.04s\n",
      "         6      213263.4515            0.83s\n",
      "         7      212037.2693            0.63s\n",
      "         8      210792.5944            0.42s\n",
      "         9      209658.2415            0.21s\n",
      "        10      208556.8934            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219797.3762            2.06s\n",
      "         2      218409.6591            1.86s\n",
      "         3      217020.9283            1.64s\n",
      "         4      215676.6313            1.42s\n",
      "         5      214368.6675            1.18s\n",
      "         6      213076.9951            0.94s\n",
      "         7      211837.0060            0.70s\n",
      "         8      210576.9779            0.47s\n",
      "         9      209370.1860            0.23s\n",
      "        10      208212.8071            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219798.4935            2.13s\n",
      "         2      218408.2160            1.88s\n",
      "         3      217020.1280            1.63s\n",
      "         4      215676.9804            1.39s\n",
      "         5      214370.5244            1.15s\n",
      "         6      213076.2990            0.92s\n",
      "         7      211836.9511            0.69s\n",
      "         8      210575.0292            0.46s\n",
      "         9      209366.7253            0.23s\n",
      "        10      208207.7328            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219803.4502            2.08s\n",
      "         2      218416.0353            1.84s\n",
      "         3      217031.2408            1.60s\n",
      "         4      215690.4998            1.37s\n",
      "         5      214386.2066            1.15s\n",
      "         6      213094.5798            0.91s\n",
      "         7      211856.9619            0.69s\n",
      "         8      210599.1069            0.46s\n",
      "         9      209393.2498            0.23s\n",
      "        10      208237.0663            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219802.6463            2.14s\n",
      "         2      218415.1388            1.86s\n",
      "         3      217032.9439            1.60s\n",
      "         4      215712.7703            1.37s\n",
      "         5      214426.1289            1.16s\n",
      "         6      213133.4657            0.92s\n",
      "         7      211882.3450            0.70s\n",
      "         8      210721.6606            0.47s\n",
      "         9      209587.1163            0.23s\n",
      "        10      208470.5489            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219802.9522            2.01s\n",
      "         2      218416.2250            1.83s\n",
      "         3      217036.0536            1.58s\n",
      "         4      215716.9409            1.35s\n",
      "         5      214423.5214            1.14s\n",
      "         6      213132.2539            0.91s\n",
      "         7      211882.5907            0.68s\n",
      "         8      210723.4545            0.46s\n",
      "         9      209590.2186            0.23s\n",
      "        10      208475.6789            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219807.0166            2.09s\n",
      "         2      218421.5109            1.84s\n",
      "         3      217044.1318            1.65s\n",
      "         4      215726.1794            1.40s\n",
      "         5      214435.7084            1.18s\n",
      "         6      213147.8048            0.94s\n",
      "         7      211900.9111            0.70s\n",
      "         8      210743.0542            0.47s\n",
      "         9      209610.3563            0.24s\n",
      "        10      208497.5898            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219759.9525            2.33s\n",
      "         2      218339.0549            2.07s\n",
      "         3      216927.2082            1.78s\n",
      "         4      215591.6513            1.51s\n",
      "         5      214262.0628            1.27s\n",
      "         6      212969.8848            1.01s\n",
      "         7      211700.5418            0.76s\n",
      "         8      210400.2980            0.51s\n",
      "         9      209223.5342            0.26s\n",
      "        10      208028.3861            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219758.5963            2.30s\n",
      "         2      218327.8072            2.04s\n",
      "         3      216916.3390            1.78s\n",
      "         4      215553.9026            1.53s\n",
      "         5      214216.9023            1.27s\n",
      "         6      212924.7512            1.01s\n",
      "         7      211657.4913            0.76s\n",
      "         8      210355.2030            0.50s\n",
      "         9      209178.2963            0.25s\n",
      "        10      207979.0671            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219767.8763            2.31s\n",
      "         2      218348.5614            2.03s\n",
      "         3      216941.1120            1.77s\n",
      "         4      215589.6718            1.51s\n",
      "         5      214258.9257            1.27s\n",
      "         6      212969.0756            1.01s\n",
      "         7      211703.1681            0.76s\n",
      "         8      210405.0657            0.51s\n",
      "         9      209230.0937            0.26s\n",
      "        10      208030.9435            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219739.1392            2.63s\n",
      "         2      218241.3961            2.43s\n",
      "         3      216803.8289            2.10s\n",
      "         4      215399.3057            1.80s\n",
      "         5      213996.7794            1.50s\n",
      "         6      212624.3819            1.20s\n",
      "         7      211285.7307            0.90s\n",
      "         8      209950.3130            0.60s\n",
      "         9      208646.3939            0.30s\n",
      "        10      207403.2795            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219740.4677            2.70s\n",
      "         2      218242.3632            2.42s\n",
      "         3      216804.9242            2.09s\n",
      "         4      215368.1668            1.82s\n",
      "         5      213964.2588            1.51s\n",
      "         6      212589.8605            1.21s\n",
      "         7      211250.7673            0.90s\n",
      "         8      209911.5325            0.60s\n",
      "         9      208605.9929            0.30s\n",
      "        10      207359.5251            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219746.0980            2.59s\n",
      "         2      218254.0150            2.37s\n",
      "         3      216820.9114            2.05s\n",
      "         4      215388.8519            1.76s\n",
      "         5      213989.3456            1.48s\n",
      "         6      212619.3328            1.19s\n",
      "         7      211285.2020            0.89s\n",
      "         8      209952.7639            0.59s\n",
      "         9      208652.2405            0.30s\n",
      "        10      207409.5505            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219646.9544            3.89s\n",
      "         2      218107.8664            3.41s\n",
      "         3      216614.2918            2.93s\n",
      "         4      215128.0405            2.55s\n",
      "         5      213695.1790            2.13s\n",
      "         6      212322.6638            1.70s\n",
      "         7      210962.0731            1.28s\n",
      "         8      209653.4581            0.85s\n",
      "         9      208371.3502            0.43s\n",
      "        10      207142.1361            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219646.7245            3.82s\n",
      "         2      218110.4926            3.32s\n",
      "         3      216610.7947            2.93s\n",
      "         4      215111.0579            2.55s\n",
      "         5      213684.9489            2.15s\n",
      "         6      212284.5196            1.73s\n",
      "         7      210974.6195            1.30s\n",
      "         8      209702.0689            0.86s\n",
      "         9      208422.5468            0.43s\n",
      "        10      207173.4749            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219670.4682            3.89s\n",
      "         2      218142.9752            3.46s\n",
      "         3      216647.5482            2.98s\n",
      "         4      215175.4565            2.60s\n",
      "         5      213748.4130            2.21s\n",
      "         6      212362.6484            1.76s\n",
      "         7      210983.4415            1.31s\n",
      "         8      209690.9634            0.87s\n",
      "         9      208415.8329            0.44s\n",
      "        10      207188.8390            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219654.5617            4.66s\n",
      "         2      218079.1641            4.26s\n",
      "         3      216523.4262            3.70s\n",
      "         4      215030.8280            3.12s\n",
      "         5      213539.3151            2.63s\n",
      "         6      212078.4986            2.10s\n",
      "         7      210635.2363            1.59s\n",
      "         8      209228.6078            1.06s\n",
      "         9      207893.6347            0.53s\n",
      "        10      206585.5638            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219643.2578            4.60s\n",
      "         2      218058.6088            4.24s\n",
      "         3      216496.1983            3.66s\n",
      "         4      215007.7420            3.14s\n",
      "         5      213516.7460            2.63s\n",
      "         6      212032.7880            2.12s\n",
      "         7      210618.9396            1.60s\n",
      "         8      209208.9474            1.07s\n",
      "         9      207865.5214            0.54s\n",
      "        10      206553.3180            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219646.1426            4.71s\n",
      "         2      218079.2369            4.24s\n",
      "         3      216535.8062            3.68s\n",
      "         4      215079.8170            3.18s\n",
      "         5      213582.0945            2.67s\n",
      "         6      212154.1726            2.15s\n",
      "         7      210778.2758            1.61s\n",
      "         8      209374.7571            1.08s\n",
      "         9      208031.2949            0.54s\n",
      "        10      206727.8150            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219524.8150            7.01s\n",
      "         2      217869.6919            6.27s\n",
      "         3      216251.9240            5.54s\n",
      "         4      214657.8038            4.70s\n",
      "         5      213131.0650            3.89s\n",
      "         6      211602.2988            3.13s\n",
      "         7      210127.8113            2.38s\n",
      "         8      208678.5591            1.58s\n",
      "         9      207275.9126            0.79s\n",
      "        10      205919.0588            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219520.7463            7.54s\n",
      "         2      217846.1967            6.78s\n",
      "         3      216230.0794            5.87s\n",
      "         4      214632.3409            4.99s\n",
      "         5      213101.5963            4.08s\n",
      "         6      211624.4263            3.27s\n",
      "         7      210134.7922            2.45s\n",
      "         8      208687.5604            1.63s\n",
      "         9      207277.7601            0.83s\n",
      "        10      205893.5156            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219528.3900            8.08s\n",
      "         2      217863.5853            6.83s\n",
      "         3      216252.8165            5.88s\n",
      "         4      214663.0777            4.96s\n",
      "         5      213136.3954            4.09s\n",
      "         6      211616.0671            3.29s\n",
      "         7      210137.6802            2.49s\n",
      "         8      208685.5075            1.65s\n",
      "         9      207286.3775            0.82s\n",
      "        10      205930.1738            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219548.5526            9.17s\n",
      "         2      217869.6622            8.18s\n",
      "         3      216311.3571            7.22s\n",
      "         4      214736.5748            6.29s\n",
      "         5      213237.5683            5.23s\n",
      "         6      211729.4421            4.22s\n",
      "         7      210298.4140            3.16s\n",
      "         8      208927.9958            2.11s\n",
      "         9      207591.9013            1.06s\n",
      "        10      206282.1104            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219531.7886            8.97s\n",
      "         2      217917.6280            8.10s\n",
      "         3      216307.2207            7.16s\n",
      "         4      214708.9388            6.20s\n",
      "         5      213175.9367            5.25s\n",
      "         6      211683.6439            4.25s\n",
      "         7      210258.3937            3.20s\n",
      "         8      208875.8297            2.14s\n",
      "         9      207497.0604            1.08s\n",
      "        10      206178.5781            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219586.3405            9.22s\n",
      "         2      217952.6844            8.25s\n",
      "         3      216359.7814            7.27s\n",
      "         4      214781.9470            6.37s\n",
      "         5      213292.1607            5.34s\n",
      "         6      211827.0928            4.30s\n",
      "         7      210360.8132            3.21s\n",
      "         8      208988.9323            2.14s\n",
      "         9      207614.3858            1.08s\n",
      "        10      206320.0516            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219510.0368           11.62s\n",
      "         2      217810.5628           11.13s\n",
      "         3      216179.5888            9.56s\n",
      "         4      214615.8808            8.13s\n",
      "         5      213065.0880            6.87s\n",
      "         6      211508.0110            5.54s\n",
      "         7      209990.2000            4.17s\n",
      "         8      208507.5831            2.79s\n",
      "         9      207086.3968            1.40s\n",
      "        10      205715.2159            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219498.4523           11.70s\n",
      "         2      217801.2060           11.05s\n",
      "         3      216151.4829            9.66s\n",
      "         4      214583.1769            8.21s\n",
      "         5      213001.2148            6.93s\n",
      "         6      211445.2952            5.58s\n",
      "         7      209945.5219            4.21s\n",
      "         8      208470.0846            2.83s\n",
      "         9      207025.7888            1.42s\n",
      "        10      205650.6551            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219493.7150           11.87s\n",
      "         2      217822.4221           11.00s\n",
      "         3      216208.7532            9.59s\n",
      "         4      214587.0168            8.23s\n",
      "         5      212994.9329            6.95s\n",
      "         6      211440.7001            5.57s\n",
      "         7      209967.9577            4.19s\n",
      "         8      208503.7924            2.80s\n",
      "         9      207079.5411            1.40s\n",
      "        10      205696.2175            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219440.9856           18.70s\n",
      "         2      217684.6033           16.98s\n",
      "         3      215966.1359           15.10s\n",
      "         4      214290.6798           13.00s\n",
      "         5      212668.6748           10.83s\n",
      "         6      211077.0848            8.75s\n",
      "         7      209520.7821            6.62s\n",
      "         8      207998.2028            4.42s\n",
      "         9      206521.0258            2.21s\n",
      "        10      205068.8591            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219423.7994           20.80s\n",
      "         2      217662.5094           18.14s\n",
      "         3      215941.9905           15.84s\n",
      "         4      214264.9933           13.48s\n",
      "         5      212646.4212           11.11s\n",
      "         6      211065.1329            8.87s\n",
      "         7      209496.8482            6.74s\n",
      "         8      207975.7476            4.49s\n",
      "         9      206493.9114            2.25s\n",
      "        10      205029.6309            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      219430.4130           19.81s\n",
      "         2      217673.2472           17.49s\n",
      "         3      215960.6305           15.49s\n",
      "         4      214290.4717           13.26s\n",
      "         5      212667.3677           11.01s\n",
      "         6      211080.0599            8.93s\n",
      "         7      209524.3980            6.78s\n",
      "         8      208008.3499            4.50s\n",
      "         9      206524.9447            2.25s\n",
      "        10      205072.5490            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      217292.6358            1.94s\n",
      "         2      213488.0985            1.74s\n",
      "         3      209858.1286            1.49s\n",
      "         4      206525.1503            1.29s\n",
      "         5      203570.0166            1.07s\n",
      "         6      200568.1583            0.85s\n",
      "         7      197781.9175            0.63s\n",
      "         8      195323.6264            0.42s\n",
      "         9      193014.2545            0.21s\n",
      "        10      190802.9196            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      217292.1472            1.76s\n",
      "         2      213483.5450            1.75s\n",
      "         3      209857.2960            1.51s\n",
      "         4      206520.5438            1.30s\n",
      "         5      203565.2993            1.07s\n",
      "         6      200563.6909            0.85s\n",
      "         7      197779.3695            0.63s\n",
      "         8      195325.2860            0.42s\n",
      "         9      193019.7244            0.21s\n",
      "        10      190812.5847            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      217296.5415            1.82s\n",
      "         2      213493.7818            1.61s\n",
      "         3      209874.3996            1.41s\n",
      "         4      206544.9237            1.20s\n",
      "         5      203591.4509            0.99s\n",
      "         6      200595.8398            0.80s\n",
      "         7      197816.1543            0.59s\n",
      "         8      195364.7962            0.40s\n",
      "         9      193058.7992            0.20s\n",
      "        10      190854.6275            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      217122.3755            1.81s\n",
      "         2      213239.7077            1.63s\n",
      "         3      209494.1140            1.44s\n",
      "         4      206135.2857            1.23s\n",
      "         5      203120.6192            1.03s\n",
      "         6      200106.2504            0.82s\n",
      "         7      197331.4766            0.62s\n",
      "         8      194576.1780            0.41s\n",
      "         9      192213.6449            0.21s\n",
      "        10      190012.4454            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      217120.6511            1.80s\n",
      "         2      213230.4354            1.64s\n",
      "         3      209487.0340            1.45s\n",
      "         4      206129.0076            1.24s\n",
      "         5      203114.6044            1.03s\n",
      "         6      200096.5932            0.83s\n",
      "         7      197320.7239            0.62s\n",
      "         8      194556.8289            0.41s\n",
      "         9      192193.4920            0.21s\n",
      "        10      189995.5998            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      217130.0777            1.84s\n",
      "         2      213248.2635            1.64s\n",
      "         3      209514.2865            1.44s\n",
      "         4      206163.8352            1.24s\n",
      "         5      203149.9831            1.04s\n",
      "         6      200137.0928            0.86s\n",
      "         7      197365.8412            0.65s\n",
      "         8      194612.6840            0.44s\n",
      "         9      192249.2968            0.22s\n",
      "        10      190054.5021            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      217043.0238            2.05s\n",
      "         2      213127.2334            1.83s\n",
      "         3      209388.8784            1.59s\n",
      "         4      205926.4697            1.36s\n",
      "         5      202708.4204            1.14s\n",
      "         6      199649.4668            0.92s\n",
      "         7      196851.5386            0.69s\n",
      "         8      194053.6008            0.46s\n",
      "         9      191499.6121            0.23s\n",
      "        10      189184.6076            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      217046.3512            2.00s\n",
      "         2      213123.0314            1.82s\n",
      "         3      209386.7877            1.59s\n",
      "         4      205924.7482            1.36s\n",
      "         5      202681.9590            1.14s\n",
      "         6      199608.6626            0.94s\n",
      "         7      196805.8328            0.71s\n",
      "         8      194004.9322            0.47s\n",
      "         9      191450.7137            0.23s\n",
      "        10      189127.5034            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      217056.7084            2.00s\n",
      "         2      213141.8070            1.81s\n",
      "         3      209414.6232            1.59s\n",
      "         4      205959.5776            1.36s\n",
      "         5      202722.7251            1.13s\n",
      "         6      199656.2350            0.91s\n",
      "         7      196857.5865            0.68s\n",
      "         8      194065.8633            0.45s\n",
      "         9      191516.9295            0.23s\n",
      "        10      189200.2366            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      217057.5846            2.08s\n",
      "         2      213143.3690            1.83s\n",
      "         3      209407.5886            1.62s\n",
      "         4      206008.1241            1.38s\n",
      "         5      202829.0720            1.15s\n",
      "         6      199757.7561            0.91s\n",
      "         7      196923.1753            0.69s\n",
      "         8      194416.0771            0.46s\n",
      "         9      192062.7123            0.23s\n",
      "        10      189833.0183            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      217058.4843            2.07s\n",
      "         2      213146.5328            1.97s\n",
      "         3      209416.4881            1.73s\n",
      "         4      206015.6892            1.45s\n",
      "         5      202815.9510            1.23s\n",
      "         6      199748.8664            1.00s\n",
      "         7      196919.0177            0.78s\n",
      "         8      194416.0532            0.54s\n",
      "         9      192066.9911            0.27s\n",
      "        10      189835.5631            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      217066.2109            2.40s\n",
      "         2      213157.8874            2.06s\n",
      "         3      209435.9455            1.75s\n",
      "         4      206037.2307            1.48s\n",
      "         5      202863.7745            1.24s\n",
      "         6      199803.1145            0.99s\n",
      "         7      196978.1987            0.74s\n",
      "         8      194476.8331            0.49s\n",
      "         9      192128.7944            0.24s\n",
      "        10      189899.3644            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216930.4774            2.32s\n",
      "         2      212919.6014            2.08s\n",
      "         3      209118.1342            1.78s\n",
      "         4      205664.4834            1.52s\n",
      "         5      202380.8857            1.28s\n",
      "         6      199321.9492            1.02s\n",
      "         7      196447.1774            0.77s\n",
      "         8      193567.9409            0.51s\n",
      "         9      191087.8343            0.26s\n",
      "        10      188670.2078            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216926.5332            2.29s\n",
      "         2      212889.1118            2.08s\n",
      "         3      209090.9275            1.77s\n",
      "         4      205586.5328            1.55s\n",
      "         5      202283.4872            1.29s\n",
      "         6      199227.9385            1.03s\n",
      "         7      196359.7910            0.77s\n",
      "         8      193478.1708            0.51s\n",
      "         9      190998.3455            0.26s\n",
      "        10      188570.4511            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216949.5597            2.42s\n",
      "         2      212943.2371            2.08s\n",
      "         3      209153.7009            1.78s\n",
      "         4      205654.2875            1.52s\n",
      "         5      202386.2871            1.27s\n",
      "         6      199333.4897            1.02s\n",
      "         7      196467.0007            0.76s\n",
      "         8      193595.0343            0.51s\n",
      "         9      191120.0425            0.25s\n",
      "        10      188675.4265            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216869.7131            2.61s\n",
      "         2      212647.6849            2.40s\n",
      "         3      208787.6053            2.10s\n",
      "         4      205096.9883            1.81s\n",
      "         5      201590.6715            1.52s\n",
      "         6      198327.9711            1.22s\n",
      "         7      195294.2640            0.91s\n",
      "         8      192403.2804            0.61s\n",
      "         9      189668.7103            0.31s\n",
      "        10      187184.3271            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216873.6587            2.67s\n",
      "         2      212650.2905            2.43s\n",
      "         3      208790.4825            2.10s\n",
      "         4      205091.3889            1.82s\n",
      "         5      201577.0119            1.52s\n",
      "         6      198308.5947            1.22s\n",
      "         7      195272.3580            0.92s\n",
      "         8      192358.7252            0.61s\n",
      "         9      189619.0364            0.31s\n",
      "        10      187129.0185            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216886.0240            2.72s\n",
      "         2      212679.7999            2.46s\n",
      "         3      208831.6574            2.13s\n",
      "         4      205143.8059            1.83s\n",
      "         5      201642.1523            1.52s\n",
      "         6      198384.9549            1.22s\n",
      "         7      195360.8824            0.91s\n",
      "         8      192460.8178            0.64s\n",
      "         9      189732.1222            0.32s\n",
      "        10      187250.1907            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216595.7315            3.96s\n",
      "         2      212250.7434            3.43s\n",
      "         3      208214.9618            2.96s\n",
      "         4      204373.9024            2.59s\n",
      "         5      200839.9222            2.17s\n",
      "         6      197552.8740            1.73s\n",
      "         7      194478.0822            1.29s\n",
      "         8      191599.2959            0.86s\n",
      "         9      188906.0443            0.43s\n",
      "        10      186403.6770            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216594.0053            3.79s\n",
      "         2      212308.5017            3.34s\n",
      "         3      208249.4267            2.90s\n",
      "         4      204361.3960            2.56s\n",
      "         5      200837.4020            2.16s\n",
      "         6      197503.5989            1.73s\n",
      "         7      194551.7102            1.30s\n",
      "         8      191693.4891            0.86s\n",
      "         9      188994.6820            0.43s\n",
      "        10      186499.5950            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216662.2437            3.82s\n",
      "         2      212347.6585            3.37s\n",
      "         3      208303.9208            3.01s\n",
      "         4      204497.8147            2.68s\n",
      "         5      200979.1717            2.25s\n",
      "         6      197684.7430            1.78s\n",
      "         7      194654.8777            1.33s\n",
      "         8      191830.4085            0.88s\n",
      "         9      189120.0152            0.44s\n",
      "        10      186621.9435            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216619.0835            4.67s\n",
      "         2      212196.0142            4.30s\n",
      "         3      208004.8450            3.71s\n",
      "         4      204120.7621            3.20s\n",
      "         5      200393.8226            2.71s\n",
      "         6      196844.7163            2.16s\n",
      "         7      193584.1284            1.62s\n",
      "         8      190526.1567            1.08s\n",
      "         9      187735.2791            0.55s\n",
      "        10      185106.9103            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216586.4473            4.75s\n",
      "         2      212112.0770            4.41s\n",
      "         3      207910.4758            3.80s\n",
      "         4      204083.8080            3.23s\n",
      "         5      200358.1698            2.70s\n",
      "         6      196906.9668            2.16s\n",
      "         7      193712.9698            1.62s\n",
      "         8      190635.9809            1.08s\n",
      "         9      187804.6813            0.54s\n",
      "        10      185149.1269            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216581.1726            5.02s\n",
      "         2      212159.9659            4.46s\n",
      "         3      208004.7038            3.84s\n",
      "         4      204223.1276            3.28s\n",
      "         5      200535.7948            2.73s\n",
      "         6      197059.4286            2.20s\n",
      "         7      193832.1275            1.66s\n",
      "         8      190806.2493            1.10s\n",
      "         9      187973.3943            0.55s\n",
      "        10      185333.7224            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216236.8905            7.23s\n",
      "         2      211580.8712            6.31s\n",
      "         3      207234.0638            5.57s\n",
      "         4      203162.6223            4.76s\n",
      "         5      199414.7313            3.94s\n",
      "         6      195819.0851            3.16s\n",
      "         7      192495.6726            2.38s\n",
      "         8      189376.7655            1.58s\n",
      "         9      186482.4338            0.79s\n",
      "        10      183740.1078            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216223.8103            7.14s\n",
      "         2      211508.7219            6.24s\n",
      "         3      207175.9273            5.54s\n",
      "         4      203095.0245            4.74s\n",
      "         5      199338.1974            3.89s\n",
      "         6      195853.5126            3.13s\n",
      "         7      192485.6936            2.36s\n",
      "         8      189351.6534            1.57s\n",
      "         9      186448.1532            0.79s\n",
      "        10      183673.9047            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216245.5298            7.07s\n",
      "         2      211559.8884            6.24s\n",
      "         3      207236.3077            5.53s\n",
      "         4      203175.5305            4.75s\n",
      "         5      199427.0496            3.93s\n",
      "         6      195847.4725            3.16s\n",
      "         7      192515.0674            2.38s\n",
      "         8      189378.9810            1.58s\n",
      "         9      186487.3385            0.79s\n",
      "        10      183747.6700            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216243.1969            9.38s\n",
      "         2      211501.9488            8.40s\n",
      "         3      207245.6171            7.35s\n",
      "         4      203166.2306            6.40s\n",
      "         5      199461.5920            5.42s\n",
      "         6      195995.4187            4.34s\n",
      "         7      192747.3665            3.26s\n",
      "         8      189711.2867            2.18s\n",
      "         9      186875.7710            1.09s\n",
      "        10      184229.1925            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216306.1866           10.17s\n",
      "         2      211720.4271            9.06s\n",
      "         3      207375.9034            7.85s\n",
      "         4      203305.6253            6.71s\n",
      "         5      199582.9712            5.62s\n",
      "         6      196054.7011            4.46s\n",
      "         7      192916.4811            3.34s\n",
      "         8      189872.0523            2.23s\n",
      "         9      186944.0287            1.11s\n",
      "        10      184266.4679            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216333.0599            9.20s\n",
      "         2      211722.3929            8.34s\n",
      "         3      207503.3815            7.31s\n",
      "         4      203365.1495            6.32s\n",
      "         5      199686.9844            5.38s\n",
      "         6      196272.4313            4.34s\n",
      "         7      192963.1957            3.26s\n",
      "         8      189944.9123            2.16s\n",
      "         9      187082.0392            1.09s\n",
      "        10      184462.3156            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216168.0451           12.10s\n",
      "         2      211392.9739           11.25s\n",
      "         3      206986.6536            9.84s\n",
      "         4      202863.7293            8.32s\n",
      "         5      198943.3720            7.00s\n",
      "         6      195308.9938            5.62s\n",
      "         7      191930.4469            4.24s\n",
      "         8      188760.2756            2.83s\n",
      "         9      185781.8316            1.42s\n",
      "        10      183031.9699            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216136.8454           12.20s\n",
      "         2      211370.2942           11.21s\n",
      "         3      206927.6005            9.73s\n",
      "         4      202783.3128            8.33s\n",
      "         5      198923.2466            7.07s\n",
      "         6      195330.7918            5.70s\n",
      "         7      191993.5369            4.29s\n",
      "         8      188789.1614            2.86s\n",
      "         9      185781.3516            1.43s\n",
      "        10      183004.1205            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      216127.8108           12.23s\n",
      "         2      211434.3667           11.26s\n",
      "         3      207096.7096            9.78s\n",
      "         4      203019.5561            8.30s\n",
      "         5      199116.8580            7.02s\n",
      "         6      195464.9168            5.61s\n",
      "         7      192125.6209            4.22s\n",
      "         8      188950.2317            2.81s\n",
      "         9      185956.1841            1.41s\n",
      "        10      183128.6694            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      215969.9949           19.23s\n",
      "         2      211035.2918           17.25s\n",
      "         3      206433.6094           15.20s\n",
      "         4      202139.7233           13.06s\n",
      "         5      198161.2346           10.92s\n",
      "         6      194421.7378            8.76s\n",
      "         7      190931.1623            6.63s\n",
      "         8      187638.1746            4.43s\n",
      "         9      184561.1016            2.21s\n",
      "        10      181679.4971            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      215899.5309           19.23s\n",
      "         2      210963.1337           17.21s\n",
      "         3      206357.6089           15.28s\n",
      "         4      202044.1361           13.15s\n",
      "         5      198078.2602           10.88s\n",
      "         6      194365.9453            8.82s\n",
      "         7      190851.8141            6.66s\n",
      "         8      187586.3700            4.43s\n",
      "         9      184530.0767            2.21s\n",
      "        10      181618.8878            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      215891.4658           19.42s\n",
      "         2      210943.2132           17.09s\n",
      "         3      206364.8605           15.16s\n",
      "         4      202089.3144           13.07s\n",
      "         5      198130.1811           10.85s\n",
      "         6      194411.6425            8.80s\n",
      "         7      190948.3013            6.62s\n",
      "         8      187674.9172            4.44s\n",
      "         9      184605.5279            2.21s\n",
      "        10      181723.5192            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221074.0449            1.72s\n",
      "         2      220935.2634            1.54s\n",
      "         3      220794.3690            1.35s\n",
      "         4      220655.3083            1.16s\n",
      "         5      220522.8301            0.97s\n",
      "         6      220381.4489            0.78s\n",
      "         7      220241.0371            0.58s\n",
      "         8      220107.5948            0.39s\n",
      "         9      219974.1779            0.20s\n",
      "        10      219840.1508            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221074.0287            1.76s\n",
      "         2      220935.1123            1.58s\n",
      "         3      220794.3391            1.37s\n",
      "         4      220655.1509            1.20s\n",
      "         5      220522.6671            0.99s\n",
      "         6      220381.2861            0.80s\n",
      "         7      220240.9250            0.60s\n",
      "         8      220107.6277            0.40s\n",
      "         9      219974.3477            0.20s\n",
      "        10      219840.4661            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221076.3086            1.71s\n",
      "         2      220937.5896            1.56s\n",
      "         3      220797.0452            1.39s\n",
      "         4      220658.1243            1.19s\n",
      "         5      220525.6980            0.99s\n",
      "         6      220384.5515            0.79s\n",
      "         7      220244.3943            0.60s\n",
      "         8      220111.1994            0.40s\n",
      "         9      219977.9241            0.20s\n",
      "        10      219844.1518            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221068.2834            1.85s\n",
      "         2      220926.7259            1.73s\n",
      "         3      220780.8474            1.53s\n",
      "         4      220640.3002            1.31s\n",
      "         5      220505.8117            1.08s\n",
      "         6      220363.6195            0.87s\n",
      "         7      220223.2301            0.66s\n",
      "         8      220079.1424            0.46s\n",
      "         9      219944.0669            0.23s\n",
      "        10      219809.9561            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221068.2250            1.85s\n",
      "         2      220926.4091            1.67s\n",
      "         3      220780.5917            1.47s\n",
      "         4      220640.1327            1.29s\n",
      "         5      220505.6480            1.07s\n",
      "         6      220363.4261            0.86s\n",
      "         7      220223.0875            0.64s\n",
      "         8      220078.6812            0.43s\n",
      "         9      219943.6841            0.21s\n",
      "        10      219809.7068            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221070.6751            1.86s\n",
      "         2      220929.1466            1.66s\n",
      "         3      220783.6723            1.49s\n",
      "         4      220643.4803            1.28s\n",
      "         5      220509.0295            1.07s\n",
      "         6      220367.0164            0.86s\n",
      "         7      220226.8813            0.64s\n",
      "         8      220082.8787            0.43s\n",
      "         9      219947.8977            0.21s\n",
      "        10      219814.0397            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221065.5503            2.02s\n",
      "         2      220922.9000            1.83s\n",
      "         3      220777.0301            1.60s\n",
      "         4      220632.8368            1.38s\n",
      "         5      220489.3871            1.16s\n",
      "         6      220345.0386            0.93s\n",
      "         7      220203.1967            0.70s\n",
      "         8      220056.4578            0.47s\n",
      "         9      219913.8245            0.24s\n",
      "        10      219773.4366            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221065.6624            2.09s\n",
      "         2      220922.7538            1.90s\n",
      "         3      220776.9450            1.65s\n",
      "         4      220632.8681            1.41s\n",
      "         5      220489.5717            1.18s\n",
      "         6      220344.9539            0.94s\n",
      "         7      220203.1794            0.71s\n",
      "         8      220056.2371            0.47s\n",
      "         9      219913.4604            0.24s\n",
      "        10      219772.9003            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221068.1453            2.05s\n",
      "         2      220925.5256            1.87s\n",
      "         3      220780.0595            1.64s\n",
      "         4      220636.2409            1.40s\n",
      "         5      220493.1860            1.17s\n",
      "         6      220348.8549            0.93s\n",
      "         7      220207.2834            0.70s\n",
      "         8      220060.8014            0.47s\n",
      "         9      219918.2809            0.23s\n",
      "        10      219778.0350            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221066.0960            2.03s\n",
      "         2      220923.4551            1.82s\n",
      "         3      220778.5182            1.60s\n",
      "         4      220637.1320            1.37s\n",
      "         5      220495.7706            1.15s\n",
      "         6      220351.6340            0.94s\n",
      "         7      220208.8962            0.71s\n",
      "         8      220073.4048            0.47s\n",
      "         9      219938.2208            0.24s\n",
      "        10      219802.7708            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221066.1268            2.19s\n",
      "         2      220923.5653            1.94s\n",
      "         3      220778.8360            1.67s\n",
      "         4      220637.3705            1.42s\n",
      "         5      220495.8793            1.19s\n",
      "         6      220351.8893            0.95s\n",
      "         7      220209.2958            0.71s\n",
      "         8      220073.9673            0.47s\n",
      "         9      219938.9217            0.24s\n",
      "        10      219803.6808            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221068.5198            2.05s\n",
      "         2      220926.0809            1.83s\n",
      "         3      220781.6351            1.60s\n",
      "         4      220640.2930            1.37s\n",
      "         5      220499.0014            1.15s\n",
      "         6      220355.3133            0.92s\n",
      "         7      220212.9701            0.69s\n",
      "         8      220077.7749            0.46s\n",
      "         9      219942.7858            0.23s\n",
      "        10      219807.7367            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221061.8113            2.26s\n",
      "         2      220915.7740            2.03s\n",
      "         3      220767.4911            1.77s\n",
      "         4      220624.0498            1.51s\n",
      "         5      220477.8485            1.26s\n",
      "         6      220333.4046            1.01s\n",
      "         7      220188.4897            0.76s\n",
      "         8      220038.0886            0.51s\n",
      "         9      219898.6805            0.25s\n",
      "        10      219754.2748            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221061.6738            2.46s\n",
      "         2      220914.5970            2.34s\n",
      "         3      220766.3102            1.94s\n",
      "         4      220620.9126            1.62s\n",
      "         5      220474.5964            1.34s\n",
      "         6      220330.1437            1.09s\n",
      "         7      220185.3736            0.83s\n",
      "         8      220034.7019            0.54s\n",
      "         9      219895.3096            0.27s\n",
      "        10      219750.3293            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221064.5937            2.28s\n",
      "         2      220918.7173            2.13s\n",
      "         3      220770.8939            1.85s\n",
      "         4      220625.8196            1.59s\n",
      "         5      220480.1961            1.36s\n",
      "         6      220335.9926            1.07s\n",
      "         7      220191.4475            0.80s\n",
      "         8      220041.2450            0.53s\n",
      "         9      219902.0213            0.27s\n",
      "        10      219757.0656            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221059.7053            2.64s\n",
      "         2      220905.6736            2.42s\n",
      "         3      220754.4755            2.11s\n",
      "         4      220603.6968            1.85s\n",
      "         5      220449.8699            1.54s\n",
      "         6      220296.7252            1.23s\n",
      "         7      220143.8651            0.92s\n",
      "         8      219988.4790            0.61s\n",
      "         9      219833.5464            0.31s\n",
      "        10      219682.4606            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221059.8388            2.76s\n",
      "         2      220905.7749            2.48s\n",
      "         3      220754.5899            2.13s\n",
      "         4      220603.7392            1.85s\n",
      "         5      220449.7142            1.56s\n",
      "         6      220296.3772            1.25s\n",
      "         7      220143.0045            0.94s\n",
      "         8      219987.0972            0.62s\n",
      "         9      219831.9022            0.31s\n",
      "        10      219680.2364            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221062.3893            2.67s\n",
      "         2      220908.9422            2.45s\n",
      "         3      220758.2156            2.11s\n",
      "         4      220607.6276            1.80s\n",
      "         5      220454.0959            1.54s\n",
      "         6      220301.2389            1.23s\n",
      "         7      220148.3990            0.92s\n",
      "         8      219993.2646            0.62s\n",
      "         9      219838.6648            0.31s\n",
      "        10      219687.4076            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221050.4387            3.97s\n",
      "         2      220892.3335            3.46s\n",
      "         3      220735.7787            2.99s\n",
      "         4      220576.6053            2.60s\n",
      "         5      220422.1179            2.17s\n",
      "         6      220268.8437            1.74s\n",
      "         7      220113.6270            1.30s\n",
      "         8      219961.0260            0.87s\n",
      "         9      219809.2773            0.44s\n",
      "        10      219661.0112            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221050.4068            4.04s\n",
      "         2      220892.5590            3.49s\n",
      "         3      220735.7976            3.00s\n",
      "         4      220577.3030            2.61s\n",
      "         5      220421.4327            2.20s\n",
      "         6      220265.1803            1.76s\n",
      "         7      220115.2384            1.32s\n",
      "         8      219967.2784            0.88s\n",
      "         9      219815.9097            0.44s\n",
      "        10      219665.4740            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221054.7786            3.90s\n",
      "         2      220897.7095            3.45s\n",
      "         3      220741.2244            2.98s\n",
      "         4      220583.4260            2.60s\n",
      "         5      220427.8164            2.20s\n",
      "         6      220272.3314            1.76s\n",
      "         7      220117.6330            1.34s\n",
      "         8      219967.4145            0.90s\n",
      "         9      219816.3407            0.45s\n",
      "        10      219668.1713            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221051.2010            4.82s\n",
      "         2      220889.2481            4.42s\n",
      "         3      220725.8688            3.79s\n",
      "         4      220566.2776            3.19s\n",
      "         5      220402.7267            2.68s\n",
      "         6      220237.9894            2.13s\n",
      "         7      220071.8857            1.60s\n",
      "         8      219908.0742            1.07s\n",
      "         9      219748.2713            0.53s\n",
      "        10      219590.4443            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221049.9824            4.66s\n",
      "         2      220887.1731            4.38s\n",
      "         3      220723.0574            3.76s\n",
      "         4      220565.0790            3.21s\n",
      "         5      220402.9068            2.68s\n",
      "         6      220235.0050            2.16s\n",
      "         7      220075.2592            1.63s\n",
      "         8      219910.8484            1.08s\n",
      "         9      219752.3689            0.54s\n",
      "        10      219593.3468            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221052.3089            4.74s\n",
      "         2      220891.1524            4.29s\n",
      "         3      220729.1183            3.71s\n",
      "         4      220571.8702            3.19s\n",
      "         5      220408.1502            2.68s\n",
      "         6      220248.2038            2.15s\n",
      "         7      220087.8439            1.62s\n",
      "         8      219924.5709            1.08s\n",
      "         9      219765.3373            0.54s\n",
      "        10      219607.1691            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221038.1135            7.32s\n",
      "         2      220867.7343            6.38s\n",
      "         3      220697.7194            5.61s\n",
      "         4      220526.3207            4.96s\n",
      "         5      220358.6717            4.15s\n",
      "         6      220187.9846            3.30s\n",
      "         7      220019.7539            2.47s\n",
      "         8      219850.0779            1.63s\n",
      "         9      219682.3816            0.81s\n",
      "        10      219516.9512            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221037.5582            7.08s\n",
      "         2      220865.2078            6.28s\n",
      "         3      220695.0760            5.59s\n",
      "         4      220523.5203            4.73s\n",
      "         5      220355.3980            3.88s\n",
      "         6      220187.7278            3.10s\n",
      "         7      220016.8231            2.32s\n",
      "         8      219847.7754            1.55s\n",
      "         9      219679.6524            0.77s\n",
      "        10      219509.4568            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221040.5591            7.07s\n",
      "         2      220868.9829            6.26s\n",
      "         3      220699.4999            5.52s\n",
      "         4      220528.5019            4.68s\n",
      "         5      220360.8693            3.87s\n",
      "         6      220189.8444            3.12s\n",
      "         7      220020.6577            2.34s\n",
      "         8      219850.6034            1.56s\n",
      "         9      219683.2836            0.78s\n",
      "        10      219517.7462            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221039.5510            9.44s\n",
      "         2      220867.4061            8.14s\n",
      "         3      220703.5072            7.11s\n",
      "         4      220532.5700            6.16s\n",
      "         5      220368.6136            5.14s\n",
      "         6      220201.9447            4.11s\n",
      "         7      220038.0672            3.06s\n",
      "         8      219878.8482            2.06s\n",
      "         9      219716.7109            1.03s\n",
      "        10      219558.9411            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221041.5116            9.05s\n",
      "         2      220875.1767            7.89s\n",
      "         3      220708.5795            6.90s\n",
      "         4      220534.7597            5.97s\n",
      "         5      220370.1133            5.03s\n",
      "         6      220202.2714            4.05s\n",
      "         7      220037.6216            3.08s\n",
      "         8      219877.9018            2.04s\n",
      "         9      219713.8500            1.03s\n",
      "        10      219554.0760            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221045.3141            9.56s\n",
      "         2      220876.6553            8.11s\n",
      "         3      220710.4682            7.03s\n",
      "         4      220542.2542            6.00s\n",
      "         5      220374.7275            5.08s\n",
      "         6      220208.3191            4.11s\n",
      "         7      220042.3213            3.05s\n",
      "         8      219881.8952            2.05s\n",
      "         9      219721.3861            1.03s\n",
      "        10      219561.9621            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221036.5907           11.58s\n",
      "         2      220861.6646           10.49s\n",
      "         3      220690.3220            9.13s\n",
      "         4      220516.7680            7.74s\n",
      "         5      220347.2457            6.53s\n",
      "         6      220175.4432            5.25s\n",
      "         7      220007.8258            3.96s\n",
      "         8      219835.4330            2.65s\n",
      "         9      219663.6990            1.33s\n",
      "        10      219497.4421            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221034.3650           11.72s\n",
      "         2      220859.9810           10.66s\n",
      "         3      220685.6340            9.32s\n",
      "         4      220520.4450            7.88s\n",
      "         5      220352.0633            6.82s\n",
      "         6      220179.5600            5.45s\n",
      "         7      220003.9234            4.09s\n",
      "         8      219831.9193            2.71s\n",
      "         9      219660.5615            1.36s\n",
      "        10      219493.4318            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221036.7703           13.29s\n",
      "         2      220864.1459           11.44s\n",
      "         3      220694.4626            9.73s\n",
      "         4      220520.9551            8.14s\n",
      "         5      220350.5356            6.76s\n",
      "         6      220176.7374            5.38s\n",
      "         7      220011.4209            4.04s\n",
      "         8      219840.5971            2.69s\n",
      "         9      219669.6902            1.35s\n",
      "        10      219501.3070            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221029.0227           19.68s\n",
      "         2      220848.1024           17.16s\n",
      "         3      220667.0519           15.08s\n",
      "         4      220486.5999           13.08s\n",
      "         5      220308.6893           11.02s\n",
      "         6      220132.4305            9.31s\n",
      "         7      219953.8845            7.12s\n",
      "         8      219775.7148            4.70s\n",
      "         9      219598.2563            2.33s\n",
      "        10      219422.6728            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221027.8951           18.50s\n",
      "         2      220846.6900           16.40s\n",
      "         3      220665.2390           14.39s\n",
      "         4      220484.7125           12.36s\n",
      "         5      220305.6500           10.23s\n",
      "         6      220124.6829            8.33s\n",
      "         7      219946.1537            6.31s\n",
      "         8      219767.1418            4.21s\n",
      "         9      219591.4560            2.11s\n",
      "        10      219413.4741            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      221029.2392           18.66s\n",
      "         2      220849.1558           16.23s\n",
      "         3      220669.1504           14.48s\n",
      "         4      220488.9698           12.38s\n",
      "         5      220310.3185           10.25s\n",
      "         6      220133.2188            8.27s\n",
      "         7      219956.9361            6.26s\n",
      "         8      219778.8389            4.16s\n",
      "         9      219602.9812            2.09s\n",
      "        10      219424.4665            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1      324046.9893           31.11s\n",
      "         2      316613.4970           28.00s\n",
      "         3      309736.3845           24.57s\n",
      "         4      303344.6531           20.98s\n",
      "         5      297389.2506           17.37s\n",
      "         6      291771.0689           13.98s\n",
      "         7      286571.4629           10.63s\n",
      "         8      281691.6907            7.09s\n",
      "         9      277081.5220            3.54s\n",
      "        10      272783.4891            0.00s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, fbeta_score, accuracy_score\n",
    "\n",
    "\n",
    "# TODO: Initialize the classifier\n",
    "clf = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "# TODO: Create the parameters list you wish to tune, using a dictionary if needed.\n",
    "# HINT: parameters = {'parameter_1': [value1, value2], 'parameter_2': [value1, value2]}\n",
    "parameters = {\n",
    "    'learning_rate': [0.01, 0.03, 0.001],\n",
    "    'n_estimators': [10],\n",
    "    'max_depth': [1, 2, 5, 8],\n",
    "    'max_features': [5, 8, 16],\n",
    "    'verbose': [1],\n",
    "    'random_state': [2]\n",
    "}\n",
    "\n",
    "# TODO: Make an fbeta_score scoring object using make_scorer()\n",
    "# scorer = make_scorer(fbeta_score, beta=0.5, needs_proba=True)\n",
    "# scorer = make_scorer(fbeta_score, beta=0.5, average='samples')\n",
    "scorer = make_scorer(accuracy_score)\n",
    "\n",
    "# TODO: Perform grid search on the classifier using 'scorer' as the scoring method using GridSearchCV()\n",
    "grid_obj = GridSearchCV(clf, parameters, scoring=scorer)\n",
    "\n",
    "# TODO: Fit the grid search object to the training data and find the optimal parameters using fit()\n",
    "rows, cols = y_train.shape\n",
    "grid_fit = grid_obj.fit(X_train, y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unoptimized model\n",
      "------\n",
      "Accuracy score on testing data: 0.7265\n",
      "F-score on testing data: 0.6438\n",
      "\n",
      "Optimized Model\n",
      "------\n",
      "Final accuracy score on the testing data: 0.7141\n",
      "Final F-score on the testing data: 0.5826\n"
     ]
    }
   ],
   "source": [
    "# Get the estimator\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "# Make predictions using the unoptimized and model\n",
    "predictions = (clf.fit(X_train, y_train[1])).predict(X_test)\n",
    "best_predictions = best_clf.predict(X_test)\n",
    "\n",
    "# Report the before-and-afterscores\n",
    "print(\"Unoptimized model\\n------\")\n",
    "print(\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test[1], predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test[1], predictions, beta = 0.5, average='weighted')))\n",
    "print(\"\\nOptimized Model\\n------\")\n",
    "print(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
    "print(\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test[1], best_predictions, beta = 0.5, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_train_s = pd.Series(y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "# TODO: Initialize the classifier\n",
    "clf = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "# TODO: Create the parameters list you wish to tune, using a dictionary if needed.\n",
    "# HINT: parameters = {'parameter_1': [value1, value2], 'parameter_2': [value1, value2]}\n",
    "parameters = {\n",
    "    'learning_rate': [0.01, 0.03, 0.001],\n",
    "    'n_estimators': [10],\n",
    "    'max_depth': [8],\n",
    "    'max_features': [5],\n",
    "    'verbose': [1],\n",
    "    'random_state': [2]\n",
    "}\n",
    "\n",
    "# TODO: Make an fbeta_score scoring object using make_scorer()\n",
    "# scorer = make_scorer(fbeta_score, beta=0.5, needs_proba=True)\n",
    "# scorer = make_scorer(fbeta_score, beta=0.5, average='samples')\n",
    "scorer = make_scorer(accuracy_score)\n",
    "\n",
    "# TODO: Perform grid search on the classifier using 'scorer' as the scoring method using GridSearchCV()\n",
    "grid_obj = GridSearchCV(clf, parameters, scoring=scorer)\n",
    "\n",
    "# TODO: Fit the grid search object to the training data and find the optimal parameters using fit()\n",
    "rows, cols = y_train.shape\n",
    "grid_fit = grid_obj.fit(X_train, y_train[1])\n",
    "\n",
    "# Get the estimator\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "# Make predictions using the unoptimized and model\n",
    "predictions = (clf.fit(X_train, y_train[1])).predict(X_test)\n",
    "best_predictions = best_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Report the before-and-afterscores\n",
    "print(\"Unoptimized model\\n------\")\n",
    "print(\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test[1], predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test[1], predictions, beta = 0.5, average='weighted')))\n",
    "print(\"\\nOptimized Model\\n------\")\n",
    "print(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
    "print(\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test[1], best_predictions, beta = 0.5, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pd.get_dummies(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "best_clf.predict_proba(pd.get_dummies(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "# Report the before-and-afterscores\n",
    "print(\"Unoptimized model\\n------\")\n",
    "print(\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test[1], predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test[1], predictions, beta = 0.5, average='weighted')))\n",
    "print(\"Log loss score on testing data: {:.4f}\".format(log_loss(y_test[1], best_clf.predict_proba(pd.get_dummies(X_test)), 0.5)))\n",
    "print(\"\\nOptimized Model\\n------\")\n",
    "print(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
    "print(\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test[1], best_predictions, beta = 0.5, average='weighted')))\n",
    "print(\"Log loss score on testing data: {:.4f}\".format(log_loss(y_test[1], best_clf.predict_proba(pd.get_dummies(X_test)), 0.5)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Adaboost un/optimized model performance\n",
    "\n",
    "average = 'weighted':\n",
    "```\n",
    "Unoptimized model\n",
    "------\n",
    "Accuracy score on testing data: 0.7220\n",
    "F-score on testing data: 0.6347\n",
    "\n",
    "Optimized Model\n",
    "------\n",
    "Final accuracy score on the testing data: 0.7066\n",
    "Final F-score on the testing data: 0.5718\n",
    "```\n",
    "\n",
    "average = 'samples':\n",
    "```\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## XGBoost Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ticket', 'Arrest', 'Summons', 'Verbal Warning', 'Written Warning'], dtype=object)"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "codes = {\n",
    "    'Ticket': 1,\n",
    "    'Arrest': 2,\n",
    "    'Summons': 3,\n",
    "    'Verbal Warning': 4,\n",
    "    'Written Warning': 5,\n",
    "}\n",
    "\n",
    "def labels_to_ints(label):\n",
    "    return codes[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, ..., 1, 1, 3], dtype=int64)"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted = y_train[1].apply(labels_to_ints)\n",
    "converted.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "xg_train = xgb.DMatrix(X_train.values, label=y_train[1].apply(labels_to_ints).values)\n",
    "xg_test = xgb.DMatrix(X_test.values, label=y_test[1].apply(labels_to_ints).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     'objective': 'multi:softmax',\n",
    "#     'eta': 0.1,\n",
    "#     'max_depth': 6,\n",
    "#     'silent': 1,\n",
    "#     'nthread': 4,\n",
    "#     'num_class': 6,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'multi:softmax',\n",
    "#     'learning_rate': .03,\n",
    "    'max_depth': 10,\n",
    "    'silent': 1,\n",
    "    'nthread': 6,\n",
    "    'num_class': 7,\n",
    "#     'predictor': 'gpu_predictor',\n",
    "#     'max_bin': 512,\n",
    "    'tree_method': 'gpu_hist',\n",
    "#     'alpha': 0.8,\n",
    "#     'gamma': 10.0,\n",
    "    'subsample': 0.6,\n",
    "#     'lambda': 0.9,,\n",
    "#     'colsample_bytree': 0.9,\n",
    "#     'colsample_bylevel': 0.3,\n",
    "#     'scale_pos_weight': 0.1,\n",
    "#     'updater': 'grow_histmaker,refresh,prune',\n",
    "#     'grow_policy': 'lossguide',\n",
    "#     'max_leaves': 20000,\n",
    "#     'max_bin': 1024,\n",
    "#     'base_score': 1.0,\n",
    "#     'eval_metric': 'ndcg',\n",
    "#     'max_delta_step': 8,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.269481\ttest-merror:0.27487\n",
      "[1]\ttrain-merror:0.267585\ttest-merror:0.273035\n",
      "[2]\ttrain-merror:0.266568\ttest-merror:0.272013\n",
      "[3]\ttrain-merror:0.265718\ttest-merror:0.272077\n",
      "[4]\ttrain-merror:0.265279\ttest-merror:0.27187\n",
      "[5]\ttrain-merror:0.264561\ttest-merror:0.27187\n",
      "[6]\ttrain-merror:0.26409\ttest-merror:0.271838\n",
      "[7]\ttrain-merror:0.263743\ttest-merror:0.271471\n",
      "[8]\ttrain-merror:0.263276\ttest-merror:0.271423\n",
      "[9]\ttrain-merror:0.262502\ttest-merror:0.271407\n",
      "[10]\ttrain-merror:0.261756\ttest-merror:0.270928\n",
      "[11]\ttrain-merror:0.261157\ttest-merror:0.271008\n",
      "[12]\ttrain-merror:0.260627\ttest-merror:0.271024\n",
      "[13]\ttrain-merror:0.260136\ttest-merror:0.271008\n",
      "[14]\ttrain-merror:0.259617\ttest-merror:0.270896\n",
      "[15]\ttrain-merror:0.259031\ttest-merror:0.270641\n",
      "[16]\ttrain-merror:0.258604\ttest-merror:0.270768\n",
      "[17]\ttrain-merror:0.258085\ttest-merror:0.270497\n"
     ]
    }
   ],
   "source": [
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "num_round = 18\n",
    "bst = xgb.train(params, xg_train, num_round, watchlist)\n",
    "pred = bst.predict(xg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error using softmax = 0.2704971670257761\n"
     ]
    }
   ],
   "source": [
    "error_rate = np.sum(pred != y_test[1].apply(labels_to_ints).values) / y_test[1].shape[0]\n",
    "print('Test error using softmax = {}'.format(error_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.269481\ttest-merror:0.27487\n",
      "[1]\ttrain-merror:0.267585\ttest-merror:0.273035\n",
      "[2]\ttrain-merror:0.266568\ttest-merror:0.272013\n",
      "[3]\ttrain-merror:0.265718\ttest-merror:0.272077\n",
      "[4]\ttrain-merror:0.265279\ttest-merror:0.27187\n",
      "[5]\ttrain-merror:0.264561\ttest-merror:0.27187\n",
      "[6]\ttrain-merror:0.26409\ttest-merror:0.271838\n",
      "[7]\ttrain-merror:0.263743\ttest-merror:0.271471\n",
      "[8]\ttrain-merror:0.263276\ttest-merror:0.271423\n",
      "[9]\ttrain-merror:0.262502\ttest-merror:0.271407\n",
      "[10]\ttrain-merror:0.261756\ttest-merror:0.270928\n",
      "[11]\ttrain-merror:0.261157\ttest-merror:0.271008\n",
      "[12]\ttrain-merror:0.260627\ttest-merror:0.271024\n",
      "[13]\ttrain-merror:0.260136\ttest-merror:0.271008\n",
      "[14]\ttrain-merror:0.259617\ttest-merror:0.270896\n",
      "[15]\ttrain-merror:0.259031\ttest-merror:0.270641\n",
      "[16]\ttrain-merror:0.258604\ttest-merror:0.270768\n",
      "[17]\ttrain-merror:0.258085\ttest-merror:0.270497\n",
      "Test error using softprob = 0.2704971670257761\n"
     ]
    }
   ],
   "source": [
    "params['objective'] = 'multi:softprob'\n",
    "bst = xgb.train(params, xg_train, num_round, watchlist)\n",
    "pred_prob = bst.predict(xg_test).reshape(y_test[1].shape[0], 7)\n",
    "pred_label = np.argmax(pred_prob, axis=1)\n",
    "error_rate = np.sum(pred_label != y_test[1].apply(labels_to_ints).values) / y_test[1].shape[0]\n",
    "print('Test error using softprob = {}'.format(error_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
