{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-05-26T19:49:47.773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Stage 1:\n",
      "\n",
      "Reading CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pato/anaconda2/envs/ppoon_capstone/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flags:\n",
      "\tinclude_location_raw: False\n",
      "\tperform_oversampling: False\n",
      "\tencode_labels: False\n",
      "Dropping non-essential columns...\n",
      "Dropping empty stop_outcome and county_name rows...\n",
      "Dropping driver_age rows under 15 y.o....\n",
      "Filling empty stop_time values with median...\n",
      "Categorizing stop_time and time-of-day...\n",
      "Normalizing violations and appending one-hot encoded violations to df...\n",
      "Dropping no longer needed columns...\n",
      "Dropping duplicate rows...\n",
      "Converting boolean columns to 0 and 1...\n",
      "Normalizing driver_age...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pato/anaconda2/envs/ppoon_capstone/lib/python3.6/site-packages/ipykernel_launcher.py:52: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "/home/pato/anaconda2/envs/ppoon_capstone/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row counts] train: 250118  test: 62530\n",
      "\n",
      "Pickling dataframe to file...\n",
      "\n",
      "\n",
      "Stage 2:\n",
      "\n",
      "Reading CSV...\n",
      "Flags:\n",
      "\tinclude_location_raw: True\n",
      "\tperform_oversampling: False\n",
      "\tencode_labels: False\n",
      "Dropping non-essential columns...\n",
      "Dropping empty stop_outcome and county_name rows...\n",
      "Dropping driver_age rows under 15 y.o....\n",
      "Filling empty stop_time values with median...\n",
      "Categorizing stop_time and time-of-day...\n",
      "LabelEncoding location_raw...\n",
      "Normalizing violations and appending one-hot encoded violations to df...\n",
      "Dropping no longer needed columns...\n",
      "Dropping duplicate rows...\n",
      "Converting boolean columns to 0 and 1...\n",
      "Normalizing driver_age...\n",
      "[Row counts] train: 250134  test: 62534\n",
      "\n",
      "Pickling dataframe to file...\n",
      "\n",
      "\n",
      "Stage 3:\n",
      "\n",
      "Reading CSV...\n",
      "Flags:\n",
      "\tinclude_location_raw: True\n",
      "\tperform_oversampling: False\n",
      "\tencode_labels: True\n",
      "Dropping non-essential columns...\n",
      "Dropping empty stop_outcome and county_name rows...\n",
      "Dropping driver_age rows under 15 y.o....\n",
      "Filling empty stop_time values with median...\n",
      "Categorizing stop_time and time-of-day...\n",
      "LabelEncoding location_raw...\n",
      "Normalizing violations and appending one-hot encoded violations to df...\n",
      "Dropping no longer needed columns...\n",
      "Dropping duplicate rows...\n",
      "Converting boolean columns to 0 and 1...\n",
      "Normalizing driver_age...\n",
      "LabelEncoding appropriate columns...\n",
      "[Row counts] train: 250134  test: 62534\n",
      "\n",
      "Pickling dataframe to file...\n",
      "\n",
      "\n",
      "Stage 4:\n",
      "\n",
      "Reading CSV...\n",
      "Flags:\n",
      "\tinclude_location_raw: True\n",
      "\tperform_oversampling: True\n",
      "\tencode_labels: True\n",
      "Dropping non-essential columns...\n",
      "Dropping empty stop_outcome and county_name rows...\n",
      "Dropping driver_age rows under 15 y.o....\n",
      "Filling empty stop_time values with median...\n",
      "Categorizing stop_time and time-of-day...\n",
      "LabelEncoding location_raw...\n",
      "Normalizing violations and appending one-hot encoded violations to df...\n",
      "Dropping no longer needed columns...\n",
      "Dropping duplicate rows...\n",
      "Converting boolean columns to 0 and 1...\n",
      "Normalizing driver_age...\n",
      "LabelEncoding appropriate columns...\n",
      "Oversampling rows...\n",
      "Num rows before oversampling: 250134\n",
      "multiplier for 0: 1 row count: 250134\n",
      "num rows to be added: 5801\n",
      "num rows after added: 255935\n",
      "multiplier for 1: 1 row count: 255935\n",
      "num rows to be added: 9503\n",
      "num rows after added: 265438\n",
      "multiplier for 3: 1 row count: 265438\n",
      "num rows to be added: 38922\n",
      "num rows after added: 304360\n",
      "multiplier for 4: 1 row count: 304360\n",
      "num rows to be added: 20509\n",
      "num rows after added: 324869\n",
      "Num rows after oversampling: 324869\n",
      "[Row counts] train: 324869  test: 62534\n",
      "\n",
      "Pickling dataframe to file...\n",
      "\n",
      "\n",
      "Stage 5:\n",
      "\n",
      "Reading CSV...\n",
      "Flags:\n",
      "\tinclude_location_raw: True\n",
      "\tperform_oversampling: False\n",
      "\tencode_labels: True\n",
      "Dropping non-essential columns...\n",
      "Dropping empty stop_outcome and county_name rows...\n",
      "Dropping driver_age rows under 15 y.o....\n",
      "Filling empty stop_time values with median...\n",
      "Categorizing stop_time and time-of-day...\n",
      "LabelEncoding location_raw...\n",
      "Normalizing violations and appending one-hot encoded violations to df...\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import importlib\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from tabulate import tabulate\n",
    "import humanize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scripts.sampling import oversample, undersample\n",
    "from scripts.time_categories import day_period, season\n",
    "from scripts.violations import normalize_violations\n",
    "\n",
    "\n",
    "def split_train_test(df, decimal_pct):\n",
    "    lop_off_idx = round(df.shape[0] * decimal_pct)\n",
    "    test = df[:lop_off_idx]\n",
    "    train = df[lop_off_idx:]\n",
    "    return (train, test)\n",
    "\n",
    "\n",
    "def categorize_dates_times(df):\n",
    "    print('Categorizing stop_time and time-of-day...')\n",
    "    df['hour'] = pd.to_numeric(df['stop_time'].apply(lambda x: str(x).split(':')[0]), downcast='signed')\n",
    "    df['minute'] = pd.to_numeric(df['stop_time'].apply(lambda x: str(x).split(':')[1]), downcast='signed')\n",
    "    df['month'] = pd.to_numeric(df['stop_date'].apply(lambda x: str(x).split('-')[1]), downcast='signed')\n",
    "    df['day'] = pd.to_numeric(df['stop_date'].apply(lambda x: int(str(x).split('-')[2])), downcast='signed')\n",
    "    return df\n",
    "\n",
    "\n",
    "def drop_threshold_ages(df, age_threshold):\n",
    "    print('Dropping driver_age rows under {} y.o....'.format(age_threshold))\n",
    "    weird_ages_rows = df[df[\"driver_age_raw\"] < 15]['driver_age_raw']\n",
    "    df.drop(index=weird_ages_rows.index, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def binarize(df, columns):\n",
    "    print('Converting boolean columns to 0 and 1...')\n",
    "    for col in columns:\n",
    "        df[col] = df[col].apply(lambda x: int(x))\n",
    "    return df\n",
    "\n",
    "\n",
    "def normalize_columns(df, columns):\n",
    "    print('Normalizing driver_age...')\n",
    "    scaler = MinMaxScaler() # default=(0, 1)\n",
    "    for col in columns:\n",
    "        df[col] = scaler.fit_transform(df[col].reshape(-1, 1))\n",
    "    return df\n",
    "\n",
    "\n",
    "def column_names(df):\n",
    "    return list(df.columns.values)\n",
    "\n",
    "\n",
    "def encode_categoricals(df, cols_to_encode, encode_labels):\n",
    "    \"\"\"Use LabelEncoder() to enumerate categorical fields values;  If encode_labels=False: One-hot encode\n",
    "    :param pd.DataFrame df:\n",
    "    :param list[str] cols_to_encode:\n",
    "    :param bool encode_labels:\n",
    "    :return: Dataframe with categorical labels that have been enumerated in-place in their respective columns or\n",
    "             multiple binary columns if one-hot encoded\n",
    "    :rtype: pd.DataFrame\n",
    "    \"\"\"\n",
    "    col_names = column_names(df)\n",
    "    parsed_cols = [col for col in cols_to_encode if col in col_names]\n",
    "    # for col in cols_to_encode:\n",
    "    #     if col in col_names:\n",
    "    #         parsed_cols.append(col)\n",
    "\n",
    "    if encode_labels:\n",
    "        print('LabelEncoding appropriate columns...')\n",
    "        for col in parsed_cols:\n",
    "            encoder = LabelEncoder()\n",
    "            df[col] = encoder.fit_transform(df[col].astype('str'))\n",
    "    else:\n",
    "        df = pd.get_dummies(df, columns=parsed_cols)\n",
    "    return df\n",
    "\n",
    "\n",
    "def populate_empty_vals(df, col_name):\n",
    "    print('Filling empty {} values with median...'.format(col_name))\n",
    "    populated = df[df[col_name].notnull()][col_name].sort_values()\n",
    "    median_value = populated.iloc[populated.shape[0] // 2]\n",
    "    df[col_name].fillna(median_value, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess(df, **kwargs):\n",
    "    # Set flags\n",
    "    include_location_raw = kwargs['include_location_raw']\n",
    "    include_driver_race = kwargs['include_driver_race']\n",
    "    perform_oversampling = kwargs['perform_oversampling']\n",
    "    perform_undersampling = kwargs['perform_undersampling']\n",
    "    # True: Use LabelEncoder to enumerate categorical fields values;  False: Use one-hot encoding via pd.get_dummies\n",
    "    encode_labels = kwargs['encode_labels']\n",
    "\n",
    "    print(\"Flags:\\n\\tinclude_location_raw: {}\\n\\tperform_oversampling: {}\\n\\tencode_labels: {}\".format(include_location_raw,\n",
    "        perform_oversampling, encode_labels))\n",
    "\n",
    "    # Drop non-essential base columns\n",
    "    print('Dropping non-essential columns...')\n",
    "    # Start with columns that are always dropped\n",
    "    drop_cols = [\n",
    "        'county_fips',\n",
    "        'driver_age',\n",
    "        'driver_race_raw',\n",
    "        'fine_grained_location',\n",
    "        'id',\n",
    "        'is_arrested',\n",
    "        'officer_id',\n",
    "        'police_department',\n",
    "        'search_type_raw',\n",
    "        'search_type',\n",
    "        'state',\n",
    "    ]\n",
    "\n",
    "    if not include_location_raw:\n",
    "        drop_cols.append('location_raw')\n",
    "    if not include_driver_race:\n",
    "        drop_cols.append('driver_race')\n",
    "\n",
    "    df.drop(drop_cols, axis=1, inplace=True)\n",
    "\n",
    "    # Drop empty stop_outcome and county_name rows\n",
    "    print('Dropping empty stop_outcome and county_name rows...')\n",
    "    df.dropna(subset=['stop_outcome', 'county_name'], axis=0, inplace=True)\n",
    "    # df.dropna(subset=['stop_outcome'], axis=0, inplace=True) [REMOVEME?]\n",
    "\n",
    "    # Remove records with age less than 15\n",
    "    if 'driver_age_raw' in column_names(df):\n",
    "        df = drop_threshold_ages(df, 15)\n",
    "\n",
    "    # Fill in empty stop_time values with median value\n",
    "    df = populate_empty_vals(df, 'stop_time')\n",
    "\n",
    "    # Categorize stop_date and stop_time into month, day, hour, and min columns\n",
    "    df = categorize_dates_times(df)\n",
    "\n",
    "    if include_location_raw:\n",
    "        print('LabelEncoding location_raw...')\n",
    "        encoder = LabelEncoder()\n",
    "        df['location_raw'] = encoder.fit_transform(df['location_raw'].astype(str))\n",
    "\n",
    "    # Normalize violations and append one-hot encoded violations\n",
    "    print('Normalizing violations and appending one-hot encoded violations to df...')\n",
    "    df_violations = normalize_violations(df)\n",
    "    df = pd.concat([df, df_violations], axis=1)\n",
    "\n",
    "\n",
    "    # Encode officer_id\n",
    "    # df['officer_id'] = df['officer_id'].apply(lambda x: 'ofcr_{}'.format(x))\n",
    "\n",
    "    # Drop columns no longer needed\n",
    "    print('Dropping no longer needed columns...')\n",
    "    drop_cols = [\n",
    "        # 'driver_gender',\n",
    "        'stop_date',\n",
    "        'stop_time',\n",
    "        'violation_raw',\n",
    "        'violation',\n",
    "    ]\n",
    "    df.drop(drop_cols, axis=1, inplace=True)\n",
    "\n",
    "    # Drop duplicate rows\n",
    "    print('Dropping duplicate rows...')\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Convert booleans to 0 and 1\n",
    "    df = binarize(df, ['search_conducted', 'contraband_found'])\n",
    "\n",
    "\n",
    "    # Normalize driver_age\n",
    "    df = normalize_columns(df, ['driver_age_raw'])\n",
    "\n",
    "    # Categorical variables to one-hot encode or label encode\n",
    "    cols_to_encode = [\n",
    "        'county_name',\n",
    "        'driver_gender',\n",
    "        'driver_race',\n",
    "        'location_raw',\n",
    "        'stop_duration',\n",
    "    ]\n",
    "\n",
    "    # Either label-encode or one-hot encode categorical variables\n",
    "    df = encode_categoricals(df, cols_to_encode, encode_labels)\n",
    "\n",
    "    # LabelEncode stop_outcome\n",
    "    encoder = LabelEncoder()\n",
    "    df['stop_outcome'] = encoder.fit_transform(df['stop_outcome'])\n",
    "\n",
    "    # Split dataset into training and testing sets\n",
    "    split_pct = 0.20\n",
    "    (train, test) = split_train_test(df, split_pct)\n",
    "\n",
    "    # Oversample\n",
    "    if perform_oversampling and not perform_undersampling:\n",
    "        print('Oversampling rows...')\n",
    "        train = shuffle(oversample(train), random_state=0)\n",
    "\n",
    "    # Undersample largest outcome\n",
    "    if perform_undersampling and not perform_oversampling:\n",
    "        train = undersample(train)\n",
    "\n",
    "    # Emulate dropout layer\n",
    "    # dropout_pct = .75\n",
    "    # train = train[:round(train.shape[0] * dropout_pct)]\n",
    "\n",
    "    return (train, test)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    stages = [{\n",
    "        'include_location_raw': False,\n",
    "        'include_driver_race': True,\n",
    "        'encode_labels': False,\n",
    "        'perform_oversampling': False,\n",
    "        'perform_undersampling': False,\n",
    "    }, {\n",
    "        'include_location_raw': True,\n",
    "        'include_driver_race': True,\n",
    "        'encode_labels': False,\n",
    "        'perform_oversampling': False,\n",
    "        'perform_undersampling': False,\n",
    "    }, {\n",
    "        'include_location_raw': True,\n",
    "        'include_driver_race': True,\n",
    "        'encode_labels': True,\n",
    "        'perform_oversampling': False,\n",
    "        'perform_undersampling': False,\n",
    "    }, {\n",
    "        'include_location_raw': True,\n",
    "        'include_driver_race': True,\n",
    "        'encode_labels': True,\n",
    "        'perform_oversampling': True,\n",
    "        'perform_undersampling': False,\n",
    "    }, {\n",
    "        'include_location_raw': True,\n",
    "        'include_driver_race': True,\n",
    "        'encode_labels': True,\n",
    "        'perform_oversampling': False,\n",
    "        'perform_undersampling': True,\n",
    "    }, {\n",
    "        'include_location_raw': True,\n",
    "        'include_driver_race': False,\n",
    "        'encode_labels': False,\n",
    "        'perform_oversampling': False,\n",
    "        'perform_undersampling': False,\n",
    "    }, {\n",
    "        'include_location_raw': True,\n",
    "        'include_driver_race': False,\n",
    "        'encode_labels': True,\n",
    "        'perform_oversampling': False,\n",
    "        'perform_undersampling': False,\n",
    "    }]\n",
    "\n",
    "    for idx, stage in enumerate(stages, 1):\n",
    "        print('\\n\\nStage {}:\\n\\nReading CSV...'.format(idx))\n",
    "        df_in = pd.read_csv('./data/CT-clean.csv', header=0)\n",
    "        (train, test) = preprocess(df_in, **stage)\n",
    "\n",
    "        print('[Row counts] train: {}  test: {}'.format(train.shape[0], test.shape[0]))\n",
    "\n",
    "        print('\\nPickling dataframe to file...')\n",
    "        train.to_pickle('./data/stage{}-train.pkl'.format(idx))\n",
    "        test.to_pickle('./data/stage{}-test.pkl'.format(idx))\n",
    "\n",
    "    print('\\nFinished preprocessing.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
