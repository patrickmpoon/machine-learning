{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3\n",
    "\n",
    "- has **`location_raw`**: True\n",
    "- vars one-hot encoded: False\n",
    "- var label-encoded: True\n",
    "- oversampled: False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T22:21:00.520700Z",
     "start_time": "2018-05-19T22:21:00.512891Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import humanize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.externals.joblib import parallel_backend\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T22:21:01.459399Z",
     "start_time": "2018-05-19T22:21:00.521985Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row counts:\n",
      "\ttrain: 222186\n",
      "\ttest: 55547\n"
     ]
    }
   ],
   "source": [
    "X_train = pickle.load(open('./data/stage6-train.pkl', 'rb'))\n",
    "y_train = X_train.pop('stop_outcome')\n",
    "X_test = pickle.load(open('./data/stage6-test.pkl', 'rb'))\n",
    "y_test = X_test.pop('stop_outcome')\n",
    "\n",
    "print('Row counts:\\n\\ttrain: {}\\n\\ttest: {}'.format(X_train.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T14:30:43.232766Z",
     "start_time": "2018-05-19T14:30:43.230452Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# features = pickle.load(open('./data/stage3-l_encoded.pkl', 'rb'))\n",
    "# labels = features.pop('stop_outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T14:30:43.237206Z",
     "start_time": "2018-05-19T14:30:43.234125Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# final_test_features = pickle.load(open('./data/final_test_set.pkl', 'rb'))\n",
    "# final_test_outcomes = final_test_features.pop('stop_outcome')\n",
    "# print('Final test set row count: {}'.format(final_test_features.shape[0]))\n",
    "\n",
    "# X_train = features\n",
    "# y_train = labels\n",
    "# X_test = final_test_features\n",
    "# y_test = final_test_outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T14:30:44.189991Z",
     "start_time": "2018-05-19T14:30:43.238035Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pato/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.68248510270581675"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "clf_sgd = linear_model.SGDClassifier()\n",
    "clf_sgd.fit(X_train, y_train)\n",
    "clf_sgd.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T14:32:01.237432Z",
     "start_time": "2018-05-19T14:30:44.190843Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 4 of 10\n",
      "building tree 5 of 10building tree 6 of 10building tree 1 of 10building tree 2 of 10building tree 7 of 10building tree 8 of 10building tree 3 of 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.5s remaining:    1.2s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.6s remaining:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1      281283.1875            1.23m\n",
      "         2      266377.5430            1.16m\n",
      "         3      254461.9679            1.15m\n",
      "         4      244809.7438            1.12m\n",
      "         5      236933.1755            1.10m\n",
      "         6      230389.0604            1.09m\n",
      "         7      224984.9688            1.08m\n",
      "         8      220253.9521            1.08m\n",
      "         9      216417.4604            1.08m\n",
      "        10      213112.6378            1.07m\n",
      "        11      210269.1842            1.07m\n",
      "        12      207924.1580            1.06m\n",
      "        13      205713.8042            1.05m\n",
      "        14      203931.8350            1.04m\n",
      "        15      202204.6937            1.03m\n",
      "        16      200696.2240            1.03m\n",
      "        17      199482.6120            1.01m\n",
      "        18      198379.0694            1.00m\n",
      "        19      197438.5903           59.67s\n",
      "        20      196566.2978           58.98s\n",
      "        21      195826.7270           58.42s\n",
      "        22      195023.0793           57.77s\n",
      "        23      194370.6862           57.03s\n",
      "        24      193815.7947           56.36s\n",
      "        25      193309.0059           55.61s\n",
      "        26      192659.8814           54.95s\n",
      "        27      192199.7761           54.15s\n",
      "        28      191839.9164           53.52s\n",
      "        29      191497.0531           52.79s\n",
      "        30      191198.0691           52.04s\n",
      "        31      190897.0893           51.31s\n",
      "        32      190511.1142           50.64s\n",
      "        33      190137.4376           49.90s\n",
      "        34      189901.2118           49.19s\n",
      "        35      189716.9217           48.30s\n",
      "        36      189503.9089           47.43s\n",
      "        37      189156.4948           46.81s\n",
      "        38      188912.3404           46.19s\n",
      "        39      188638.0572           45.47s\n",
      "        40      188483.9101           44.64s\n",
      "        41      188302.6895           43.87s\n",
      "        42      188096.7086           43.17s\n",
      "        43      187981.4155           42.39s\n",
      "        44      187662.7071           41.71s\n",
      "        45      187514.3267           40.96s\n",
      "        46      187366.5030           40.23s\n",
      "        47      187236.2914           39.48s\n",
      "        48      187131.7500           38.64s\n",
      "        49      186976.8623           37.94s\n",
      "        50      186876.2328           37.16s\n",
      "        51      186691.9697           36.44s\n",
      "        52      186595.8549           35.72s\n",
      "        53      186503.7678           35.00s\n",
      "        54      186381.5036           34.29s\n",
      "        55      186295.5807           33.47s\n",
      "        56      186201.9278           32.75s\n",
      "        57      186026.9483           32.05s\n",
      "        58      185949.3063           31.29s\n",
      "        59      185847.4560           30.54s\n",
      "        60      185754.6795           29.77s\n",
      "        61      185646.2184           29.03s\n",
      "        62      185577.9650           28.27s\n",
      "        63      185526.2243           27.50s\n",
      "        64      185443.0788           26.75s\n",
      "        65      185326.2164           26.01s\n",
      "        66      185219.0775           25.24s\n",
      "        67      185080.5122           24.51s\n",
      "        68      184924.2821           23.77s\n",
      "        69      184793.3645           23.04s\n",
      "        70      184695.7818           22.32s\n",
      "        71      184642.0358           21.56s\n",
      "        72      184517.4985           20.83s\n",
      "        73      184443.5340           20.08s\n",
      "        74      184373.3130           19.31s\n",
      "        75      184280.4292           18.57s\n",
      "        76      184185.4344           17.83s\n",
      "        77      184111.3485           17.07s\n",
      "        78      184044.8953           16.35s\n",
      "        79      183948.7037           15.61s\n",
      "        80      183864.9437           14.88s\n",
      "        81      183771.1074           14.14s\n",
      "        82      183722.6511           13.37s\n",
      "        83      183675.5785           12.63s\n",
      "        84      183592.9420           11.90s\n",
      "        85      183508.3622           11.17s\n",
      "        86      183463.3360           10.42s\n",
      "        87      183375.6965            9.67s\n",
      "        88      183321.8966            8.92s\n",
      "        89      183279.0279            8.18s\n",
      "        90      183208.4189            7.43s\n",
      "        91      183169.4258            6.69s\n",
      "        92      183120.0877            5.93s\n",
      "        93      183058.4665            5.19s\n",
      "        94      183002.9240            4.45s\n",
      "        95      182954.8323            3.71s\n",
      "        96      182886.4111            2.97s\n",
      "        97      182837.6644            2.23s\n",
      "        98      182791.6963            1.48s\n",
      "        99      182716.8214            0.74s\n",
      "       100      182673.6669            0.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eclf score: 0.6808288476425369\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf1 = RandomForestClassifier(n_jobs=8, verbose=3, random_state=0)\n",
    "clf2 = GaussianNB()\n",
    "clf3 = DecisionTreeClassifier(random_state=0)\n",
    "clf4 = GradientBoostingClassifier(verbose=3, random_state=0)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('rf', clf1), ('gnb', clf2), ('dt', clf3), ('gb', clf4)],\n",
    "                        voting='soft')\n",
    "eclf = eclf.fit(X_train, y_train)\n",
    "print('eclf score: {}'.format(eclf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T14:32:01.241287Z",
     "start_time": "2018-05-19T14:32:01.238229Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=8,\n",
       "             oob_score=False, random_state=0, verbose=3, warm_start=False),\n",
       " GaussianNB(priors=None),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "             splitter='best'),\n",
       " GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "               learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "               max_features=None, max_leaf_nodes=None,\n",
       "               min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "               min_samples_leaf=1, min_samples_split=2,\n",
       "               min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "               presort='auto', random_state=0, subsample=1.0, verbose=3,\n",
       "               warm_start=False)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf.estimators_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T14:32:01.723900Z",
     "start_time": "2018-05-19T14:32:01.242040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6732496804507894\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "print('{}'.format(gnb.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T14:32:02.900181Z",
     "start_time": "2018-05-19T14:32:01.724672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5399211478567699\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(random_state=0)\n",
    "dtc.fit(X_train, y_train)\n",
    "print('{}'.format(dtc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T14:32:05.304043Z",
     "start_time": "2018-05-19T14:32:02.900931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6320413343654923\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(random_state=0)\n",
    "rfc.fit(X_train, y_train)\n",
    "print('{}'.format(rfc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T04:36:36.956271Z",
     "start_time": "2018-05-19T04:36:36.947970Z"
    }
   },
   "source": [
    "# GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T22:20:32.140146Z",
     "start_time": "2018-05-19T22:20:32.057550Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GradientBoostingClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f8c1756b2355>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgbc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgbc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgbc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GradientBoostingClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(random_state=0)\n",
    "gbc.fit(X_train, y_train)\n",
    "print('{}'.format(gbc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingClassifier (Tuned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T22:20:32.140460Z",
     "start_time": "2018-05-19T22:20:32.060Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbc_tuned = GradientBoostingClassifier(\n",
    "    learning_rate=0.0983,\n",
    "    max_depth=6,\n",
    "    max_features=len(list(X_train.columns.values)),\n",
    "    subsample=0.9,\n",
    "    verbose=3,\n",
    "    random_state=0,\n",
    ")\n",
    "gbc_tuned.fit(X_train, y_train)\n",
    "print('{}'.format(gbc_tuned.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T22:20:32.140872Z",
     "start_time": "2018-05-19T22:20:32.066Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals.joblib import parallel_backend\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "\n",
    "\n",
    "params = {\n",
    "    'criterion': ['friedman_mse', 'mse', 'mae'],\n",
    "#     'loss': ['deviance'],\n",
    "    'learning_rate': [0.0983, 0.1],\n",
    "    'max_depth': [5, 6, 7],\n",
    "    'max_features': [None, len(list(X_train.columns.values))],\n",
    "    'subsample': [0.5, 0.75, 0.9],\n",
    "#     'verbose': [3],\n",
    "#     'random_state': [0],\n",
    "\n",
    "}\n",
    "\n",
    "gbc = GradientBoostingClassifier(verbose=3, random_state=0)\n",
    "clf = RandomizedSearchCV(gbc, params, scoring='accuracy', cv=5, verbose=3)\n",
    "\n",
    "with parallel_backend('threading'):\n",
    "    clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T22:20:32.141285Z",
     "start_time": "2018-05-19T22:20:32.068Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T22:20:32.141645Z",
     "start_time": "2018-05-19T22:20:32.070Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T22:20:32.142026Z",
     "start_time": "2018-05-19T22:20:32.074Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T22:20:32.142442Z",
     "start_time": "2018-05-19T22:20:32.074Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T22:20:32.143407Z",
     "start_time": "2018-05-19T22:20:32.076Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T22:20:32.143823Z",
     "start_time": "2018-05-19T22:20:32.078Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_estimators = 100\n",
    "criterion='friedman_mse'\n",
    "learning_rate=0.0983\n",
    "max_depth=6\n",
    "max_features=25\n",
    "subsample=0.9\n",
    "# gbc100 = GradientBoostingClassifier(verbose=3, random_state=0, criterion=criterion,learning_rate=learning_rate, max_depth=max_depth, max_features=max_features, subsample=subsample)\n",
    "gbc100 = GradientBoostingClassifier(clf.best_params_)\n",
    "gbc100.fit(X_train, y_train)\n",
    "print('{}'.format(gbc100.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T22:22:26.303451Z",
     "start_time": "2018-05-19T22:21:10.324365Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7080130340072371\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "gbc = GradientBoostingClassifier(random_state=0)\n",
    "with parallel_backend('threading'):\n",
    "    gbc.fit(X_train, y_train)\n",
    "print('{}'.format(gbc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingClassifier (Tuned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T22:26:26.145119Z",
     "start_time": "2018-05-19T22:22:26.304343Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1      252173.4557        2021.5795            3.55m\n",
      "         2      237869.7440        1554.8071            3.50m\n",
      "         3      226537.7157        1284.3680            3.46m\n",
      "         4      217022.3110        1025.0879            3.43m\n",
      "         5      209507.3365         822.1559            3.43m\n",
      "         6      203239.1616         697.5678            3.44m\n",
      "         7      197916.5056         585.7970            3.43m\n",
      "         8      193493.7245         471.2457            3.40m\n",
      "         9      189747.8529         409.0788            3.37m\n",
      "        10      186326.6897         348.7715            3.36m\n",
      "        11      183742.5363         283.0833            3.32m\n",
      "        12      181261.0246         244.2004            3.29m\n",
      "        13      179342.0977         233.0752            3.28m\n",
      "        14      177546.1736         189.8533            3.26m\n",
      "        15      175727.0496         171.3121            3.25m\n",
      "        16      174091.4728         159.9038            3.23m\n",
      "        17      173025.6370         130.7020            3.20m\n",
      "        18      171990.3704         112.9522            3.17m\n",
      "        19      170870.6540          95.5496            3.13m\n",
      "        20      169958.4279          98.7994            3.09m\n",
      "        21      169127.9879          66.9005            3.07m\n",
      "        22      168470.4358          70.4584            3.04m\n",
      "        23      167633.1316          82.7204            3.01m\n",
      "        24      166863.7195          62.9359            2.98m\n",
      "        25      166563.8228          40.5870            2.93m\n",
      "        26      165860.2492          53.6297            2.90m\n",
      "        27      165117.7980          70.3887            2.88m\n",
      "        28      164737.2857          46.9624            2.84m\n",
      "        29      164228.4933          33.2888            2.81m\n",
      "        30      163769.9753          40.3992            2.78m\n",
      "        31      163364.8974          24.8461            2.74m\n",
      "        32      163133.3590          22.5254            2.70m\n",
      "        33      162909.4786          24.1939            2.66m\n",
      "        34      162264.6037          32.1479            2.64m\n",
      "        35      162225.4858          21.2843            2.60m\n",
      "        36      162067.2500          13.5849            2.56m\n",
      "        37      161756.2831          17.2021            2.52m\n",
      "        38      161417.2634          21.4420            2.48m\n",
      "        39      161176.9886          15.2436            2.44m\n",
      "        40      160854.0671          19.1108            2.40m\n",
      "        41      160833.2518          19.4514            2.36m\n",
      "        42      160279.4467          16.1933            2.32m\n",
      "        43      160052.5105          24.8977            2.28m\n",
      "        44      160011.8694          11.4738            2.24m\n",
      "        45      159791.7180           9.6108            2.20m\n",
      "        46      159591.9844           8.5887            2.16m\n",
      "        47      159413.9473          20.2584            2.12m\n",
      "        48      159269.8294          12.1317            2.08m\n",
      "        49      158872.2484          12.3595            2.04m\n",
      "        50      158623.4863           6.4524            1.99m\n",
      "        51      158885.0926           4.1251            1.95m\n",
      "        52      158311.0841           5.4267            1.91m\n",
      "        53      158185.0620           4.9628            1.87m\n",
      "        54      158085.6620           6.6872            1.83m\n",
      "        55      158153.6606           4.5536            1.79m\n",
      "        56      157906.3096           3.6492            1.75m\n",
      "        57      157840.3318           5.3410            1.70m\n",
      "        58      157636.2361           4.7842            1.66m\n",
      "        59      157430.6197           7.2703            1.62m\n",
      "        60      157381.7787           0.9681            1.58m\n",
      "        61      157171.7171           1.5042            1.54m\n",
      "        62      157119.0743           7.6940            1.50m\n",
      "        63      157073.0814           5.5823            1.46m\n",
      "        64      156991.2087           2.2550            1.42m\n",
      "        65      157036.2817           5.9504            1.38m\n",
      "        66      156518.8254           5.3103            1.34m\n",
      "        67      156515.8375           1.2595            1.30m\n",
      "        68      156452.5113           1.4823            1.27m\n",
      "        69      156158.8859           5.1362            1.23m\n",
      "        70      156332.5404           2.7399            1.19m\n",
      "        71      155991.7624           2.9816            1.15m\n",
      "        72      155990.3828           2.0476            1.11m\n",
      "        73      155673.8030           0.2318            1.07m\n",
      "        74      155871.2298           5.2533            1.04m\n",
      "        75      155643.0171           3.6972           59.85s\n",
      "        76      155627.1945           2.1809           57.49s\n",
      "        77      155232.8389           4.5730           55.10s\n",
      "        78      155228.5940           0.6619           52.72s\n",
      "        79      155276.8146           6.3908           50.36s\n",
      "        80      155355.2934          -0.8898           47.88s\n",
      "        81      155124.3842           1.6879           45.50s\n",
      "        82      155001.6789          -0.4378           43.03s\n",
      "        83      154899.4193           2.3327           40.63s\n",
      "        84      154857.7986           4.1767           38.23s\n",
      "        85      154576.3462           1.2887           35.81s\n",
      "        86      154596.1652           0.8163           33.48s\n",
      "        87      154353.2214           3.2369           31.10s\n",
      "        88      154420.8623           1.7041           28.70s\n",
      "        89      154305.6364          -0.9490           26.29s\n",
      "        90      154375.3451           1.7010           23.87s\n",
      "        91      154180.7553          -2.1247           21.47s\n",
      "        92      154070.8546           0.9596           19.11s\n",
      "        93      153967.3287           1.9353           16.73s\n",
      "        94      153806.9053          -1.0613           14.33s\n",
      "        95      153776.9285           1.8343           11.94s\n",
      "        96      153669.1575           0.6627            9.55s\n",
      "        97      153698.9251           2.5314            7.17s\n",
      "        98      153401.4557          -1.0348            4.79s\n",
      "        99      153408.5795          -2.4557            2.39s\n",
      "       100      153383.5696          -1.0918            0.00s\n",
      "0.7175004950762417\n"
     ]
    }
   ],
   "source": [
    "gbc_tuned = GradientBoostingClassifier(\n",
    "    learning_rate=0.0983,\n",
    "    max_depth=6,\n",
    "    max_features=len(list(X_train.columns.values)),\n",
    "    subsample=0.9,\n",
    "    verbose=3,\n",
    "    random_state=0,\n",
    ")\n",
    "with parallel_backend('threading'):\n",
    "    gbc_tuned.fit(X_train, y_train)\n",
    "print('{}'.format(gbc_tuned.score(X_test, y_test)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
