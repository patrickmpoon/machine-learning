{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1\n",
    "\n",
    "- has **`location_raw`**: False\n",
    "- vars one-hot encoded: True\n",
    "- var label-encoded: False\n",
    "- oversampled: False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T19:49:23.337323Z",
     "start_time": "2018-05-19T19:49:19.963401Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import humanize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.externals.joblib import parallel_backend\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T19:49:23.545019Z",
     "start_time": "2018-05-19T19:49:23.357206Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row counts:\n",
      "\ttrain: 148446\n",
      "\ttest: 37112\n"
     ]
    }
   ],
   "source": [
    "X_train = pickle.load(open('./data/stage1-train.pkl', 'rb'))\n",
    "y_train = X_train.pop('stop_outcome')\n",
    "X_test = pickle.load(open('./data/stage1-test.pkl', 'rb'))\n",
    "y_test = X_test.pop('stop_outcome')\n",
    "\n",
    "print('Row counts:\\n\\ttrain: {}\\n\\ttest: {}'.format(X_train.shape[0], X_test.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T20:07:03.990902Z",
     "start_time": "2018-05-19T19:49:23.565703Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, PassiveAggressiveClassifier, Perceptron\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier as EnsExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "\n",
    "# clf1 = RandomForestClassifier(n_jobs=8, verbose=3, random_state=0)\n",
    "# clf2 = GaussianNB()\n",
    "# clf3 = DecisionTreeClassifier(random_state=0)\n",
    "# clf4 = GradientBoostingClassifier(verbose=3, random_state=0)\n",
    "\n",
    "# eclf = VotingClassifier(estimators=[('rf', clf1), ('gnb', clf2), ('dt', clf3), ('gb', clf4)],\n",
    "#                         voting='soft')\n",
    "\n",
    "clf5 = BernoulliNB()\n",
    "clf6 = ExtraTreeClassifier()\n",
    "clf7 = EnsExtraTreesClassifier(n_jobs=-1, verbose=3, random_state=0)\n",
    "clf8 = KNeighborsClassifier(n_jobs=-1)\n",
    "clf9 = LogisticRegressionCV(n_jobs=-1, verbose=3, random_state=0)\n",
    "clf10 = MLPClassifier(verbose=3, random_state=0)\n",
    "# clf11 = LinearSVC(verbose=3, random_state=0)\n",
    "clf12 = Perceptron(n_jobs=-1, verbose=3, random_state=0)\n",
    "clf13 = PassiveAggressiveClassifier(n_jobs=-1, verbose=3, random_state=0)\n",
    "# clf14 = ()\n",
    "# clf15 = ()\n",
    "\n",
    "eclf = VotingClassifier(estimators=[\n",
    "                            ('bnb', clf5),\n",
    "                            ('etc', clf6),\n",
    "                            ('eetc', clf7),\n",
    "                            ('knc', clf8),\n",
    "                            ('lrcv', clf9),\n",
    "                            ('mlpc', clf10),\n",
    "#                             ('lsvc', clf11),\n",
    "                            ('p', clf12),\n",
    "                            ('pac', clf13),\n",
    "#                             ('', clf14),\n",
    "#                             ('', clf15),\n",
    "                        ], voting='soft')\n",
    "\n",
    "with parallel_backend('threading'):\n",
    "    eclf = eclf.fit(X_train, y_train)\n",
    "print('eclf score: {}'.format(eclf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T20:15:24.166051Z",
     "start_time": "2018-05-19T20:15:22.471805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf5 score: 0.578330459150679\n"
     ]
    }
   ],
   "source": [
    "with parallel_backend('threading'):\n",
    "    clf5.fit(X_train, y_train)\n",
    "print('clf5 score: {}'.format(clf5.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T20:29:33.245687Z",
     "start_time": "2018-05-19T20:27:55.510747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf6 score: 0.36263203276568223\n"
     ]
    }
   ],
   "source": [
    "with parallel_backend('threading'):\n",
    "    clf6.fit(X_train, y_train)\n",
    "print('clf6 score: {}'.format(clf6.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T20:29:33.245687Z",
     "start_time": "2018-05-19T20:27:55.510747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 10\n",
      "building tree 2 of 10building tree 3 of 10building tree 4 of 10building tree 5 of 10building tree 6 of 10building tree 7 of 10\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    1.7s remaining:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    1.9s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.2s remaining:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf7 score: 0.3698803621470144\n"
     ]
    }
   ],
   "source": [
    "with parallel_backend('threading'):\n",
    "    clf7.fit(X_train, y_train)\n",
    "print('clf7 score: {}'.format(clf7.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T20:29:33.245687Z",
     "start_time": "2018-05-19T20:27:55.510747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf8 score: 0.48348243155852555\n"
     ]
    }
   ],
   "source": [
    "with parallel_backend('threading'):\n",
    "    clf8.fit(X_train, y_train)\n",
    "print('clf8 score: {}'.format(clf8.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T20:29:33.245687Z",
     "start_time": "2018-05-19T20:27:55.510747Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pato/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:718: UserWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"lbfgs failed to converge. Increase the number \"\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  15 | elapsed:   43.8s remaining:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  15 | elapsed:  1.4min remaining:   20.3s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf9 score: 0.6329219659409355\n"
     ]
    }
   ],
   "source": [
    "with parallel_backend('threading'):\n",
    "    clf9.fit(X_train, y_train)\n",
    "print('clf9 score: {}'.format(clf9.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T20:36:39.106437Z",
     "start_time": "2018-05-19T20:29:33.248120Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.04564758\n",
      "Iteration 2, loss = 1.00236776\n",
      "Iteration 3, loss = 0.99608363\n",
      "Iteration 4, loss = 0.99241641\n",
      "Iteration 5, loss = 0.98977881\n",
      "Iteration 6, loss = 0.98770017\n",
      "Iteration 7, loss = 0.98579702\n",
      "Iteration 8, loss = 0.98460003\n",
      "Iteration 9, loss = 0.98336188\n",
      "Iteration 10, loss = 0.98246146\n",
      "Iteration 11, loss = 0.98169996\n",
      "Iteration 12, loss = 0.98061031\n",
      "Iteration 13, loss = 0.98019954\n",
      "Iteration 14, loss = 0.97959228\n",
      "Iteration 15, loss = 0.97874129\n",
      "Iteration 16, loss = 0.97825517\n",
      "Iteration 17, loss = 0.97777956\n",
      "Iteration 18, loss = 0.97739662\n",
      "Iteration 19, loss = 0.97731143\n",
      "Iteration 20, loss = 0.97668241\n",
      "Iteration 21, loss = 0.97638296\n",
      "Iteration 22, loss = 0.97590987\n",
      "Iteration 23, loss = 0.97566239\n",
      "Iteration 24, loss = 0.97544431\n",
      "Iteration 25, loss = 0.97510354\n",
      "Iteration 26, loss = 0.97487261\n",
      "Iteration 27, loss = 0.97448945\n",
      "Iteration 28, loss = 0.97420448\n",
      "Iteration 29, loss = 0.97431868\n",
      "Iteration 30, loss = 0.97376724\n",
      "Iteration 31, loss = 0.97357398\n",
      "Iteration 32, loss = 0.97347149\n",
      "Iteration 33, loss = 0.97347072\n",
      "Iteration 34, loss = 0.97305704\n",
      "Iteration 35, loss = 0.97318241\n",
      "Iteration 36, loss = 0.97271313\n",
      "Iteration 37, loss = 0.97264513\n",
      "Iteration 38, loss = 0.97253737\n",
      "Iteration 39, loss = 0.97216615\n",
      "Iteration 40, loss = 0.97206693\n",
      "Iteration 41, loss = 0.97195864\n",
      "Iteration 42, loss = 0.97188258\n",
      "Iteration 43, loss = 0.97158767\n",
      "Iteration 44, loss = 0.97154719\n",
      "Iteration 45, loss = 0.97149752\n",
      "Iteration 46, loss = 0.97147727\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "clf10 score: 0.5784382410002156\n"
     ]
    }
   ],
   "source": [
    "with parallel_backend('threading'):\n",
    "    clf10.fit(X_train, y_train)\n",
    "print('clf10 score: {}'.format(clf10.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T20:36:42.650410Z",
     "start_time": "2018-05-19T20:36:40.701536Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pato/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "-- Epoch 1-- Epoch 1\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "\n",
      "Norm: 14.29, NNZs: 36, Bias: -2.000000, T: 148446, Avg. loss: 0.760514\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 17.07, NNZs: 37, Bias: -2.000000, T: 148446, Avg. loss: 1.218748Norm: 11.01, NNZs: 33, Bias: -2.000000, T: 148446, Avg. loss: 0.266418\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.87, NNZs: 32, Bias: -2.000000, T: 148446, Avg. loss: 0.347386\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14.34, NNZs: 40, Bias: 0.000000, T: 148446, Avg. loss: 1.703343\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 16.32, NNZs: 37, Bias: -1.000000, T: 296892, Avg. loss: 0.760548\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 11.81, NNZs: 35, Bias: -1.000000, T: 296892, Avg. loss: 0.265124\n",
      "Total training time: 0.32 seconds.Norm: 16.08, NNZs: 33, Bias: -4.000000, T: 296892, Avg. loss: 1.212277\n",
      "-- Epoch 3\n",
      "\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 12.89, NNZs: 27, Bias: -2.000000, T: 296892, Avg. loss: 0.344121\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 18.50, NNZs: 36, Bias: 0.000000, T: 296892, Avg. loss: 1.694641\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15.92, NNZs: 36, Bias: -4.000000, T: 445338, Avg. loss: 0.761670\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.90, NNZs: 37, Bias: -4.000000, T: 445338, Avg. loss: 1.214319\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 13.42, NNZs: 35, Bias: -3.000000, T: 445338, Avg. loss: 0.267014\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 15.55, NNZs: 32, Bias: -2.000000, T: 445338, Avg. loss: 0.347360\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 16.48, NNZs: 39, Bias: 1.000000, T: 445338, Avg. loss: 1.699101\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 14.62, NNZs: 36, Bias: -3.000000, T: 593784, Avg. loss: 0.760523\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 14.49, NNZs: 33, Bias: -4.000000, T: 593784, Avg. loss: 1.217954\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.51, NNZs: 33, Bias: -1.000000, T: 593784, Avg. loss: 0.264854\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 17.01, NNZs: 34, Bias: 1.000000, T: 593784, Avg. loss: 1.700481\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 14.44, NNZs: 30, Bias: -3.000000, T: 742230, Avg. loss: 1.213197\n",
      "Total training time: 0.67 seconds.\n",
      "Norm: 16.09, NNZs: 35, Bias: -3.000000, T: 593784, Avg. loss: 0.346364\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.18, NNZs: 36, Bias: -2.000000, T: 742230, Avg. loss: 0.761336\n",
      "Total training time: 0.68 seconds.\n",
      "Norm: 17.13, NNZs: 32, Bias: 2.000000, T: 742230, Avg. loss: 1.705375Norm: 11.92, NNZs: 34, Bias: -1.000000, T: 742230, Avg. loss: 0.266085\n",
      "Total training time: 0.69 seconds.\n",
      "\n",
      "Total training time: 0.70 seconds.\n",
      "Norm: 12.41, NNZs: 35, Bias: -2.000000, T: 742230, Avg. loss: 0.347102\n",
      "Total training time: 0.81 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.7s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf12 score: 0.5750970036645829\n"
     ]
    }
   ],
   "source": [
    "with parallel_backend('threading'):\n",
    "    clf12.fit(X_train, y_train)\n",
    "print('clf12 score: {}'.format(clf12.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-19T20:36:42.650410Z",
     "start_time": "2018-05-19T20:36:40.701536Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pato/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1-- Epoch 1\n",
      "-- Epoch 1\n",
      "\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n",
      "Norm: 4.36, NNZs: 43, Bias: -0.796465, T: 148446, Avg. loss: 0.806039\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.83, NNZs: 43, Bias: -0.810669, T: 148446, Avg. loss: 0.247690Norm: 3.35, NNZs: 43, Bias: -0.948060, T: 148446, Avg. loss: 0.194959\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 2\n",
      "\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 3.91, NNZs: 43, Bias: -0.668891, T: 148446, Avg. loss: 0.535836Norm: 4.38, NNZs: 43, Bias: 0.113153, T: 148446, Avg. loss: 1.080692\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 2\n",
      "\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.90, NNZs: 43, Bias: -1.190651, T: 296892, Avg. loss: 0.803423\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3.79, NNZs: 43, Bias: -0.625253, T: 296892, Avg. loss: 0.193717\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3.97, NNZs: 43, Bias: -0.623526, T: 296892, Avg. loss: 0.247680\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.67, NNZs: 43, Bias: -0.194281, T: 296892, Avg. loss: 0.534247\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.68, NNZs: 43, Bias: -0.160892, T: 296892, Avg. loss: 1.076067\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.65, NNZs: 43, Bias: -0.919147, T: 445338, Avg. loss: 0.806952\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.89, NNZs: 43, Bias: -1.050084, T: 445338, Avg. loss: 0.194317\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.43, NNZs: 43, Bias: -1.245137, T: 445338, Avg. loss: 0.535581\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.28, NNZs: 43, Bias: 0.462094, T: 445338, Avg. loss: 1.082670\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.54, NNZs: 43, Bias: -0.510967, T: 445338, Avg. loss: 0.249386\n",
      "Norm: 4.54, NNZs: 43, Bias: -1.191470, T: 593784, Avg. loss: 0.806713Total training time: 0.66 seconds.\n",
      "\n",
      "-- Epoch 4Total training time: 0.65 seconds.\n",
      "\n",
      "-- Epoch 5\n",
      "Norm: 3.31, NNZs: 43, Bias: -0.272782, T: 593784, Avg. loss: 0.194918\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.94, NNZs: 43, Bias: 0.532521, T: 593784, Avg. loss: 1.077190\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.05, NNZs: 43, Bias: -1.126882, T: 593784, Avg. loss: 0.535837\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.94, NNZs: 43, Bias: -0.430276, T: 742230, Avg. loss: 0.193781\n",
      "Total training time: 0.81 seconds.\n",
      "Norm: 4.77, NNZs: 43, Bias: -0.724177, T: 593784, Avg. loss: 0.248550\n",
      "Norm: 4.41, NNZs: 43, Bias: -0.960003, T: 742230, Avg. loss: 0.805089Total training time: 0.86 seconds.\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.9s remaining:    1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 5.02, NNZs: 43, Bias: 0.359865, T: 742230, Avg. loss: 1.080826\n",
      "Total training time: 0.88 seconds.\n",
      "Norm: 4.04, NNZs: 43, Bias: -0.529661, T: 742230, Avg. loss: 0.536202\n",
      "Total training time: 0.93 seconds.\n",
      "Norm: 4.15, NNZs: 43, Bias: -0.955092, T: 742230, Avg. loss: 0.247585\n",
      "Total training time: 1.07 seconds.\n",
      "clf13 score: 0.5372925199396421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.1s finished\n"
     ]
    }
   ],
   "source": [
    "with parallel_backend('threading'):\n",
    "    clf13.fit(X_train, y_train)\n",
    "print('clf13 score: {}'.format(clf13.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
